{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, Dense, Dropout, LayerNormalization, Multiply, Reshape, Concatenate, Layer)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import RandomNormal, Orthogonal, Zeros\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('symtoms_df.csv')\n",
    "df2=pd.read_csv('Symptom-severity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_1</th>\n",
       "      <th>Symptom_2</th>\n",
       "      <th>Symptom_3</th>\n",
       "      <th>Symptom_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic _patches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic _patches</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic _patches</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>dischromic _patches</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Disease   Symptom_1              Symptom_2  \\\n",
       "0           0  Fungal infection     itching              skin_rash   \n",
       "1           1  Fungal infection   skin_rash   nodal_skin_eruptions   \n",
       "2           2  Fungal infection     itching   nodal_skin_eruptions   \n",
       "3           3  Fungal infection     itching              skin_rash   \n",
       "4           4  Fungal infection     itching              skin_rash   \n",
       "\n",
       "               Symptom_3             Symptom_4  \n",
       "0   nodal_skin_eruptions   dischromic _patches  \n",
       "1    dischromic _patches                   NaN  \n",
       "2    dischromic _patches                   NaN  \n",
       "3    dischromic _patches                   NaN  \n",
       "4   nodal_skin_eruptions                   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptom</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin_rash</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continuous_sneezing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shivering</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Symptom  weight\n",
       "0               itching       1\n",
       "1             skin_rash       3\n",
       "2  nodal_skin_eruptions       4\n",
       "3   continuous_sneezing       4\n",
       "4             shivering       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     | Symptom                        |   weight |\n",
      "|----:|:-------------------------------|---------:|\n",
      "|   0 | itching                        |        1 |\n",
      "|   1 | skin_rash                      |        3 |\n",
      "|   2 | nodal_skin_eruptions           |        4 |\n",
      "|   3 | continuous_sneezing            |        4 |\n",
      "|   4 | shivering                      |        5 |\n",
      "|   5 | chills                         |        3 |\n",
      "|   6 | joint_pain                     |        3 |\n",
      "|   7 | stomach_pain                   |        5 |\n",
      "|   8 | acidity                        |        3 |\n",
      "|   9 | ulcers_on_tongue               |        4 |\n",
      "|  10 | muscle_wasting                 |        3 |\n",
      "|  11 | vomiting                       |        5 |\n",
      "|  12 | burning_micturition            |        6 |\n",
      "|  13 | spotting_urination             |        6 |\n",
      "|  14 | fatigue                        |        4 |\n",
      "|  15 | weight_gain                    |        3 |\n",
      "|  16 | anxiety                        |        4 |\n",
      "|  17 | cold_hands_and_feets           |        5 |\n",
      "|  18 | mood_swings                    |        3 |\n",
      "|  19 | weight_loss                    |        3 |\n",
      "|  20 | restlessness                   |        5 |\n",
      "|  21 | lethargy                       |        2 |\n",
      "|  22 | patches_in_throat              |        6 |\n",
      "|  23 | irregular_sugar_level          |        5 |\n",
      "|  24 | cough                          |        4 |\n",
      "|  25 | high_fever                     |        7 |\n",
      "|  26 | sunken_eyes                    |        3 |\n",
      "|  27 | breathlessness                 |        4 |\n",
      "|  28 | sweating                       |        3 |\n",
      "|  29 | dehydration                    |        4 |\n",
      "|  30 | indigestion                    |        5 |\n",
      "|  31 | headache                       |        3 |\n",
      "|  32 | yellowish_skin                 |        3 |\n",
      "|  33 | dark_urine                     |        4 |\n",
      "|  34 | nausea                         |        5 |\n",
      "|  35 | loss_of_appetite               |        4 |\n",
      "|  36 | pain_behind_the_eyes           |        4 |\n",
      "|  37 | back_pain                      |        3 |\n",
      "|  38 | constipation                   |        4 |\n",
      "|  39 | abdominal_pain                 |        4 |\n",
      "|  40 | diarrhoea                      |        6 |\n",
      "|  41 | mild_fever                     |        5 |\n",
      "|  42 | yellow_urine                   |        4 |\n",
      "|  43 | yellowing_of_eyes              |        4 |\n",
      "|  44 | acute_liver_failure            |        6 |\n",
      "|  45 | fluid_overload                 |        6 |\n",
      "|  46 | swelling_of_stomach            |        7 |\n",
      "|  47 | swelled_lymph_nodes            |        6 |\n",
      "|  48 | malaise                        |        6 |\n",
      "|  49 | blurred_and_distorted_vision   |        5 |\n",
      "|  50 | phlegm                         |        5 |\n",
      "|  51 | throat_irritation              |        4 |\n",
      "|  52 | redness_of_eyes                |        5 |\n",
      "|  53 | sinus_pressure                 |        4 |\n",
      "|  54 | runny_nose                     |        5 |\n",
      "|  55 | congestion                     |        5 |\n",
      "|  56 | chest_pain                     |        7 |\n",
      "|  57 | weakness_in_limbs              |        7 |\n",
      "|  58 | fast_heart_rate                |        5 |\n",
      "|  59 | pain_during_bowel_movements    |        5 |\n",
      "|  60 | pain_in_anal_region            |        6 |\n",
      "|  61 | bloody_stool                   |        5 |\n",
      "|  62 | irritation_in_anus             |        6 |\n",
      "|  63 | neck_pain                      |        5 |\n",
      "|  64 | dizziness                      |        4 |\n",
      "|  65 | cramps                         |        4 |\n",
      "|  66 | bruising                       |        4 |\n",
      "|  67 | obesity                        |        4 |\n",
      "|  68 | swollen_legs                   |        5 |\n",
      "|  69 | swollen_blood_vessels          |        5 |\n",
      "|  70 | puffy_face_and_eyes            |        5 |\n",
      "|  71 | enlarged_thyroid               |        6 |\n",
      "|  72 | brittle_nails                  |        5 |\n",
      "|  73 | swollen_extremeties            |        5 |\n",
      "|  74 | excessive_hunger               |        4 |\n",
      "|  75 | extra_marital_contacts         |        5 |\n",
      "|  76 | drying_and_tingling_lips       |        4 |\n",
      "|  77 | slurred_speech                 |        4 |\n",
      "|  78 | knee_pain                      |        3 |\n",
      "|  79 | hip_joint_pain                 |        2 |\n",
      "|  80 | muscle_weakness                |        2 |\n",
      "|  81 | stiff_neck                     |        4 |\n",
      "|  82 | swelling_joints                |        5 |\n",
      "|  83 | movement_stiffness             |        5 |\n",
      "|  84 | spinning_movements             |        6 |\n",
      "|  85 | loss_of_balance                |        4 |\n",
      "|  86 | unsteadiness                   |        4 |\n",
      "|  87 | weakness_of_one_body_side      |        4 |\n",
      "|  88 | loss_of_smell                  |        3 |\n",
      "|  89 | bladder_discomfort             |        4 |\n",
      "|  90 | foul_smell_ofurine             |        5 |\n",
      "|  91 | continuous_feel_of_urine       |        6 |\n",
      "|  92 | passage_of_gases               |        5 |\n",
      "|  93 | internal_itching               |        4 |\n",
      "|  94 | toxic_look_(typhos)            |        5 |\n",
      "|  95 | depression                     |        3 |\n",
      "|  96 | irritability                   |        2 |\n",
      "|  97 | muscle_pain                    |        2 |\n",
      "|  98 | altered_sensorium              |        2 |\n",
      "|  99 | red_spots_over_body            |        3 |\n",
      "| 100 | belly_pain                     |        4 |\n",
      "| 101 | abnormal_menstruation          |        6 |\n",
      "| 102 | dischromic_patches             |        6 |\n",
      "| 103 | watering_from_eyes             |        4 |\n",
      "| 104 | increased_appetite             |        5 |\n",
      "| 105 | polyuria                       |        4 |\n",
      "| 106 | family_history                 |        5 |\n",
      "| 107 | mucoid_sputum                  |        4 |\n",
      "| 108 | rusty_sputum                   |        4 |\n",
      "| 109 | lack_of_concentration          |        3 |\n",
      "| 110 | visual_disturbances            |        3 |\n",
      "| 111 | receiving_blood_transfusion    |        5 |\n",
      "| 112 | receiving_unsterile_injections |        2 |\n",
      "| 113 | coma                           |        7 |\n",
      "| 114 | stomach_bleeding               |        6 |\n",
      "| 115 | distention_of_abdomen          |        4 |\n",
      "| 116 | history_of_alcohol_consumption |        5 |\n",
      "| 117 | fluid_overload                 |        4 |\n",
      "| 118 | blood_in_sputum                |        5 |\n",
      "| 119 | prominent_veins_on_calf        |        6 |\n",
      "| 120 | palpitations                   |        4 |\n",
      "| 121 | painful_walking                |        2 |\n",
      "| 122 | pus_filled_pimples             |        2 |\n",
      "| 123 | blackheads                     |        2 |\n",
      "| 124 | scurring                       |        2 |\n",
      "| 125 | skin_peeling                   |        3 |\n",
      "| 126 | silver_like_dusting            |        2 |\n",
      "| 127 | small_dents_in_nails           |        2 |\n",
      "| 128 | inflammatory_nails             |        2 |\n",
      "| 129 | blister                        |        4 |\n",
      "| 130 | red_sore_around_nose           |        2 |\n",
      "| 131 | yellow_crust_ooze              |        3 |\n",
      "| 132 | prognosis                      |        5 |\n"
     ]
    }
   ],
   "source": [
    "print(df2.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moin2\\AppData\\Local\\Temp\\ipykernel_2560\\1593813174.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1['Symptom_4'].fillna('',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df1['Symptom_4'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Symptoms']=df1['Symptom_1']+','+df1['Symptom_2']+','+df1['Symptom_3']+','+df1['Symptom_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[['Symptoms','Disease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Symptoms']=df1['Symptoms'].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>vomiting, headache, nausea, spinning movements</td>\n",
       "      <td>(vertigo) Paroymsal  Positional Vertigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>skin rash, pus filled pimples, blackheads, sc...</td>\n",
       "      <td>Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>burning micturition, bladder discomfort, foul...</td>\n",
       "      <td>Urinary tract infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>skin rash, joint pain, skin peeling, silver l...</td>\n",
       "      <td>Psoriasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>skin rash, high fever, blister, red sore arou...</td>\n",
       "      <td>Impetigo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Symptoms  \\\n",
       "4915     vomiting, headache, nausea, spinning movements   \n",
       "4916   skin rash, pus filled pimples, blackheads, sc...   \n",
       "4917   burning micturition, bladder discomfort, foul...   \n",
       "4918   skin rash, joint pain, skin peeling, silver l...   \n",
       "4919   skin rash, high fever, blister, red sore arou...   \n",
       "\n",
       "                                      Disease  \n",
       "4915  (vertigo) Paroymsal  Positional Vertigo  \n",
       "4916                                     Acne  \n",
       "4917                  Urinary tract infection  \n",
       "4918                                Psoriasis  \n",
       "4919                                 Impetigo  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptom</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>inflammatory_nails</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>blister</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>red_sore_around_nose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>yellow_crust_ooze</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>prognosis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Symptom  weight\n",
       "128    inflammatory_nails       2\n",
       "129               blister       4\n",
       "130  red_sore_around_nose       2\n",
       "131     yellow_crust_ooze       3\n",
       "132             prognosis       5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df2 into a dictionary: symptom -> weight\n",
    "severity_dict = dict(zip(df2['Symptom'], df2['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just want to check unique weights\n",
    "set(severity_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# 3. Preprocess Symptoms from df1\n",
    "# --------------------------------------\n",
    "def preprocess_symptoms(symptom_str):\n",
    "    \"\"\"\n",
    "    Converts comma-separated symptoms into a list of standardized tokens.\n",
    "    1) Lowercase\n",
    "    2) Trim spaces\n",
    "    3) Replace inner spaces with underscores\n",
    "    \"\"\"\n",
    "    # Split on commas\n",
    "    symptoms = symptom_str.lower().split(',')\n",
    "    # Clean each symptom token\n",
    "    symptoms = [s.strip().replace(' ', '_') for s in symptoms]\n",
    "    return symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in df1 with the list of symptoms\n",
    "\n",
    "df1['Symptom_list'] = df1['Symptoms'].apply(preprocess_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itching, skin rash, nodal skin eruptions, disc...</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, skin_rash, nodal_skin_eruptions, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin rash, nodal skin eruptions, dischromic  ...</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[skin_rash, nodal_skin_eruptions, dischromic__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itching, nodal skin eruptions, dischromic  pat...</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, nodal_skin_eruptions, dischromic__pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itching, skin rash, dischromic  patches,</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, skin_rash, dischromic__patches, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itching, skin rash, nodal skin eruptions,</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, skin_rash, nodal_skin_eruptions, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms           Disease  \\\n",
       "0  itching, skin rash, nodal skin eruptions, disc...  Fungal infection   \n",
       "1   skin rash, nodal skin eruptions, dischromic  ...  Fungal infection   \n",
       "2  itching, nodal skin eruptions, dischromic  pat...  Fungal infection   \n",
       "3           itching, skin rash, dischromic  patches,  Fungal infection   \n",
       "4          itching, skin rash, nodal skin eruptions,  Fungal infection   \n",
       "\n",
       "                                        Symptom_list  \n",
       "0  [itching, skin_rash, nodal_skin_eruptions, dis...  \n",
       "1  [skin_rash, nodal_skin_eruptions, dischromic__...  \n",
       "2  [itching, nodal_skin_eruptions, dischromic__pa...  \n",
       "3        [itching, skin_rash, dischromic__patches, ]  \n",
       "4       [itching, skin_rash, nodal_skin_eruptions, ]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 4. Tokenize the Symptoms (build a vocabulary)\n",
    "# ----------------------------------------------------\n",
    "# Flatten all symptom tokens to build a complete vocabulary\n",
    "\n",
    "all_symptoms = [sym for row in df1['Symptom_list'] for sym in row]\n",
    "\n",
    "tokenizer = Tokenizer(lower=True, filters='')  # no filters, since we've already cleaned\n",
    "tokenizer.fit_on_texts(all_symptoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 5. Convert Each List of Symptoms into Integer Sequences\n",
    "# ----------------------------------------------------\n",
    "# For each row, convert the list of symptom tokens into their integer IDs\n",
    "\n",
    "df1['Symptom_seq'] = df1['Symptom_list'].apply(lambda x: tokenizer.texts_to_sequences(x))\n",
    "\n",
    "# Flatten the list-of-lists for each row\n",
    "\n",
    "df1['Symptom_seq'] = df1['Symptom_seq'].apply(lambda seq: [item for sublist in seq for item in sublist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_list</th>\n",
       "      <th>Symptom_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itching, skin rash, nodal skin eruptions, disc...</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, skin_rash, nodal_skin_eruptions, dis...</td>\n",
       "      <td>[8, 5, 56, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin rash, nodal skin eruptions, dischromic  ...</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[skin_rash, nodal_skin_eruptions, dischromic__...</td>\n",
       "      <td>[5, 56, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itching, nodal skin eruptions, dischromic  pat...</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, nodal_skin_eruptions, dischromic__pa...</td>\n",
       "      <td>[8, 56, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itching, skin rash, dischromic  patches,</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, skin_rash, dischromic__patches, ]</td>\n",
       "      <td>[8, 5, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itching, skin rash, nodal skin eruptions,</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[itching, skin_rash, nodal_skin_eruptions, ]</td>\n",
       "      <td>[8, 5, 56]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms           Disease  \\\n",
       "0  itching, skin rash, nodal skin eruptions, disc...  Fungal infection   \n",
       "1   skin rash, nodal skin eruptions, dischromic  ...  Fungal infection   \n",
       "2  itching, nodal skin eruptions, dischromic  pat...  Fungal infection   \n",
       "3           itching, skin rash, dischromic  patches,  Fungal infection   \n",
       "4          itching, skin rash, nodal skin eruptions,  Fungal infection   \n",
       "\n",
       "                                        Symptom_list     Symptom_seq  \n",
       "0  [itching, skin_rash, nodal_skin_eruptions, dis...  [8, 5, 56, 57]  \n",
       "1  [skin_rash, nodal_skin_eruptions, dischromic__...     [5, 56, 57]  \n",
       "2  [itching, nodal_skin_eruptions, dischromic__pa...     [8, 56, 57]  \n",
       "3        [itching, skin_rash, dischromic__patches, ]      [8, 5, 57]  \n",
       "4       [itching, skin_rash, nodal_skin_eruptions, ]      [8, 5, 56]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_symptoms(row):\n",
    "    \"\"\"\n",
    "    Takes a row with 'Symptoms', 'Symptom_list', and 'Symptom_seq'.\n",
    "    Shuffles the symptom tokens (and corresponding token IDs) so that\n",
    "    the mapping between symptom and token ID remains consistent.\n",
    "    Returns new columns with the shuffled data.\n",
    "    \"\"\"\n",
    "    # Pair each token with its corresponding token ID\n",
    "    pairs = list(zip(row[\"Symptom_list\"], row[\"Symptom_seq\"]))\n",
    "\n",
    "    # Shuffle the (token, token_id) pairs in place\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    # Unzip the shuffled pairs back into separate lists\n",
    "    shuffled_symptoms, shuffled_seq = zip(*pairs)\n",
    "\n",
    "    # Reconstruct the \"Symptoms\" string by joining shuffled tokens with commas\n",
    "    shuffled_symptoms_str = \", \".join(shuffled_symptoms)\n",
    "\n",
    "    # Return a Series containing the shuffled versions\n",
    "    return pd.Series({\n",
    "        \"Shuffled_Symptoms\": shuffled_symptoms_str,\n",
    "        \"Shuffled_Symptom_list\": list(shuffled_symptoms),\n",
    "        \"Shuffled_Symptom_seq\": list(shuffled_seq)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the shuffle function row-by-row\n",
    "df1[[\"Shuffled_Symptoms\", \"Shuffled_Symptom_list\", \"Shuffled_Symptom_seq\"]] = df1.apply(shuffle_symptoms, axis=1)\n",
    "\n",
    "# Display the Disease column as well as original and shuffled columns\n",
    "df1[[\n",
    "    \"Symptoms\", \"Disease\", \"Symptom_list\", \"Symptom_seq\",\n",
    "    \"Shuffled_Symptoms\", \"Shuffled_Symptom_list\", \"Shuffled_Symptom_seq\"\n",
    "]].head()\n",
    "df1=df1.drop(columns={'Symptoms','Symptom_list','Symptom_seq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Shuffled_Symptoms</th>\n",
       "      <th>Shuffled_Symptom_list</th>\n",
       "      <th>Shuffled_Symptom_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>dischromic__patches, nodal_skin_eruptions, ski...</td>\n",
       "      <td>[dischromic__patches, nodal_skin_eruptions, sk...</td>\n",
       "      <td>[57, 56, 5, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>skin_rash, nodal_skin_eruptions, dischromic__p...</td>\n",
       "      <td>[skin_rash, nodal_skin_eruptions, dischromic__...</td>\n",
       "      <td>[5, 56, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>dischromic__patches, itching, nodal_skin_erupt...</td>\n",
       "      <td>[dischromic__patches, itching, nodal_skin_erup...</td>\n",
       "      <td>[57, 8, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching, skin_rash, dischromic__patches</td>\n",
       "      <td>[itching, skin_rash, dischromic__patches]</td>\n",
       "      <td>[8, 5, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching, nodal_skin_eruptions, skin_rash</td>\n",
       "      <td>[itching, nodal_skin_eruptions, skin_rash]</td>\n",
       "      <td>[8, 56, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Disease                                  Shuffled_Symptoms  \\\n",
       "0  Fungal infection  dischromic__patches, nodal_skin_eruptions, ski...   \n",
       "1  Fungal infection  skin_rash, nodal_skin_eruptions, dischromic__p...   \n",
       "2  Fungal infection  dischromic__patches, itching, nodal_skin_erupt...   \n",
       "3  Fungal infection            itching, skin_rash, dischromic__patches   \n",
       "4  Fungal infection           itching, nodal_skin_eruptions, skin_rash   \n",
       "\n",
       "                               Shuffled_Symptom_list Shuffled_Symptom_seq  \n",
       "0  [dischromic__patches, nodal_skin_eruptions, sk...       [57, 56, 5, 8]  \n",
       "1  [skin_rash, nodal_skin_eruptions, dischromic__...          [5, 56, 57]  \n",
       "2  [dischromic__patches, itching, nodal_skin_erup...          [57, 8, 56]  \n",
       "3          [itching, skin_rash, dischromic__patches]           [8, 5, 57]  \n",
       "4         [itching, nodal_skin_eruptions, skin_rash]           [8, 56, 5]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 6. Pad the Sequences\n",
    "# ----------------------------------------------------\n",
    "max_length = max(df1['Shuffled_Symptom_seq'].apply(len))  # maximum length of any symptom sequence\n",
    "X = pad_sequences(df1['Shuffled_Symptom_seq'], maxlen=max_length, padding='post', dtype='int32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 7. Encode Disease Labels\n",
    "# ----------------------------------------------------\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df1['Disease'])\n",
    "\n",
    "# Convert to one-hot vectors for a multi-class classification problem\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 8. Build a Weight Vector for the Vocabulary\n",
    "# ----------------------------------------------------\n",
    "# We'll create a numpy array, where each index corresponds to a token ID.\n",
    "# If a token is found in severity_dict, use that weight; otherwise, default to 1.\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "embedding_scaling = np.ones(vocab_size + 1, dtype=np.float32)  # +1 because index 0 is reserved (padding)\n",
    "\n",
    "for token, index in tokenizer.word_index.items():\n",
    "    if token in severity_dict:\n",
    "        embedding_scaling[index] = severity_dict[token]\n",
    "    else:\n",
    "        embedding_scaling[index] = 1.0  # default severity weight\n",
    "\n",
    "# Convert it to a constant tensor so it won't be trainable\n",
    "embedding_scaling = tf.constant(embedding_scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(embedding_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shuffled_Symptoms</th>\n",
       "      <th>Shuffled_Symptom_list</th>\n",
       "      <th>Shuffled_Symptom_seq</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dischromic__patches, nodal_skin_eruptions, ski...</td>\n",
       "      <td>[dischromic__patches, nodal_skin_eruptions, sk...</td>\n",
       "      <td>[57, 56, 5, 8]</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin_rash, nodal_skin_eruptions, dischromic__p...</td>\n",
       "      <td>[skin_rash, nodal_skin_eruptions, dischromic__...</td>\n",
       "      <td>[5, 56, 57]</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dischromic__patches, itching, nodal_skin_erupt...</td>\n",
       "      <td>[dischromic__patches, itching, nodal_skin_erup...</td>\n",
       "      <td>[57, 8, 56]</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itching, skin_rash, dischromic__patches</td>\n",
       "      <td>[itching, skin_rash, dischromic__patches]</td>\n",
       "      <td>[8, 5, 57]</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itching, nodal_skin_eruptions, skin_rash</td>\n",
       "      <td>[itching, nodal_skin_eruptions, skin_rash]</td>\n",
       "      <td>[8, 56, 5]</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Shuffled_Symptoms  \\\n",
       "0  dischromic__patches, nodal_skin_eruptions, ski...   \n",
       "1  skin_rash, nodal_skin_eruptions, dischromic__p...   \n",
       "2  dischromic__patches, itching, nodal_skin_erupt...   \n",
       "3            itching, skin_rash, dischromic__patches   \n",
       "4           itching, nodal_skin_eruptions, skin_rash   \n",
       "\n",
       "                               Shuffled_Symptom_list Shuffled_Symptom_seq  \\\n",
       "0  [dischromic__patches, nodal_skin_eruptions, sk...       [57, 56, 5, 8]   \n",
       "1  [skin_rash, nodal_skin_eruptions, dischromic__...          [5, 56, 57]   \n",
       "2  [dischromic__patches, itching, nodal_skin_erup...          [57, 8, 56]   \n",
       "3          [itching, skin_rash, dischromic__patches]           [8, 5, 57]   \n",
       "4         [itching, nodal_skin_eruptions, skin_rash]           [8, 56, 5]   \n",
       "\n",
       "            Disease  \n",
       "0  Fungal infection  \n",
       "1  Fungal infection  \n",
       "2  Fungal infection  \n",
       "3  Fungal infection  \n",
       "4  Fungal infection  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1[['Shuffled_Symptoms','Shuffled_Symptom_list','Shuffled_Symptom_seq','Disease']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptom</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin_rash</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continuous_sneezing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shivering</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Symptom  weight\n",
       "0               itching       1\n",
       "1             skin_rash       3\n",
       "2  nodal_skin_eruptions       4\n",
       "3   continuous_sneezing       4\n",
       "4             shivering       5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one way is to put most weighted symptoms in last and least weighted symptoms first so that LSTM\\n   remembers High weighted one in the sequence in this weights also used and LSTM also works fine try this \\n   Approach and see result\\n   in UI in First two selectbox user enters common symptoms and in last two most severe symptoms'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''' Here you Need to Think of a New Approach How to deal with further  Shuffled_Symptom_seq and weights'''\n",
    "'''one way is to put most weighted symptoms in last and least weighted symptoms first so that LSTM\n",
    "   remembers High weighted one in the sequence in this weights also used and LSTM also works fine try this \n",
    "   Approach and see result\n",
    "   in UI in First two selectbox user enters common symptoms and in last two most severe symptoms'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Can we here think of New Model also despite LSTMs and RNNs --- Yes we use Some of the Attention Mechanism alse\\n    Rather than juss stick to RNN and LSTMs'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Can we here think of New Model also despite LSTMs and RNNs --- Yes we use Some of the Attention Mechanism alse\n",
    "    Rather than juss stick to RNN and LSTMs'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary: {symptom: weight}\n",
    "weight_map = dict(zip(df2[\"Symptom\"], df2[\"weight\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'itching': 1,\n",
       " 'skin_rash': 3,\n",
       " 'nodal_skin_eruptions': 4,\n",
       " 'continuous_sneezing': 4,\n",
       " 'shivering': 5,\n",
       " 'chills': 3,\n",
       " 'joint_pain': 3,\n",
       " 'stomach_pain': 5,\n",
       " 'acidity': 3,\n",
       " 'ulcers_on_tongue': 4,\n",
       " 'muscle_wasting': 3,\n",
       " 'vomiting': 5,\n",
       " 'burning_micturition': 6,\n",
       " 'spotting_urination': 6,\n",
       " 'fatigue': 4,\n",
       " 'weight_gain': 3,\n",
       " 'anxiety': 4,\n",
       " 'cold_hands_and_feets': 5,\n",
       " 'mood_swings': 3,\n",
       " 'weight_loss': 3,\n",
       " 'restlessness': 5,\n",
       " 'lethargy': 2,\n",
       " 'patches_in_throat': 6,\n",
       " 'irregular_sugar_level': 5,\n",
       " 'cough': 4,\n",
       " 'high_fever': 7,\n",
       " 'sunken_eyes': 3,\n",
       " 'breathlessness': 4,\n",
       " 'sweating': 3,\n",
       " 'dehydration': 4,\n",
       " 'indigestion': 5,\n",
       " 'headache': 3,\n",
       " 'yellowish_skin': 3,\n",
       " 'dark_urine': 4,\n",
       " 'nausea': 5,\n",
       " 'loss_of_appetite': 4,\n",
       " 'pain_behind_the_eyes': 4,\n",
       " 'back_pain': 3,\n",
       " 'constipation': 4,\n",
       " 'abdominal_pain': 4,\n",
       " 'diarrhoea': 6,\n",
       " 'mild_fever': 5,\n",
       " 'yellow_urine': 4,\n",
       " 'yellowing_of_eyes': 4,\n",
       " 'acute_liver_failure': 6,\n",
       " 'fluid_overload': 4,\n",
       " 'swelling_of_stomach': 7,\n",
       " 'swelled_lymph_nodes': 6,\n",
       " 'malaise': 6,\n",
       " 'blurred_and_distorted_vision': 5,\n",
       " 'phlegm': 5,\n",
       " 'throat_irritation': 4,\n",
       " 'redness_of_eyes': 5,\n",
       " 'sinus_pressure': 4,\n",
       " 'runny_nose': 5,\n",
       " 'congestion': 5,\n",
       " 'chest_pain': 7,\n",
       " 'weakness_in_limbs': 7,\n",
       " 'fast_heart_rate': 5,\n",
       " 'pain_during_bowel_movements': 5,\n",
       " 'pain_in_anal_region': 6,\n",
       " 'bloody_stool': 5,\n",
       " 'irritation_in_anus': 6,\n",
       " 'neck_pain': 5,\n",
       " 'dizziness': 4,\n",
       " 'cramps': 4,\n",
       " 'bruising': 4,\n",
       " 'obesity': 4,\n",
       " 'swollen_legs': 5,\n",
       " 'swollen_blood_vessels': 5,\n",
       " 'puffy_face_and_eyes': 5,\n",
       " 'enlarged_thyroid': 6,\n",
       " 'brittle_nails': 5,\n",
       " 'swollen_extremeties': 5,\n",
       " 'excessive_hunger': 4,\n",
       " 'extra_marital_contacts': 5,\n",
       " 'drying_and_tingling_lips': 4,\n",
       " 'slurred_speech': 4,\n",
       " 'knee_pain': 3,\n",
       " 'hip_joint_pain': 2,\n",
       " 'muscle_weakness': 2,\n",
       " 'stiff_neck': 4,\n",
       " 'swelling_joints': 5,\n",
       " 'movement_stiffness': 5,\n",
       " 'spinning_movements': 6,\n",
       " 'loss_of_balance': 4,\n",
       " 'unsteadiness': 4,\n",
       " 'weakness_of_one_body_side': 4,\n",
       " 'loss_of_smell': 3,\n",
       " 'bladder_discomfort': 4,\n",
       " 'foul_smell_ofurine': 5,\n",
       " 'continuous_feel_of_urine': 6,\n",
       " 'passage_of_gases': 5,\n",
       " 'internal_itching': 4,\n",
       " 'toxic_look_(typhos)': 5,\n",
       " 'depression': 3,\n",
       " 'irritability': 2,\n",
       " 'muscle_pain': 2,\n",
       " 'altered_sensorium': 2,\n",
       " 'red_spots_over_body': 3,\n",
       " 'belly_pain': 4,\n",
       " 'abnormal_menstruation': 6,\n",
       " 'dischromic_patches': 6,\n",
       " 'watering_from_eyes': 4,\n",
       " 'increased_appetite': 5,\n",
       " 'polyuria': 4,\n",
       " 'family_history': 5,\n",
       " 'mucoid_sputum': 4,\n",
       " 'rusty_sputum': 4,\n",
       " 'lack_of_concentration': 3,\n",
       " 'visual_disturbances': 3,\n",
       " 'receiving_blood_transfusion': 5,\n",
       " 'receiving_unsterile_injections': 2,\n",
       " 'coma': 7,\n",
       " 'stomach_bleeding': 6,\n",
       " 'distention_of_abdomen': 4,\n",
       " 'history_of_alcohol_consumption': 5,\n",
       " 'blood_in_sputum': 5,\n",
       " 'prominent_veins_on_calf': 6,\n",
       " 'palpitations': 4,\n",
       " 'painful_walking': 2,\n",
       " 'pus_filled_pimples': 2,\n",
       " 'blackheads': 2,\n",
       " 'scurring': 2,\n",
       " 'skin_peeling': 3,\n",
       " 'silver_like_dusting': 2,\n",
       " 'small_dents_in_nails': 2,\n",
       " 'inflammatory_nails': 2,\n",
       " 'blister': 4,\n",
       " 'red_sore_around_nose': 2,\n",
       " 'yellow_crust_ooze': 3,\n",
       " 'prognosis': 5}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For any symptom not in weight_map, use a default weight of 0\n",
    "df1[\"Symptom_Weights\"] = df1[\"Shuffled_Symptom_list\"].apply(\n",
    "    lambda sym_list: [weight_map.get(sym,1) for sym in sym_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shuffled_Symptoms</th>\n",
       "      <th>Shuffled_Symptom_list</th>\n",
       "      <th>Shuffled_Symptom_seq</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dischromic__patches, nodal_skin_eruptions, ski...</td>\n",
       "      <td>[dischromic__patches, nodal_skin_eruptions, sk...</td>\n",
       "      <td>[57, 56, 5, 8]</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[1, 4, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin_rash, nodal_skin_eruptions, dischromic__p...</td>\n",
       "      <td>[skin_rash, nodal_skin_eruptions, dischromic__...</td>\n",
       "      <td>[5, 56, 57]</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[3, 4, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dischromic__patches, itching, nodal_skin_erupt...</td>\n",
       "      <td>[dischromic__patches, itching, nodal_skin_erup...</td>\n",
       "      <td>[57, 8, 56]</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itching, skin_rash, dischromic__patches</td>\n",
       "      <td>[itching, skin_rash, dischromic__patches]</td>\n",
       "      <td>[8, 5, 57]</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[1, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itching, nodal_skin_eruptions, skin_rash</td>\n",
       "      <td>[itching, nodal_skin_eruptions, skin_rash]</td>\n",
       "      <td>[8, 56, 5]</td>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>[1, 4, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Shuffled_Symptoms  \\\n",
       "0  dischromic__patches, nodal_skin_eruptions, ski...   \n",
       "1  skin_rash, nodal_skin_eruptions, dischromic__p...   \n",
       "2  dischromic__patches, itching, nodal_skin_erupt...   \n",
       "3            itching, skin_rash, dischromic__patches   \n",
       "4           itching, nodal_skin_eruptions, skin_rash   \n",
       "\n",
       "                               Shuffled_Symptom_list Shuffled_Symptom_seq  \\\n",
       "0  [dischromic__patches, nodal_skin_eruptions, sk...       [57, 56, 5, 8]   \n",
       "1  [skin_rash, nodal_skin_eruptions, dischromic__...          [5, 56, 57]   \n",
       "2  [dischromic__patches, itching, nodal_skin_erup...          [57, 8, 56]   \n",
       "3          [itching, skin_rash, dischromic__patches]           [8, 5, 57]   \n",
       "4         [itching, nodal_skin_eruptions, skin_rash]           [8, 56, 5]   \n",
       "\n",
       "            Disease Symptom_Weights  \n",
       "0  Fungal infection    [1, 4, 3, 1]  \n",
       "1  Fungal infection       [3, 4, 1]  \n",
       "2  Fungal infection       [1, 1, 4]  \n",
       "3  Fungal infection       [1, 3, 1]  \n",
       "4  Fungal infection       [1, 4, 3]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 5, 6, 2, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.weight.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[['Shuffled_Symptoms','Shuffled_Symptom_list','Symptom_Weights','Disease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shuffled_Symptoms</th>\n",
       "      <th>Shuffled_Symptom_list</th>\n",
       "      <th>Symptom_Weights</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>vomiting, headache, spinning_movements, nausea</td>\n",
       "      <td>[vomiting, headache, spinning_movements, nausea]</td>\n",
       "      <td>[5, 3, 6, 5]</td>\n",
       "      <td>(vertigo) Paroymsal  Positional Vertigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>skin_rash, pus_filled_pimples, blackheads, scu...</td>\n",
       "      <td>[skin_rash, pus_filled_pimples, blackheads, sc...</td>\n",
       "      <td>[3, 2, 2, 2]</td>\n",
       "      <td>Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>continuous_feel_of_urine, burning_micturition,...</td>\n",
       "      <td>[continuous_feel_of_urine, burning_micturition...</td>\n",
       "      <td>[6, 6, 1, 4]</td>\n",
       "      <td>Urinary tract infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>skin_peeling, joint_pain, skin_rash, silver_li...</td>\n",
       "      <td>[skin_peeling, joint_pain, skin_rash, silver_l...</td>\n",
       "      <td>[3, 3, 3, 2]</td>\n",
       "      <td>Psoriasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>skin_rash, high_fever, red_sore_around_nose, b...</td>\n",
       "      <td>[skin_rash, high_fever, red_sore_around_nose, ...</td>\n",
       "      <td>[3, 7, 2, 4]</td>\n",
       "      <td>Impetigo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Shuffled_Symptoms  \\\n",
       "4915     vomiting, headache, spinning_movements, nausea   \n",
       "4916  skin_rash, pus_filled_pimples, blackheads, scu...   \n",
       "4917  continuous_feel_of_urine, burning_micturition,...   \n",
       "4918  skin_peeling, joint_pain, skin_rash, silver_li...   \n",
       "4919  skin_rash, high_fever, red_sore_around_nose, b...   \n",
       "\n",
       "                                  Shuffled_Symptom_list Symptom_Weights  \\\n",
       "4915   [vomiting, headache, spinning_movements, nausea]    [5, 3, 6, 5]   \n",
       "4916  [skin_rash, pus_filled_pimples, blackheads, sc...    [3, 2, 2, 2]   \n",
       "4917  [continuous_feel_of_urine, burning_micturition...    [6, 6, 1, 4]   \n",
       "4918  [skin_peeling, joint_pain, skin_rash, silver_l...    [3, 3, 3, 2]   \n",
       "4919  [skin_rash, high_fever, red_sore_around_nose, ...    [3, 7, 2, 4]   \n",
       "\n",
       "                                      Disease  \n",
       "4915  (vertigo) Paroymsal  Positional Vertigo  \n",
       "4916                                     Acne  \n",
       "4917                  Urinary tract infection  \n",
       "4918                                Psoriasis  \n",
       "4919                                 Impetigo  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4920, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['Disease'].str.contains('Heart')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def safe_literal_eval(x):\n",
    "    # If it's already a list, return it as-is.\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    # Otherwise, try to evaluate the string representation\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {x}: {e}\")\n",
    "        return x\n",
    "\n",
    "# Apply the safe evaluation function to the Symptom_Weights column.\n",
    "df1['Symptom_Weights'] = df1['Symptom_Weights'].apply(safe_literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1, 4, 3, 1]\n",
       "1          [3, 4, 1]\n",
       "2          [1, 1, 4]\n",
       "3          [1, 3, 1]\n",
       "4          [1, 4, 3]\n",
       "            ...     \n",
       "4915    [5, 3, 6, 5]\n",
       "4916    [3, 2, 2, 2]\n",
       "4917    [6, 6, 1, 4]\n",
       "4918    [3, 3, 3, 2]\n",
       "4919    [3, 7, 2, 4]\n",
       "Name: Symptom_Weights, Length: 4920, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Symptom_Weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the symptoms: we assume they are a comma-separated string.\n",
    "# If needed, you can further process (strip spaces, etc.)\n",
    "df1['Symptom_Tokens'] = df1['Shuffled_Symptoms'].apply(lambda x: [sym.strip() for sym in x.split(',')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine maximum sequence length (number of symptoms per record)\n",
    "max_len = df1['Symptom_Tokens'].apply(len).max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer on the symptom tokens\n",
    "all_symptoms = df1['Symptom_Tokens'].tolist()\n",
    "# Flatten the list of tokens\n",
    "flat_symptoms = [sym for sublist in all_symptoms for sym in sublist]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(flat_symptoms)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each record's symptom tokens to sequences of integers\n",
    "df1['Symptom_Seq'] = df1['Symptom_Tokens'].apply(lambda tokens: tokenizer.texts_to_sequences(tokens))\n",
    "# texts_to_sequences returns list of lists, so flatten each record\n",
    "df1['Symptom_Seq'] = df1['Symptom_Seq'].apply(lambda seq_list: [item for sub in seq_list for item in sub])\n",
    "# Pad sequences to uniform length (pad with zeros)\n",
    "symptom_seqs = pad_sequences(df1['Symptom_Seq'], maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  4, 11, 13],\n",
       "       [ 4, 88, 86, 42],\n",
       "       [13, 87,  4, 88],\n",
       "       ...,\n",
       "       [ 5, 18, 75, 76],\n",
       "       [11, 77, 78, 79],\n",
       "       [82, 83, 84, 85]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptom_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 3, 1],\n",
       "       [3, 4, 1, 0],\n",
       "       [1, 1, 4, 0],\n",
       "       ...,\n",
       "       [6, 6, 1, 4],\n",
       "       [3, 3, 3, 2],\n",
       "       [3, 7, 2, 4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly, pad the weights. We assume weights are given in order.\n",
    "# If a record has fewer weights than max_len, pad with zeros.\n",
    "weights = np.array([np.pad(w, (0, max_len - len(w)), 'constant') for w in df1['Symptom_Weights']])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the disease labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df1['Disease'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "labels_cat = to_categorical(labels, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_symptoms_train, X_symptoms_test, X_weights_train, X_weights_test, y_train, y_test = train_test_split(\n",
    "    symptom_seqs, weights, labels_cat, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2. Build the LSTM Model\n",
    "# -------------------------\n",
    "embedding_dim = 512  # Adjust embedding size as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers\n",
    "symptoms_input = Input(shape=(max_len,), name=\"symptoms_input\")\n",
    "weights_input = Input(shape=(max_len,), name=\"weights_input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moin2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer for symptoms\n",
    "embedding_layer = Embedding(input_dim=vocab_size,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=max_len,\n",
    "                            name=\"symptom_embedding\")\n",
    "embedded_symptoms = embedding_layer(symptoms_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape weights to multiply with embedding output\n",
    "weights_reshaped = Reshape((max_len, 1), name=\"reshape_weights\")(weights_input)\n",
    "# Multiply embeddings by weights (element-wise multiplication)\n",
    "weighted_embedding = Multiply(name=\"weighted_embedding\")([embedded_symptoms, weights_reshaped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, np.int64(4), 512), dtype=float32, sparse=False, name=keras_tensor_2>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape weights to match the dimensions of the embeddings (for element-wise multiplication)\n",
    "weights_reshaped = Reshape((max_len, 1), name=\"reshape_weights\")(weights_input)\n",
    "\n",
    "# Multiply the embeddings by the corresponding weights\n",
    "weighted_embedding = Multiply(name=\"weighted_embedding\")([embedded_symptoms, weights_reshaped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer with recurrent_dropout to force the fallback (non-cuDNN) implementation\n",
    "lstm_out = LSTM(512, \n",
    "                activation='tanh', \n",
    "                recurrent_activation='sigmoid', \n",
    "                recurrent_dropout=0.2,  # This parameter forces the non-cuDNN kernel\n",
    "                name=\"lstm_layer\")(weighted_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a dense layer for further processing\n",
    "dense1 = Dense(128, activation='relu', name=\"dense_layer\")(lstm_out)\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output = Dense(num_classes, activation='softmax', name=\"output_layer\")(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ symptoms_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ weights_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ symptom_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,216</span> │ symptoms_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_weights     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ weights_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ weighted_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ symptom_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ reshape_weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ weighted_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ lstm_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,289</span> │ dense_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ symptoms_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ weights_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ symptom_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m73,216\u001b[0m │ symptoms_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_weights     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ weights_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ weighted_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ symptom_embeddin… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ reshape_weights[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,099,200\u001b[0m │ weighted_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m65,664\u001b[0m │ lstm_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)        │      \u001b[38;5;34m5,289\u001b[0m │ dense_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,243,369</span> (8.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,243,369\u001b[0m (8.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,243,369</span> (8.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,243,369\u001b[0m (8.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model = Model(inputs=[symptoms_input, weights_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.5593 - loss: 2.0758 - val_accuracy: 0.8959 - val_loss: 0.3127\n",
      "Epoch 2/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9060 - loss: 0.2672 - val_accuracy: 0.9492 - val_loss: 0.1989\n",
      "Epoch 3/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9307 - loss: 0.1717 - val_accuracy: 0.9264 - val_loss: 0.1914\n",
      "Epoch 4/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9308 - loss: 0.1675 - val_accuracy: 0.9492 - val_loss: 0.1902\n",
      "Epoch 5/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9433 - loss: 0.1357 - val_accuracy: 0.9213 - val_loss: 0.2281\n",
      "Epoch 6/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9470 - loss: 0.1326 - val_accuracy: 0.9239 - val_loss: 0.2386\n",
      "Epoch 7/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9390 - loss: 0.1366 - val_accuracy: 0.9264 - val_loss: 0.2159\n",
      "Epoch 8/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9481 - loss: 0.1212 - val_accuracy: 0.9365 - val_loss: 0.1683\n",
      "Epoch 9/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9532 - loss: 0.1081 - val_accuracy: 0.9391 - val_loss: 0.1858\n",
      "Epoch 10/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9503 - loss: 0.1226 - val_accuracy: 0.9467 - val_loss: 0.1624\n",
      "Epoch 11/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9581 - loss: 0.0989 - val_accuracy: 0.9543 - val_loss: 0.1514\n",
      "Epoch 12/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9648 - loss: 0.0843 - val_accuracy: 0.9467 - val_loss: 0.1656\n",
      "Epoch 13/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9530 - loss: 0.1019 - val_accuracy: 0.9391 - val_loss: 0.1762\n",
      "Epoch 14/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9528 - loss: 0.1045 - val_accuracy: 0.9594 - val_loss: 0.1580\n",
      "Epoch 15/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9614 - loss: 0.0970 - val_accuracy: 0.9391 - val_loss: 0.1773\n",
      "Epoch 16/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9508 - loss: 0.1476 - val_accuracy: 0.9340 - val_loss: 0.2138\n",
      "Epoch 17/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9566 - loss: 0.1167 - val_accuracy: 0.9365 - val_loss: 0.1648\n",
      "Epoch 18/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9578 - loss: 0.0926 - val_accuracy: 0.9467 - val_loss: 0.1647\n",
      "Epoch 19/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9627 - loss: 0.0878 - val_accuracy: 0.9492 - val_loss: 0.1420\n",
      "Epoch 20/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9661 - loss: 0.0696 - val_accuracy: 0.9492 - val_loss: 0.1998\n",
      "Epoch 21/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9559 - loss: 0.0877 - val_accuracy: 0.9518 - val_loss: 0.1581\n",
      "Epoch 22/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9674 - loss: 0.0763 - val_accuracy: 0.9518 - val_loss: 0.1570\n",
      "Epoch 23/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9620 - loss: 0.0791 - val_accuracy: 0.9467 - val_loss: 0.1494\n",
      "Epoch 24/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9639 - loss: 0.0782 - val_accuracy: 0.9543 - val_loss: 0.1645\n",
      "Epoch 25/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9633 - loss: 0.0846 - val_accuracy: 0.9365 - val_loss: 0.1749\n",
      "Epoch 26/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9590 - loss: 0.0807 - val_accuracy: 0.9518 - val_loss: 0.1622\n",
      "Epoch 27/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9636 - loss: 0.0782 - val_accuracy: 0.9467 - val_loss: 0.1684\n",
      "Epoch 28/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9656 - loss: 0.0735 - val_accuracy: 0.9467 - val_loss: 0.1697\n",
      "Epoch 29/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9638 - loss: 0.0787 - val_accuracy: 0.9645 - val_loss: 0.1599\n",
      "Epoch 30/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9620 - loss: 0.0793 - val_accuracy: 0.9467 - val_loss: 0.1952\n",
      "Epoch 31/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9707 - loss: 0.0697 - val_accuracy: 0.9569 - val_loss: 0.1719\n",
      "Epoch 32/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9616 - loss: 0.0893 - val_accuracy: 0.9518 - val_loss: 0.1622\n",
      "Epoch 33/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9579 - loss: 0.0826 - val_accuracy: 0.9442 - val_loss: 0.1602\n",
      "Epoch 34/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9642 - loss: 0.0772 - val_accuracy: 0.9518 - val_loss: 0.1597\n",
      "Epoch 35/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9603 - loss: 0.0817 - val_accuracy: 0.9518 - val_loss: 0.2060\n",
      "Epoch 36/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9660 - loss: 0.0697 - val_accuracy: 0.9492 - val_loss: 0.1996\n",
      "Epoch 37/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9603 - loss: 0.0978 - val_accuracy: 0.9569 - val_loss: 0.1823\n",
      "Epoch 38/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9706 - loss: 0.0705 - val_accuracy: 0.9543 - val_loss: 0.1835\n",
      "Epoch 39/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9694 - loss: 0.0649 - val_accuracy: 0.9619 - val_loss: 0.1773\n",
      "Epoch 40/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9635 - loss: 0.0778 - val_accuracy: 0.9518 - val_loss: 0.1857\n",
      "Epoch 41/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9648 - loss: 0.0759 - val_accuracy: 0.9442 - val_loss: 0.2287\n",
      "Epoch 42/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9643 - loss: 0.0846 - val_accuracy: 0.9492 - val_loss: 0.1954\n",
      "Epoch 43/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9663 - loss: 0.0715 - val_accuracy: 0.9518 - val_loss: 0.1822\n",
      "Epoch 44/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9709 - loss: 0.0623 - val_accuracy: 0.9442 - val_loss: 0.2071\n",
      "Epoch 45/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9611 - loss: 0.0768 - val_accuracy: 0.9442 - val_loss: 0.2089\n",
      "Epoch 46/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9705 - loss: 0.0616 - val_accuracy: 0.9594 - val_loss: 0.2005\n",
      "Epoch 47/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9638 - loss: 0.0703 - val_accuracy: 0.9569 - val_loss: 0.2114\n",
      "Epoch 48/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9724 - loss: 0.0611 - val_accuracy: 0.9416 - val_loss: 0.2107\n",
      "Epoch 49/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9663 - loss: 0.0696 - val_accuracy: 0.9315 - val_loss: 0.2600\n",
      "Epoch 50/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9741 - loss: 0.0726 - val_accuracy: 0.9594 - val_loss: 0.1816\n",
      "Epoch 51/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9700 - loss: 0.0632 - val_accuracy: 0.9695 - val_loss: 0.1887\n",
      "Epoch 52/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9730 - loss: 0.0589 - val_accuracy: 0.9619 - val_loss: 0.1894\n",
      "Epoch 53/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9660 - loss: 0.0699 - val_accuracy: 0.9569 - val_loss: 0.1896\n",
      "Epoch 54/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9640 - loss: 0.0730 - val_accuracy: 0.9645 - val_loss: 0.1825\n",
      "Epoch 55/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9718 - loss: 0.0621 - val_accuracy: 0.9492 - val_loss: 0.1914\n",
      "Epoch 56/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9659 - loss: 0.0797 - val_accuracy: 0.9467 - val_loss: 0.1871\n",
      "Epoch 57/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9722 - loss: 0.0580 - val_accuracy: 0.9467 - val_loss: 0.2077\n",
      "Epoch 58/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9760 - loss: 0.0602 - val_accuracy: 0.9569 - val_loss: 0.2000\n",
      "Epoch 59/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9736 - loss: 0.0558 - val_accuracy: 0.9442 - val_loss: 0.2062\n",
      "Epoch 60/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9740 - loss: 0.0580 - val_accuracy: 0.9619 - val_loss: 0.1775\n",
      "Epoch 61/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9704 - loss: 0.0661 - val_accuracy: 0.9518 - val_loss: 0.1947\n",
      "Epoch 62/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9666 - loss: 0.0721 - val_accuracy: 0.9695 - val_loss: 0.2010\n",
      "Epoch 63/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9722 - loss: 0.0558 - val_accuracy: 0.9594 - val_loss: 0.2068\n",
      "Epoch 64/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9748 - loss: 0.0549 - val_accuracy: 0.9467 - val_loss: 0.2258\n",
      "Epoch 65/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9721 - loss: 0.0650 - val_accuracy: 0.9619 - val_loss: 0.2057\n",
      "Epoch 66/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9625 - loss: 0.1213 - val_accuracy: 0.9543 - val_loss: 0.1706\n",
      "Epoch 67/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9659 - loss: 0.0768 - val_accuracy: 0.9442 - val_loss: 0.2078\n",
      "Epoch 68/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9707 - loss: 0.0694 - val_accuracy: 0.9619 - val_loss: 0.1639\n",
      "Epoch 69/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9735 - loss: 0.0621 - val_accuracy: 0.9543 - val_loss: 0.2056\n",
      "Epoch 70/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9686 - loss: 0.0580 - val_accuracy: 0.9543 - val_loss: 0.2029\n",
      "Epoch 71/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9796 - loss: 0.0494 - val_accuracy: 0.9619 - val_loss: 0.1910\n",
      "Epoch 72/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9713 - loss: 0.0596 - val_accuracy: 0.9670 - val_loss: 0.1899\n",
      "Epoch 73/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9742 - loss: 0.0551 - val_accuracy: 0.9543 - val_loss: 0.2004\n",
      "Epoch 74/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9752 - loss: 0.0506 - val_accuracy: 0.9695 - val_loss: 0.1881\n",
      "Epoch 75/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0439 - val_accuracy: 0.9645 - val_loss: 0.1971\n",
      "Epoch 76/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0398 - val_accuracy: 0.9619 - val_loss: 0.1830\n",
      "Epoch 77/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9813 - loss: 0.0389 - val_accuracy: 0.9569 - val_loss: 0.2051\n",
      "Epoch 78/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0484 - val_accuracy: 0.9619 - val_loss: 0.1945\n",
      "Epoch 79/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9697 - loss: 0.0761 - val_accuracy: 0.9619 - val_loss: 0.1915\n",
      "Epoch 80/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9767 - loss: 0.0763 - val_accuracy: 0.9543 - val_loss: 0.1960\n",
      "Epoch 81/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9745 - loss: 0.0538 - val_accuracy: 0.9543 - val_loss: 0.2171\n",
      "Epoch 82/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9752 - loss: 0.0588 - val_accuracy: 0.9543 - val_loss: 0.2140\n",
      "Epoch 83/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9764 - loss: 0.0565 - val_accuracy: 0.9594 - val_loss: 0.2017\n",
      "Epoch 84/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9770 - loss: 0.0490 - val_accuracy: 0.9645 - val_loss: 0.1915\n",
      "Epoch 85/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9722 - loss: 0.0589 - val_accuracy: 0.9645 - val_loss: 0.1999\n",
      "Epoch 86/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9714 - loss: 0.0592 - val_accuracy: 0.9543 - val_loss: 0.2099\n",
      "Epoch 87/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9788 - loss: 0.0489 - val_accuracy: 0.9619 - val_loss: 0.2093\n",
      "Epoch 88/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9703 - loss: 0.0704 - val_accuracy: 0.9670 - val_loss: 0.1664\n",
      "Epoch 89/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9776 - loss: 0.0565 - val_accuracy: 0.9518 - val_loss: 0.2070\n",
      "Epoch 90/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9750 - loss: 0.0526 - val_accuracy: 0.9518 - val_loss: 0.1967\n",
      "Epoch 91/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9765 - loss: 0.0461 - val_accuracy: 0.9569 - val_loss: 0.1893\n",
      "Epoch 92/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9746 - loss: 0.0491 - val_accuracy: 0.9619 - val_loss: 0.1857\n",
      "Epoch 93/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9706 - loss: 0.0722 - val_accuracy: 0.9619 - val_loss: 0.2018\n",
      "Epoch 94/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9708 - loss: 0.0674 - val_accuracy: 0.9569 - val_loss: 0.2090\n",
      "Epoch 95/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9705 - loss: 0.0751 - val_accuracy: 0.9695 - val_loss: 0.1876\n",
      "Epoch 96/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9782 - loss: 0.0501 - val_accuracy: 0.9543 - val_loss: 0.2048\n",
      "Epoch 97/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9774 - loss: 0.0536 - val_accuracy: 0.9619 - val_loss: 0.2053\n",
      "Epoch 98/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9759 - loss: 0.0575 - val_accuracy: 0.9543 - val_loss: 0.2047\n",
      "Epoch 99/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9732 - loss: 0.0629 - val_accuracy: 0.9645 - val_loss: 0.1911\n",
      "Epoch 100/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9800 - loss: 0.0425 - val_accuracy: 0.9645 - val_loss: 0.2006\n",
      "Epoch 101/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9786 - loss: 0.0426 - val_accuracy: 0.9619 - val_loss: 0.1973\n",
      "Epoch 102/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9798 - loss: 0.0450 - val_accuracy: 0.9670 - val_loss: 0.2095\n",
      "Epoch 103/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9792 - loss: 0.0447 - val_accuracy: 0.9645 - val_loss: 0.2151\n",
      "Epoch 104/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0368 - val_accuracy: 0.9543 - val_loss: 0.2126\n",
      "Epoch 105/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9732 - loss: 0.0569 - val_accuracy: 0.9619 - val_loss: 0.1971\n",
      "Epoch 106/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9686 - loss: 0.0688 - val_accuracy: 0.9645 - val_loss: 0.2222\n",
      "Epoch 107/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9750 - loss: 0.0560 - val_accuracy: 0.9619 - val_loss: 0.2171\n",
      "Epoch 108/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9780 - loss: 0.0462 - val_accuracy: 0.9670 - val_loss: 0.2246\n",
      "Epoch 109/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9760 - loss: 0.0563 - val_accuracy: 0.9569 - val_loss: 0.2252\n",
      "Epoch 110/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9799 - loss: 0.0466 - val_accuracy: 0.9619 - val_loss: 0.2274\n",
      "Epoch 111/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9765 - loss: 0.0523 - val_accuracy: 0.9518 - val_loss: 0.2205\n",
      "Epoch 112/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9782 - loss: 0.0478 - val_accuracy: 0.9670 - val_loss: 0.2053\n",
      "Epoch 113/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9772 - loss: 0.0482 - val_accuracy: 0.9695 - val_loss: 0.2141\n",
      "Epoch 114/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9818 - loss: 0.0400 - val_accuracy: 0.9645 - val_loss: 0.2058\n",
      "Epoch 115/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0385 - val_accuracy: 0.9695 - val_loss: 0.2063\n",
      "Epoch 116/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9797 - loss: 0.0472 - val_accuracy: 0.9645 - val_loss: 0.2420\n",
      "Epoch 117/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9742 - loss: 0.0631 - val_accuracy: 0.9594 - val_loss: 0.2133\n",
      "Epoch 118/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9763 - loss: 0.0523 - val_accuracy: 0.9695 - val_loss: 0.2130\n",
      "Epoch 119/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9742 - loss: 0.0551 - val_accuracy: 0.9543 - val_loss: 0.2151\n",
      "Epoch 120/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0477 - val_accuracy: 0.9645 - val_loss: 0.2124\n",
      "Epoch 121/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9787 - loss: 0.0400 - val_accuracy: 0.9670 - val_loss: 0.2252\n",
      "Epoch 122/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9847 - loss: 0.0332 - val_accuracy: 0.9619 - val_loss: 0.2167\n",
      "Epoch 123/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9804 - loss: 0.0471 - val_accuracy: 0.9695 - val_loss: 0.2138\n",
      "Epoch 124/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9751 - loss: 0.0475 - val_accuracy: 0.9594 - val_loss: 0.2395\n",
      "Epoch 125/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9754 - loss: 0.0567 - val_accuracy: 0.9695 - val_loss: 0.2145\n",
      "Epoch 126/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9765 - loss: 0.0535 - val_accuracy: 0.9518 - val_loss: 0.2319\n",
      "Epoch 127/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9781 - loss: 0.0462 - val_accuracy: 0.9670 - val_loss: 0.2339\n",
      "Epoch 128/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9746 - loss: 0.0546 - val_accuracy: 0.9543 - val_loss: 0.2190\n",
      "Epoch 129/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9771 - loss: 0.0505 - val_accuracy: 0.9645 - val_loss: 0.1953\n",
      "Epoch 130/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9806 - loss: 0.0446 - val_accuracy: 0.9645 - val_loss: 0.2098\n",
      "Epoch 131/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0374 - val_accuracy: 0.9695 - val_loss: 0.2190\n",
      "Epoch 132/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9853 - loss: 0.0323 - val_accuracy: 0.9645 - val_loss: 0.2216\n",
      "Epoch 133/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9851 - loss: 0.0323 - val_accuracy: 0.9670 - val_loss: 0.2136\n",
      "Epoch 134/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9819 - loss: 0.0413 - val_accuracy: 0.9492 - val_loss: 0.3166\n",
      "Epoch 135/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9687 - loss: 0.1003 - val_accuracy: 0.9518 - val_loss: 0.2552\n",
      "Epoch 136/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9714 - loss: 0.0709 - val_accuracy: 0.9645 - val_loss: 0.2104\n",
      "Epoch 137/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9809 - loss: 0.0456 - val_accuracy: 0.9645 - val_loss: 0.1997\n",
      "Epoch 138/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9793 - loss: 0.0422 - val_accuracy: 0.9569 - val_loss: 0.2321\n",
      "Epoch 139/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9755 - loss: 0.0502 - val_accuracy: 0.9619 - val_loss: 0.2157\n",
      "Epoch 140/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9784 - loss: 0.0538 - val_accuracy: 0.9619 - val_loss: 0.2160\n",
      "Epoch 141/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9776 - loss: 0.0435 - val_accuracy: 0.9670 - val_loss: 0.2026\n",
      "Epoch 142/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9837 - loss: 0.0346 - val_accuracy: 0.9594 - val_loss: 0.2147\n",
      "Epoch 143/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9796 - loss: 0.0392 - val_accuracy: 0.9645 - val_loss: 0.2151\n",
      "Epoch 144/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0362 - val_accuracy: 0.9543 - val_loss: 0.2140\n",
      "Epoch 145/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9810 - loss: 0.0459 - val_accuracy: 0.9645 - val_loss: 0.2247\n",
      "Epoch 146/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9807 - loss: 0.0436 - val_accuracy: 0.9619 - val_loss: 0.2091\n",
      "Epoch 147/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9720 - loss: 0.0534 - val_accuracy: 0.9543 - val_loss: 0.2829\n",
      "Epoch 148/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9794 - loss: 0.0468 - val_accuracy: 0.9645 - val_loss: 0.2143\n",
      "Epoch 149/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9806 - loss: 0.0503 - val_accuracy: 0.9670 - val_loss: 0.1992\n",
      "Epoch 150/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9785 - loss: 0.0510 - val_accuracy: 0.9619 - val_loss: 0.2174\n",
      "Epoch 151/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9750 - loss: 0.0536 - val_accuracy: 0.9569 - val_loss: 0.2305\n",
      "Epoch 152/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9784 - loss: 0.0694 - val_accuracy: 0.9619 - val_loss: 0.2074\n",
      "Epoch 153/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9826 - loss: 0.0459 - val_accuracy: 0.9645 - val_loss: 0.2190\n",
      "Epoch 154/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0449 - val_accuracy: 0.9645 - val_loss: 0.2012\n",
      "Epoch 155/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9795 - loss: 0.0448 - val_accuracy: 0.9670 - val_loss: 0.2226\n",
      "Epoch 156/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9802 - loss: 0.0489 - val_accuracy: 0.9670 - val_loss: 0.2238\n",
      "Epoch 157/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9757 - loss: 0.0536 - val_accuracy: 0.9619 - val_loss: 0.2342\n",
      "Epoch 158/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9735 - loss: 0.0683 - val_accuracy: 0.9645 - val_loss: 0.2033\n",
      "Epoch 159/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9785 - loss: 0.0487 - val_accuracy: 0.9543 - val_loss: 0.2112\n",
      "Epoch 160/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9777 - loss: 0.0464 - val_accuracy: 0.9695 - val_loss: 0.2034\n",
      "Epoch 161/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9812 - loss: 0.0395 - val_accuracy: 0.9645 - val_loss: 0.1891\n",
      "Epoch 162/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9780 - loss: 0.0448 - val_accuracy: 0.9543 - val_loss: 0.2102\n",
      "Epoch 163/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9755 - loss: 0.0453 - val_accuracy: 0.9670 - val_loss: 0.2077\n",
      "Epoch 164/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0395 - val_accuracy: 0.9670 - val_loss: 0.2142\n",
      "Epoch 165/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9794 - loss: 0.0396 - val_accuracy: 0.9670 - val_loss: 0.2058\n",
      "Epoch 166/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0308 - val_accuracy: 0.9670 - val_loss: 0.2147\n",
      "Epoch 167/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9846 - loss: 0.0343 - val_accuracy: 0.9670 - val_loss: 0.2085\n",
      "Epoch 168/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9796 - loss: 0.0435 - val_accuracy: 0.9670 - val_loss: 0.2173\n",
      "Epoch 169/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9843 - loss: 0.0328 - val_accuracy: 0.9670 - val_loss: 0.2173\n",
      "Epoch 170/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9853 - loss: 0.0327 - val_accuracy: 0.9695 - val_loss: 0.2245\n",
      "Epoch 171/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9814 - loss: 0.0382 - val_accuracy: 0.9670 - val_loss: 0.2083\n",
      "Epoch 172/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9807 - loss: 0.0384 - val_accuracy: 0.9645 - val_loss: 0.2313\n",
      "Epoch 173/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9807 - loss: 0.0405 - val_accuracy: 0.9619 - val_loss: 0.2245\n",
      "Epoch 174/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9773 - loss: 0.0544 - val_accuracy: 0.9619 - val_loss: 0.2551\n",
      "Epoch 175/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9754 - loss: 0.0572 - val_accuracy: 0.9518 - val_loss: 0.2467\n",
      "Epoch 176/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9735 - loss: 0.0627 - val_accuracy: 0.9670 - val_loss: 0.1969\n",
      "Epoch 177/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0396 - val_accuracy: 0.9645 - val_loss: 0.2270\n",
      "Epoch 178/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9752 - loss: 0.0572 - val_accuracy: 0.9670 - val_loss: 0.2078\n",
      "Epoch 179/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0416 - val_accuracy: 0.9670 - val_loss: 0.2076\n",
      "Epoch 180/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0361 - val_accuracy: 0.9670 - val_loss: 0.2072\n",
      "Epoch 181/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9859 - loss: 0.0360 - val_accuracy: 0.9416 - val_loss: 0.2394\n",
      "Epoch 182/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0421 - val_accuracy: 0.9645 - val_loss: 0.2003\n",
      "Epoch 183/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9814 - loss: 0.0358 - val_accuracy: 0.9670 - val_loss: 0.2063\n",
      "Epoch 184/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9774 - loss: 0.0387 - val_accuracy: 0.9721 - val_loss: 0.2018\n",
      "Epoch 185/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9812 - loss: 0.0331 - val_accuracy: 0.9695 - val_loss: 0.2145\n",
      "Epoch 186/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0360 - val_accuracy: 0.9645 - val_loss: 0.2155\n",
      "Epoch 187/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9772 - loss: 0.0403 - val_accuracy: 0.9670 - val_loss: 0.2142\n",
      "Epoch 188/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9796 - loss: 0.0469 - val_accuracy: 0.9670 - val_loss: 0.2093\n",
      "Epoch 189/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9808 - loss: 0.0404 - val_accuracy: 0.9645 - val_loss: 0.2304\n",
      "Epoch 190/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9734 - loss: 0.0898 - val_accuracy: 0.9670 - val_loss: 0.2467\n",
      "Epoch 191/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9757 - loss: 0.0627 - val_accuracy: 0.9695 - val_loss: 0.2527\n",
      "Epoch 192/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9753 - loss: 0.0501 - val_accuracy: 0.9670 - val_loss: 0.2513\n",
      "Epoch 193/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9857 - loss: 0.0310 - val_accuracy: 0.9695 - val_loss: 0.2472\n",
      "Epoch 194/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0354 - val_accuracy: 0.9695 - val_loss: 0.2600\n",
      "Epoch 195/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9827 - loss: 0.0378 - val_accuracy: 0.9670 - val_loss: 0.2644\n",
      "Epoch 196/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9829 - loss: 0.0352 - val_accuracy: 0.9569 - val_loss: 0.2639\n",
      "Epoch 197/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9785 - loss: 0.0410 - val_accuracy: 0.9594 - val_loss: 0.2518\n",
      "Epoch 198/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9705 - loss: 0.0533 - val_accuracy: 0.9670 - val_loss: 0.2569\n",
      "Epoch 199/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9772 - loss: 0.0477 - val_accuracy: 0.9619 - val_loss: 0.2373\n",
      "Epoch 200/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9826 - loss: 0.0359 - val_accuracy: 0.9670 - val_loss: 0.2503\n",
      "Epoch 201/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9812 - loss: 0.0500 - val_accuracy: 0.9645 - val_loss: 0.2507\n",
      "Epoch 202/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9784 - loss: 0.0410 - val_accuracy: 0.9645 - val_loss: 0.2649\n",
      "Epoch 203/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9818 - loss: 0.0405 - val_accuracy: 0.9594 - val_loss: 0.2857\n",
      "Epoch 204/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9775 - loss: 0.0487 - val_accuracy: 0.9518 - val_loss: 0.2591\n",
      "Epoch 205/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9793 - loss: 0.0475 - val_accuracy: 0.9670 - val_loss: 0.2565\n",
      "Epoch 206/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9806 - loss: 0.0399 - val_accuracy: 0.9645 - val_loss: 0.2550\n",
      "Epoch 207/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0385 - val_accuracy: 0.9645 - val_loss: 0.2515\n",
      "Epoch 208/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0329 - val_accuracy: 0.9645 - val_loss: 0.2669\n",
      "Epoch 209/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9789 - loss: 0.0474 - val_accuracy: 0.9619 - val_loss: 0.2603\n",
      "Epoch 210/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9758 - loss: 0.0585 - val_accuracy: 0.9670 - val_loss: 0.2067\n",
      "Epoch 211/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9760 - loss: 0.0546 - val_accuracy: 0.9645 - val_loss: 0.2123\n",
      "Epoch 212/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0415 - val_accuracy: 0.9569 - val_loss: 0.2229\n",
      "Epoch 213/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9877 - loss: 0.0310 - val_accuracy: 0.9645 - val_loss: 0.2116\n",
      "Epoch 214/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0335 - val_accuracy: 0.9645 - val_loss: 0.2398\n",
      "Epoch 215/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9776 - loss: 0.0387 - val_accuracy: 0.9695 - val_loss: 0.2387\n",
      "Epoch 216/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0332 - val_accuracy: 0.9721 - val_loss: 0.2324\n",
      "Epoch 217/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9811 - loss: 0.0341 - val_accuracy: 0.9695 - val_loss: 0.2224\n",
      "Epoch 218/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0359 - val_accuracy: 0.9695 - val_loss: 0.2435\n",
      "Epoch 219/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9851 - loss: 0.0336 - val_accuracy: 0.9695 - val_loss: 0.2481\n",
      "Epoch 220/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9815 - loss: 0.0362 - val_accuracy: 0.9670 - val_loss: 0.2446\n",
      "Epoch 221/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9838 - loss: 0.0315 - val_accuracy: 0.9594 - val_loss: 0.2600\n",
      "Epoch 222/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9827 - loss: 0.0386 - val_accuracy: 0.9619 - val_loss: 0.2883\n",
      "Epoch 223/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0478 - val_accuracy: 0.9594 - val_loss: 0.2659\n",
      "Epoch 224/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9776 - loss: 0.0488 - val_accuracy: 0.9619 - val_loss: 0.2629\n",
      "Epoch 225/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9826 - loss: 0.0386 - val_accuracy: 0.9695 - val_loss: 0.2506\n",
      "Epoch 226/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9835 - loss: 0.0318 - val_accuracy: 0.9670 - val_loss: 0.2592\n",
      "Epoch 227/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9825 - loss: 0.0375 - val_accuracy: 0.9645 - val_loss: 0.2633\n",
      "Epoch 228/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9826 - loss: 0.0378 - val_accuracy: 0.9645 - val_loss: 0.2475\n",
      "Epoch 229/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9784 - loss: 0.0465 - val_accuracy: 0.9670 - val_loss: 0.2508\n",
      "Epoch 230/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9711 - loss: 0.0896 - val_accuracy: 0.9619 - val_loss: 0.2352\n",
      "Epoch 231/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9778 - loss: 0.0455 - val_accuracy: 0.9670 - val_loss: 0.2188\n",
      "Epoch 232/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9761 - loss: 0.0535 - val_accuracy: 0.9442 - val_loss: 0.2945\n",
      "Epoch 233/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9785 - loss: 0.0551 - val_accuracy: 0.9670 - val_loss: 0.2119\n",
      "Epoch 234/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9810 - loss: 0.0409 - val_accuracy: 0.9670 - val_loss: 0.2311\n",
      "Epoch 235/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9805 - loss: 0.0439 - val_accuracy: 0.9594 - val_loss: 0.2553\n",
      "Epoch 236/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0346 - val_accuracy: 0.9670 - val_loss: 0.2253\n",
      "Epoch 237/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9813 - loss: 0.0418 - val_accuracy: 0.9670 - val_loss: 0.2355\n",
      "Epoch 238/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9790 - loss: 0.0443 - val_accuracy: 0.9695 - val_loss: 0.2303\n",
      "Epoch 239/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9750 - loss: 0.0460 - val_accuracy: 0.9670 - val_loss: 0.2446\n",
      "Epoch 240/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0382 - val_accuracy: 0.9670 - val_loss: 0.2347\n",
      "Epoch 241/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9831 - loss: 0.0353 - val_accuracy: 0.9695 - val_loss: 0.2359\n",
      "Epoch 242/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0374 - val_accuracy: 0.9670 - val_loss: 0.2583\n",
      "Epoch 243/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9800 - loss: 0.0405 - val_accuracy: 0.9670 - val_loss: 0.2600\n",
      "Epoch 244/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9754 - loss: 0.0471 - val_accuracy: 0.9645 - val_loss: 0.2539\n",
      "Epoch 245/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9740 - loss: 0.0476 - val_accuracy: 0.9619 - val_loss: 0.2533\n",
      "Epoch 246/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9796 - loss: 0.0441 - val_accuracy: 0.9670 - val_loss: 0.2269\n",
      "Epoch 247/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9720 - loss: 0.0896 - val_accuracy: 0.9670 - val_loss: 0.2229\n",
      "Epoch 248/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9819 - loss: 0.0399 - val_accuracy: 0.9670 - val_loss: 0.2310\n",
      "Epoch 249/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9802 - loss: 0.0415 - val_accuracy: 0.9695 - val_loss: 0.2175\n",
      "Epoch 250/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0343 - val_accuracy: 0.9695 - val_loss: 0.2212\n",
      "Epoch 251/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9813 - loss: 0.0407 - val_accuracy: 0.9619 - val_loss: 0.2029\n",
      "Epoch 252/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9803 - loss: 0.0421 - val_accuracy: 0.9695 - val_loss: 0.2034\n",
      "Epoch 253/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9831 - loss: 0.0399 - val_accuracy: 0.9695 - val_loss: 0.2157\n",
      "Epoch 254/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0364 - val_accuracy: 0.9695 - val_loss: 0.2258\n",
      "Epoch 255/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0323 - val_accuracy: 0.9695 - val_loss: 0.2306\n",
      "Epoch 256/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9829 - loss: 0.0329 - val_accuracy: 0.9670 - val_loss: 0.2255\n",
      "Epoch 257/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0346 - val_accuracy: 0.9670 - val_loss: 0.2441\n",
      "Epoch 258/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0390 - val_accuracy: 0.9619 - val_loss: 0.1996\n",
      "Epoch 259/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9647 - loss: 0.0890 - val_accuracy: 0.9594 - val_loss: 0.2268\n",
      "Epoch 260/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9695 - loss: 0.0652 - val_accuracy: 0.9645 - val_loss: 0.2451\n",
      "Epoch 261/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9754 - loss: 0.0574 - val_accuracy: 0.9518 - val_loss: 0.2743\n",
      "Epoch 262/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9724 - loss: 0.0596 - val_accuracy: 0.9670 - val_loss: 0.2357\n",
      "Epoch 263/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9821 - loss: 0.0399 - val_accuracy: 0.9721 - val_loss: 0.2351\n",
      "Epoch 264/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0431 - val_accuracy: 0.9695 - val_loss: 0.2239\n",
      "Epoch 265/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9817 - loss: 0.0404 - val_accuracy: 0.9695 - val_loss: 0.2347\n",
      "Epoch 266/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9763 - loss: 0.0456 - val_accuracy: 0.9594 - val_loss: 0.2488\n",
      "Epoch 267/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9766 - loss: 0.0426 - val_accuracy: 0.9543 - val_loss: 0.2522\n",
      "Epoch 268/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9804 - loss: 0.0447 - val_accuracy: 0.9721 - val_loss: 0.2244\n",
      "Epoch 269/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9851 - loss: 0.0324 - val_accuracy: 0.9721 - val_loss: 0.2199\n",
      "Epoch 270/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9814 - loss: 0.0421 - val_accuracy: 0.9695 - val_loss: 0.2286\n",
      "Epoch 271/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9852 - loss: 0.0333 - val_accuracy: 0.9670 - val_loss: 0.2486\n",
      "Epoch 272/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9880 - loss: 0.0293 - val_accuracy: 0.9695 - val_loss: 0.2291\n",
      "Epoch 273/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9860 - loss: 0.0275 - val_accuracy: 0.9721 - val_loss: 0.2621\n",
      "Epoch 274/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9815 - loss: 0.0399 - val_accuracy: 0.9721 - val_loss: 0.2437\n",
      "Epoch 275/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9815 - loss: 0.0462 - val_accuracy: 0.9645 - val_loss: 0.2523\n",
      "Epoch 276/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9814 - loss: 0.0403 - val_accuracy: 0.9670 - val_loss: 0.2393\n",
      "Epoch 277/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9815 - loss: 0.0385 - val_accuracy: 0.9695 - val_loss: 0.2430\n",
      "Epoch 278/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9810 - loss: 0.0344 - val_accuracy: 0.9619 - val_loss: 0.2580\n",
      "Epoch 279/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9839 - loss: 0.0365 - val_accuracy: 0.9695 - val_loss: 0.2388\n",
      "Epoch 280/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0376 - val_accuracy: 0.9695 - val_loss: 0.2574\n",
      "Epoch 281/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9873 - loss: 0.0352 - val_accuracy: 0.9645 - val_loss: 0.2676\n",
      "Epoch 282/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9803 - loss: 0.0500 - val_accuracy: 0.9619 - val_loss: 0.2184\n",
      "Epoch 283/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9754 - loss: 0.0535 - val_accuracy: 0.9670 - val_loss: 0.2650\n",
      "Epoch 284/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9773 - loss: 0.0585 - val_accuracy: 0.9645 - val_loss: 0.2691\n",
      "Epoch 285/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9768 - loss: 0.0461 - val_accuracy: 0.9619 - val_loss: 0.2773\n",
      "Epoch 286/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9804 - loss: 0.0511 - val_accuracy: 0.9670 - val_loss: 0.2143\n",
      "Epoch 287/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9805 - loss: 0.0432 - val_accuracy: 0.9695 - val_loss: 0.2470\n",
      "Epoch 288/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9821 - loss: 0.0401 - val_accuracy: 0.9695 - val_loss: 0.2442\n",
      "Epoch 289/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0350 - val_accuracy: 0.9721 - val_loss: 0.2297\n",
      "Epoch 290/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9782 - loss: 0.0419 - val_accuracy: 0.9695 - val_loss: 0.2685\n",
      "Epoch 291/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0344 - val_accuracy: 0.9670 - val_loss: 0.2647\n",
      "Epoch 292/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0361 - val_accuracy: 0.9619 - val_loss: 0.2571\n",
      "Epoch 293/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0334 - val_accuracy: 0.9695 - val_loss: 0.2678\n",
      "Epoch 294/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9807 - loss: 0.0440 - val_accuracy: 0.9645 - val_loss: 0.2531\n",
      "Epoch 295/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9820 - loss: 0.0397 - val_accuracy: 0.9670 - val_loss: 0.2565\n",
      "Epoch 296/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9827 - loss: 0.0352 - val_accuracy: 0.9695 - val_loss: 0.2618\n",
      "Epoch 297/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9817 - loss: 0.0369 - val_accuracy: 0.9670 - val_loss: 0.2653\n",
      "Epoch 298/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9865 - loss: 0.0305 - val_accuracy: 0.9695 - val_loss: 0.2576\n",
      "Epoch 299/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9829 - loss: 0.0374 - val_accuracy: 0.9670 - val_loss: 0.2560\n",
      "Epoch 300/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9821 - loss: 0.0379 - val_accuracy: 0.9721 - val_loss: 0.2561\n",
      "Epoch 301/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9801 - loss: 0.0388 - val_accuracy: 0.9695 - val_loss: 0.2773\n",
      "Epoch 302/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9801 - loss: 0.0410 - val_accuracy: 0.9695 - val_loss: 0.3085\n",
      "Epoch 303/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9772 - loss: 0.0560 - val_accuracy: 0.9569 - val_loss: 0.2201\n",
      "Epoch 304/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9680 - loss: 0.0845 - val_accuracy: 0.9391 - val_loss: 0.2078\n",
      "Epoch 305/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9686 - loss: 0.0741 - val_accuracy: 0.9746 - val_loss: 0.1618\n",
      "Epoch 306/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9786 - loss: 0.0462 - val_accuracy: 0.9721 - val_loss: 0.1947\n",
      "Epoch 307/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9818 - loss: 0.0352 - val_accuracy: 0.9645 - val_loss: 0.2046\n",
      "Epoch 308/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9765 - loss: 0.0479 - val_accuracy: 0.9695 - val_loss: 0.1958\n",
      "Epoch 309/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0379 - val_accuracy: 0.9695 - val_loss: 0.2120\n",
      "Epoch 310/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9827 - loss: 0.0387 - val_accuracy: 0.9670 - val_loss: 0.2290\n",
      "Epoch 311/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0383 - val_accuracy: 0.9619 - val_loss: 0.2161\n",
      "Epoch 312/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9811 - loss: 0.0346 - val_accuracy: 0.9670 - val_loss: 0.2107\n",
      "Epoch 313/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9833 - loss: 0.0338 - val_accuracy: 0.9721 - val_loss: 0.2065\n",
      "Epoch 314/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9782 - loss: 0.0369 - val_accuracy: 0.9695 - val_loss: 0.2061\n",
      "Epoch 315/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9820 - loss: 0.0357 - val_accuracy: 0.9721 - val_loss: 0.2044\n",
      "Epoch 316/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9818 - loss: 0.0393 - val_accuracy: 0.9721 - val_loss: 0.2143\n",
      "Epoch 317/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9856 - loss: 0.0318 - val_accuracy: 0.9695 - val_loss: 0.2218\n",
      "Epoch 318/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9839 - loss: 0.0313 - val_accuracy: 0.9721 - val_loss: 0.2202\n",
      "Epoch 319/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9844 - loss: 0.0333 - val_accuracy: 0.9721 - val_loss: 0.2219\n",
      "Epoch 320/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9820 - loss: 0.0328 - val_accuracy: 0.9721 - val_loss: 0.2361\n",
      "Epoch 321/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0338 - val_accuracy: 0.9721 - val_loss: 0.2308\n",
      "Epoch 322/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9821 - loss: 0.0356 - val_accuracy: 0.9721 - val_loss: 0.2144\n",
      "Epoch 323/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0412 - val_accuracy: 0.9619 - val_loss: 0.2279\n",
      "Epoch 324/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9763 - loss: 0.0533 - val_accuracy: 0.9721 - val_loss: 0.2223\n",
      "Epoch 325/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9803 - loss: 0.0430 - val_accuracy: 0.9695 - val_loss: 0.2297\n",
      "Epoch 326/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9845 - loss: 0.0352 - val_accuracy: 0.9645 - val_loss: 0.2064\n",
      "Epoch 327/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9832 - loss: 0.0346 - val_accuracy: 0.9721 - val_loss: 0.2231\n",
      "Epoch 328/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9840 - loss: 0.0358 - val_accuracy: 0.9721 - val_loss: 0.2253\n",
      "Epoch 329/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9864 - loss: 0.0312 - val_accuracy: 0.9721 - val_loss: 0.2161\n",
      "Epoch 330/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9862 - loss: 0.0290 - val_accuracy: 0.9721 - val_loss: 0.2208\n",
      "Epoch 331/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9779 - loss: 0.0411 - val_accuracy: 0.9721 - val_loss: 0.2230\n",
      "Epoch 332/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9832 - loss: 0.0326 - val_accuracy: 0.9670 - val_loss: 0.2378\n",
      "Epoch 333/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0424 - val_accuracy: 0.9645 - val_loss: 0.2400\n",
      "Epoch 334/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9767 - loss: 0.0648 - val_accuracy: 0.9645 - val_loss: 0.1900\n",
      "Epoch 335/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9801 - loss: 0.0424 - val_accuracy: 0.9695 - val_loss: 0.2178\n",
      "Epoch 336/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9769 - loss: 0.0457 - val_accuracy: 0.9670 - val_loss: 0.2119\n",
      "Epoch 337/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0365 - val_accuracy: 0.9645 - val_loss: 0.2025\n",
      "Epoch 338/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9844 - loss: 0.0289 - val_accuracy: 0.9619 - val_loss: 0.2174\n",
      "Epoch 339/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0356 - val_accuracy: 0.9721 - val_loss: 0.1995\n",
      "Epoch 340/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9789 - loss: 0.0448 - val_accuracy: 0.9695 - val_loss: 0.1986\n",
      "Epoch 341/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0363 - val_accuracy: 0.9594 - val_loss: 0.1992\n",
      "Epoch 342/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9841 - loss: 0.0324 - val_accuracy: 0.9492 - val_loss: 0.2433\n",
      "Epoch 343/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9787 - loss: 0.0390 - val_accuracy: 0.9594 - val_loss: 0.2539\n",
      "Epoch 344/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9827 - loss: 0.0375 - val_accuracy: 0.9645 - val_loss: 0.2207\n",
      "Epoch 345/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9785 - loss: 0.0405 - val_accuracy: 0.9695 - val_loss: 0.2187\n",
      "Epoch 346/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0349 - val_accuracy: 0.9695 - val_loss: 0.2105\n",
      "Epoch 347/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0355 - val_accuracy: 0.9695 - val_loss: 0.2097\n",
      "Epoch 348/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9814 - loss: 0.0395 - val_accuracy: 0.9670 - val_loss: 0.2131\n",
      "Epoch 349/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9841 - loss: 0.0310 - val_accuracy: 0.9695 - val_loss: 0.2199\n",
      "Epoch 350/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9833 - loss: 0.0347 - val_accuracy: 0.9721 - val_loss: 0.2202\n",
      "Epoch 351/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9770 - loss: 0.0622 - val_accuracy: 0.9594 - val_loss: 0.2240\n",
      "Epoch 352/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9703 - loss: 0.0663 - val_accuracy: 0.9619 - val_loss: 0.1895\n",
      "Epoch 353/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9749 - loss: 0.0542 - val_accuracy: 0.9695 - val_loss: 0.1877\n",
      "Epoch 354/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9789 - loss: 0.0443 - val_accuracy: 0.9695 - val_loss: 0.2262\n",
      "Epoch 355/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0370 - val_accuracy: 0.9645 - val_loss: 0.2308\n",
      "Epoch 356/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0404 - val_accuracy: 0.9695 - val_loss: 0.2328\n",
      "Epoch 357/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9840 - loss: 0.0335 - val_accuracy: 0.9619 - val_loss: 0.2418\n",
      "Epoch 358/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0342 - val_accuracy: 0.9670 - val_loss: 0.2301\n",
      "Epoch 359/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0344 - val_accuracy: 0.9695 - val_loss: 0.2399\n",
      "Epoch 360/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9857 - loss: 0.0295 - val_accuracy: 0.9670 - val_loss: 0.2542\n",
      "Epoch 361/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9835 - loss: 0.0322 - val_accuracy: 0.9695 - val_loss: 0.2504\n",
      "Epoch 362/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9794 - loss: 0.0381 - val_accuracy: 0.9670 - val_loss: 0.2433\n",
      "Epoch 363/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9865 - loss: 0.0335 - val_accuracy: 0.9670 - val_loss: 0.2228\n",
      "Epoch 364/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9818 - loss: 0.0421 - val_accuracy: 0.9569 - val_loss: 0.2436\n",
      "Epoch 365/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9784 - loss: 0.0612 - val_accuracy: 0.9619 - val_loss: 0.2442\n",
      "Epoch 366/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9720 - loss: 0.0567 - val_accuracy: 0.9619 - val_loss: 0.2614\n",
      "Epoch 367/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9843 - loss: 0.0464 - val_accuracy: 0.9645 - val_loss: 0.2262\n",
      "Epoch 368/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9769 - loss: 0.0462 - val_accuracy: 0.9695 - val_loss: 0.2291\n",
      "Epoch 369/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9835 - loss: 0.0363 - val_accuracy: 0.9670 - val_loss: 0.2383\n",
      "Epoch 370/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9817 - loss: 0.0381 - val_accuracy: 0.9695 - val_loss: 0.2487\n",
      "Epoch 371/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9790 - loss: 0.0423 - val_accuracy: 0.9695 - val_loss: 0.2459\n",
      "Epoch 372/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9822 - loss: 0.0337 - val_accuracy: 0.9670 - val_loss: 0.2545\n",
      "Epoch 373/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0333 - val_accuracy: 0.9670 - val_loss: 0.2408\n",
      "Epoch 374/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9809 - loss: 0.0362 - val_accuracy: 0.9695 - val_loss: 0.2517\n",
      "Epoch 375/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9865 - loss: 0.0284 - val_accuracy: 0.9619 - val_loss: 0.2881\n",
      "Epoch 376/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0369 - val_accuracy: 0.9695 - val_loss: 0.2471\n",
      "Epoch 377/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0311 - val_accuracy: 0.9695 - val_loss: 0.2612\n",
      "Epoch 378/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9808 - loss: 0.0348 - val_accuracy: 0.9695 - val_loss: 0.2622\n",
      "Epoch 379/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9842 - loss: 0.0303 - val_accuracy: 0.9695 - val_loss: 0.2575\n",
      "Epoch 380/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0360 - val_accuracy: 0.9543 - val_loss: 0.3039\n",
      "Epoch 381/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9827 - loss: 0.0318 - val_accuracy: 0.9594 - val_loss: 0.3671\n",
      "Epoch 382/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9794 - loss: 0.0459 - val_accuracy: 0.9645 - val_loss: 0.2784\n",
      "Epoch 383/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9810 - loss: 0.0385 - val_accuracy: 0.9695 - val_loss: 0.2640\n",
      "Epoch 384/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0363 - val_accuracy: 0.9670 - val_loss: 0.2487\n",
      "Epoch 385/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9776 - loss: 0.0408 - val_accuracy: 0.9619 - val_loss: 0.2163\n",
      "Epoch 386/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0420 - val_accuracy: 0.9670 - val_loss: 0.2323\n",
      "Epoch 387/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0351 - val_accuracy: 0.9695 - val_loss: 0.2419\n",
      "Epoch 388/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9802 - loss: 0.0406 - val_accuracy: 0.9721 - val_loss: 0.2392\n",
      "Epoch 389/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0370 - val_accuracy: 0.9721 - val_loss: 0.2425\n",
      "Epoch 390/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0294 - val_accuracy: 0.9695 - val_loss: 0.2757\n",
      "Epoch 391/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0385 - val_accuracy: 0.9670 - val_loss: 0.2418\n",
      "Epoch 392/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9828 - loss: 0.0374 - val_accuracy: 0.9695 - val_loss: 0.2114\n",
      "Epoch 393/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9800 - loss: 0.0403 - val_accuracy: 0.9721 - val_loss: 0.2121\n",
      "Epoch 394/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0443 - val_accuracy: 0.9721 - val_loss: 0.2441\n",
      "Epoch 395/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9800 - loss: 0.0384 - val_accuracy: 0.9670 - val_loss: 0.2696\n",
      "Epoch 396/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9806 - loss: 0.0354 - val_accuracy: 0.9695 - val_loss: 0.2671\n",
      "Epoch 397/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0356 - val_accuracy: 0.9670 - val_loss: 0.2746\n",
      "Epoch 398/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9817 - loss: 0.0365 - val_accuracy: 0.9670 - val_loss: 0.2749\n",
      "Epoch 399/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9832 - loss: 0.0367 - val_accuracy: 0.9594 - val_loss: 0.3183\n",
      "Epoch 400/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9827 - loss: 0.0343 - val_accuracy: 0.9670 - val_loss: 0.3068\n",
      "Epoch 401/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0312 - val_accuracy: 0.9670 - val_loss: 0.2958\n",
      "Epoch 402/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9847 - loss: 0.0310 - val_accuracy: 0.9670 - val_loss: 0.2951\n",
      "Epoch 403/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0310 - val_accuracy: 0.9645 - val_loss: 0.2658\n",
      "Epoch 404/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9749 - loss: 0.0514 - val_accuracy: 0.9594 - val_loss: 0.2377\n",
      "Epoch 405/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9812 - loss: 0.0518 - val_accuracy: 0.9645 - val_loss: 0.2384\n",
      "Epoch 406/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9714 - loss: 0.0666 - val_accuracy: 0.9695 - val_loss: 0.1979\n",
      "Epoch 407/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0414 - val_accuracy: 0.9645 - val_loss: 0.2577\n",
      "Epoch 408/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0353 - val_accuracy: 0.9670 - val_loss: 0.2927\n",
      "Epoch 409/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0381 - val_accuracy: 0.9619 - val_loss: 0.3360\n",
      "Epoch 410/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9810 - loss: 0.0507 - val_accuracy: 0.9645 - val_loss: 0.2671\n",
      "Epoch 411/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9801 - loss: 0.0479 - val_accuracy: 0.9695 - val_loss: 0.2607\n",
      "Epoch 412/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0420 - val_accuracy: 0.9619 - val_loss: 0.2676\n",
      "Epoch 413/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9763 - loss: 0.0495 - val_accuracy: 0.9695 - val_loss: 0.2570\n",
      "Epoch 414/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9802 - loss: 0.0466 - val_accuracy: 0.9695 - val_loss: 0.2524\n",
      "Epoch 415/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9841 - loss: 0.0432 - val_accuracy: 0.9695 - val_loss: 0.2762\n",
      "Epoch 416/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0317 - val_accuracy: 0.9695 - val_loss: 0.2427\n",
      "Epoch 417/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0331 - val_accuracy: 0.9645 - val_loss: 0.2963\n",
      "Epoch 418/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9768 - loss: 0.0729 - val_accuracy: 0.9695 - val_loss: 0.2602\n",
      "Epoch 419/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0389 - val_accuracy: 0.9645 - val_loss: 0.2757\n",
      "Epoch 420/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0381 - val_accuracy: 0.9721 - val_loss: 0.2563\n",
      "Epoch 421/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9797 - loss: 0.0959 - val_accuracy: 0.9695 - val_loss: 0.2617\n",
      "Epoch 422/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9806 - loss: 0.0420 - val_accuracy: 0.9670 - val_loss: 0.2479\n",
      "Epoch 423/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9806 - loss: 0.0367 - val_accuracy: 0.9721 - val_loss: 0.2333\n",
      "Epoch 424/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0406 - val_accuracy: 0.9721 - val_loss: 0.2355\n",
      "Epoch 425/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9863 - loss: 0.0279 - val_accuracy: 0.9721 - val_loss: 0.2383\n",
      "Epoch 426/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0351 - val_accuracy: 0.9721 - val_loss: 0.2342\n",
      "Epoch 427/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0359 - val_accuracy: 0.9670 - val_loss: 0.2486\n",
      "Epoch 428/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9857 - loss: 0.0301 - val_accuracy: 0.9721 - val_loss: 0.2442\n",
      "Epoch 429/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9851 - loss: 0.0317 - val_accuracy: 0.9695 - val_loss: 0.2378\n",
      "Epoch 430/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.0315 - val_accuracy: 0.9721 - val_loss: 0.2543\n",
      "Epoch 431/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9795 - loss: 0.0367 - val_accuracy: 0.9721 - val_loss: 0.2425\n",
      "Epoch 432/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9870 - loss: 0.0279 - val_accuracy: 0.9721 - val_loss: 0.2435\n",
      "Epoch 433/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0323 - val_accuracy: 0.9721 - val_loss: 0.2452\n",
      "Epoch 434/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9828 - loss: 0.0356 - val_accuracy: 0.9645 - val_loss: 0.2448\n",
      "Epoch 435/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9860 - loss: 0.0308 - val_accuracy: 0.9695 - val_loss: 0.2376\n",
      "Epoch 436/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9851 - loss: 0.0300 - val_accuracy: 0.9695 - val_loss: 0.2748\n",
      "Epoch 437/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9804 - loss: 0.0497 - val_accuracy: 0.9721 - val_loss: 0.2270\n",
      "Epoch 438/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9829 - loss: 0.0366 - val_accuracy: 0.9695 - val_loss: 0.2447\n",
      "Epoch 439/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9841 - loss: 0.0318 - val_accuracy: 0.9695 - val_loss: 0.2626\n",
      "Epoch 440/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9833 - loss: 0.0347 - val_accuracy: 0.9594 - val_loss: 0.3312\n",
      "Epoch 441/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0501 - val_accuracy: 0.9721 - val_loss: 0.1870\n",
      "Epoch 442/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9821 - loss: 0.0499 - val_accuracy: 0.9670 - val_loss: 0.2246\n",
      "Epoch 443/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9822 - loss: 0.0362 - val_accuracy: 0.9721 - val_loss: 0.2252\n",
      "Epoch 444/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0346 - val_accuracy: 0.9670 - val_loss: 0.2479\n",
      "Epoch 445/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9858 - loss: 0.0332 - val_accuracy: 0.9721 - val_loss: 0.2464\n",
      "Epoch 446/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0325 - val_accuracy: 0.9695 - val_loss: 0.2448\n",
      "Epoch 447/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0315 - val_accuracy: 0.9695 - val_loss: 0.2525\n",
      "Epoch 448/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0337 - val_accuracy: 0.9721 - val_loss: 0.2391\n",
      "Epoch 449/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0340 - val_accuracy: 0.9695 - val_loss: 0.2435\n",
      "Epoch 450/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9818 - loss: 0.0339 - val_accuracy: 0.9721 - val_loss: 0.2454\n",
      "Epoch 451/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0410 - val_accuracy: 0.9695 - val_loss: 0.2612\n",
      "Epoch 452/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0357 - val_accuracy: 0.9721 - val_loss: 0.2347\n",
      "Epoch 453/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9849 - loss: 0.0320 - val_accuracy: 0.9721 - val_loss: 0.2357\n",
      "Epoch 454/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0349 - val_accuracy: 0.9695 - val_loss: 0.2338\n",
      "Epoch 455/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9822 - loss: 0.0383 - val_accuracy: 0.9721 - val_loss: 0.2343\n",
      "Epoch 456/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9867 - loss: 0.0307 - val_accuracy: 0.9721 - val_loss: 0.2347\n",
      "Epoch 457/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9860 - loss: 0.0289 - val_accuracy: 0.9721 - val_loss: 0.2436\n",
      "Epoch 458/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9835 - loss: 0.0325 - val_accuracy: 0.9721 - val_loss: 0.2419\n",
      "Epoch 459/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9854 - loss: 0.0313 - val_accuracy: 0.9619 - val_loss: 0.2695\n",
      "Epoch 460/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9841 - loss: 0.0303 - val_accuracy: 0.9594 - val_loss: 0.2913\n",
      "Epoch 461/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9771 - loss: 0.0759 - val_accuracy: 0.9670 - val_loss: 0.2270\n",
      "Epoch 462/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9784 - loss: 0.0523 - val_accuracy: 0.9594 - val_loss: 0.2024\n",
      "Epoch 463/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9758 - loss: 0.0503 - val_accuracy: 0.9695 - val_loss: 0.2129\n",
      "Epoch 464/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9785 - loss: 0.0444 - val_accuracy: 0.9569 - val_loss: 0.2596\n",
      "Epoch 465/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9814 - loss: 0.0374 - val_accuracy: 0.9619 - val_loss: 0.2099\n",
      "Epoch 466/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0411 - val_accuracy: 0.9594 - val_loss: 0.2333\n",
      "Epoch 467/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9757 - loss: 0.0545 - val_accuracy: 0.9645 - val_loss: 0.2527\n",
      "Epoch 468/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0517 - val_accuracy: 0.9619 - val_loss: 0.2717\n",
      "Epoch 469/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0401 - val_accuracy: 0.9721 - val_loss: 0.2445\n",
      "Epoch 470/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9813 - loss: 0.0405 - val_accuracy: 0.9645 - val_loss: 0.2350\n",
      "Epoch 471/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0479 - val_accuracy: 0.9695 - val_loss: 0.2448\n",
      "Epoch 472/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9803 - loss: 0.0439 - val_accuracy: 0.9645 - val_loss: 0.2345\n",
      "Epoch 473/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9794 - loss: 0.0497 - val_accuracy: 0.9543 - val_loss: 0.2632\n",
      "Epoch 474/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9716 - loss: 0.0821 - val_accuracy: 0.9594 - val_loss: 0.2913\n",
      "Epoch 475/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0418 - val_accuracy: 0.9670 - val_loss: 0.3070\n",
      "Epoch 476/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0406 - val_accuracy: 0.9594 - val_loss: 0.3090\n",
      "Epoch 477/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9858 - loss: 0.0336 - val_accuracy: 0.9645 - val_loss: 0.2928\n",
      "Epoch 478/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9828 - loss: 0.0415 - val_accuracy: 0.9619 - val_loss: 0.2824\n",
      "Epoch 479/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9809 - loss: 0.0382 - val_accuracy: 0.9594 - val_loss: 0.3173\n",
      "Epoch 480/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0466 - val_accuracy: 0.9619 - val_loss: 0.2800\n",
      "Epoch 481/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9847 - loss: 0.0339 - val_accuracy: 0.9645 - val_loss: 0.2733\n",
      "Epoch 482/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0373 - val_accuracy: 0.9670 - val_loss: 0.2828\n",
      "Epoch 483/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9802 - loss: 0.0429 - val_accuracy: 0.9670 - val_loss: 0.2776\n",
      "Epoch 484/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9817 - loss: 0.0336 - val_accuracy: 0.9670 - val_loss: 0.2928\n",
      "Epoch 485/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9816 - loss: 0.0346 - val_accuracy: 0.9695 - val_loss: 0.2783\n",
      "Epoch 486/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0261 - val_accuracy: 0.9695 - val_loss: 0.2931\n",
      "Epoch 487/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9857 - loss: 0.0308 - val_accuracy: 0.9670 - val_loss: 0.2713\n",
      "Epoch 488/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0320 - val_accuracy: 0.9670 - val_loss: 0.2781\n",
      "Epoch 489/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9816 - loss: 0.0360 - val_accuracy: 0.9670 - val_loss: 0.2706\n",
      "Epoch 490/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.0322 - val_accuracy: 0.9670 - val_loss: 0.2877\n",
      "Epoch 491/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0363 - val_accuracy: 0.9670 - val_loss: 0.2860\n",
      "Epoch 492/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.0447 - val_accuracy: 0.9619 - val_loss: 0.2373\n",
      "Epoch 493/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9815 - loss: 0.0413 - val_accuracy: 0.9695 - val_loss: 0.2684\n",
      "Epoch 494/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9843 - loss: 0.0346 - val_accuracy: 0.9594 - val_loss: 0.2953\n",
      "Epoch 495/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9775 - loss: 0.0496 - val_accuracy: 0.9721 - val_loss: 0.2439\n",
      "Epoch 496/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9828 - loss: 0.0370 - val_accuracy: 0.9569 - val_loss: 0.2768\n",
      "Epoch 497/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0414 - val_accuracy: 0.9645 - val_loss: 0.2742\n",
      "Epoch 498/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0403 - val_accuracy: 0.9670 - val_loss: 0.2738\n",
      "Epoch 499/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9837 - loss: 0.0348 - val_accuracy: 0.9670 - val_loss: 0.2756\n",
      "Epoch 500/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9843 - loss: 0.0369 - val_accuracy: 0.9695 - val_loss: 0.2718\n",
      "Epoch 501/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9856 - loss: 0.0333 - val_accuracy: 0.9695 - val_loss: 0.2769\n",
      "Epoch 502/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0319 - val_accuracy: 0.9721 - val_loss: 0.2697\n",
      "Epoch 503/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0359 - val_accuracy: 0.9645 - val_loss: 0.2955\n",
      "Epoch 504/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9812 - loss: 0.0349 - val_accuracy: 0.9594 - val_loss: 0.2813\n",
      "Epoch 505/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9808 - loss: 0.0372 - val_accuracy: 0.9670 - val_loss: 0.2843\n",
      "Epoch 506/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9877 - loss: 0.0294 - val_accuracy: 0.9695 - val_loss: 0.2987\n",
      "Epoch 507/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0318 - val_accuracy: 0.9670 - val_loss: 0.3206\n",
      "Epoch 508/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9808 - loss: 0.0461 - val_accuracy: 0.9594 - val_loss: 0.3609\n",
      "Epoch 509/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9829 - loss: 0.0377 - val_accuracy: 0.9670 - val_loss: 0.2782\n",
      "Epoch 510/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0477 - val_accuracy: 0.9645 - val_loss: 0.2420\n",
      "Epoch 511/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9751 - loss: 0.0466 - val_accuracy: 0.9619 - val_loss: 0.2829\n",
      "Epoch 512/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0393 - val_accuracy: 0.9569 - val_loss: 0.3237\n",
      "Epoch 513/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9807 - loss: 0.0512 - val_accuracy: 0.9695 - val_loss: 0.2648\n",
      "Epoch 514/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9840 - loss: 0.0343 - val_accuracy: 0.9670 - val_loss: 0.3021\n",
      "Epoch 515/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0325 - val_accuracy: 0.9695 - val_loss: 0.2900\n",
      "Epoch 516/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0308 - val_accuracy: 0.9695 - val_loss: 0.3003\n",
      "Epoch 517/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9826 - loss: 0.0372 - val_accuracy: 0.9645 - val_loss: 0.2861\n",
      "Epoch 518/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0352 - val_accuracy: 0.9721 - val_loss: 0.2806\n",
      "Epoch 519/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9837 - loss: 0.0303 - val_accuracy: 0.9721 - val_loss: 0.2890\n",
      "Epoch 520/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0363 - val_accuracy: 0.9721 - val_loss: 0.2904\n",
      "Epoch 521/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9877 - loss: 0.0309 - val_accuracy: 0.9695 - val_loss: 0.3067\n",
      "Epoch 522/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9844 - loss: 0.0322 - val_accuracy: 0.9721 - val_loss: 0.2931\n",
      "Epoch 523/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9822 - loss: 0.0346 - val_accuracy: 0.9721 - val_loss: 0.3045\n",
      "Epoch 524/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9860 - loss: 0.0294 - val_accuracy: 0.9721 - val_loss: 0.3008\n",
      "Epoch 525/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0346 - val_accuracy: 0.9721 - val_loss: 0.3172\n",
      "Epoch 526/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9844 - loss: 0.0314 - val_accuracy: 0.9721 - val_loss: 0.3126\n",
      "Epoch 527/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0298 - val_accuracy: 0.9721 - val_loss: 0.3189\n",
      "Epoch 528/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0316 - val_accuracy: 0.9721 - val_loss: 0.3140\n",
      "Epoch 529/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0324 - val_accuracy: 0.9695 - val_loss: 0.3217\n",
      "Epoch 530/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0320 - val_accuracy: 0.9695 - val_loss: 0.2860\n",
      "Epoch 531/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9825 - loss: 0.0415 - val_accuracy: 0.9721 - val_loss: 0.2855\n",
      "Epoch 532/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0355 - val_accuracy: 0.9619 - val_loss: 0.2732\n",
      "Epoch 533/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9761 - loss: 0.0545 - val_accuracy: 0.9670 - val_loss: 0.2911\n",
      "Epoch 534/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9797 - loss: 0.0446 - val_accuracy: 0.9721 - val_loss: 0.2912\n",
      "Epoch 535/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9802 - loss: 0.0435 - val_accuracy: 0.9670 - val_loss: 0.2882\n",
      "Epoch 536/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9769 - loss: 0.0460 - val_accuracy: 0.9645 - val_loss: 0.3568\n",
      "Epoch 537/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0374 - val_accuracy: 0.9721 - val_loss: 0.2851\n",
      "Epoch 538/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0381 - val_accuracy: 0.9721 - val_loss: 0.3089\n",
      "Epoch 539/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0308 - val_accuracy: 0.9721 - val_loss: 0.3063\n",
      "Epoch 540/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0291 - val_accuracy: 0.9721 - val_loss: 0.3146\n",
      "Epoch 541/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0323 - val_accuracy: 0.9695 - val_loss: 0.3436\n",
      "Epoch 542/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9846 - loss: 0.0342 - val_accuracy: 0.9645 - val_loss: 0.3311\n",
      "Epoch 543/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9785 - loss: 0.0385 - val_accuracy: 0.9695 - val_loss: 0.2982\n",
      "Epoch 544/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0345 - val_accuracy: 0.9721 - val_loss: 0.3020\n",
      "Epoch 545/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9890 - loss: 0.0259 - val_accuracy: 0.9721 - val_loss: 0.3025\n",
      "Epoch 546/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9872 - loss: 0.0315 - val_accuracy: 0.9721 - val_loss: 0.3035\n",
      "Epoch 547/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9851 - loss: 0.0338 - val_accuracy: 0.9721 - val_loss: 0.3008\n",
      "Epoch 548/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9857 - loss: 0.0289 - val_accuracy: 0.9721 - val_loss: 0.2957\n",
      "Epoch 549/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0319 - val_accuracy: 0.9721 - val_loss: 0.3131\n",
      "Epoch 550/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0278 - val_accuracy: 0.9721 - val_loss: 0.3041\n",
      "Epoch 551/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9864 - loss: 0.0287 - val_accuracy: 0.9721 - val_loss: 0.2902\n",
      "Epoch 552/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9834 - loss: 0.0338 - val_accuracy: 0.9695 - val_loss: 0.3008\n",
      "Epoch 553/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9775 - loss: 0.0477 - val_accuracy: 0.9721 - val_loss: 0.2850\n",
      "Epoch 554/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9821 - loss: 0.0318 - val_accuracy: 0.9721 - val_loss: 0.2718\n",
      "Epoch 555/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0349 - val_accuracy: 0.9543 - val_loss: 0.2925\n",
      "Epoch 556/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9778 - loss: 0.0414 - val_accuracy: 0.9645 - val_loss: 0.2774\n",
      "Epoch 557/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9843 - loss: 0.0324 - val_accuracy: 0.9670 - val_loss: 0.3163\n",
      "Epoch 558/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9816 - loss: 0.0430 - val_accuracy: 0.9695 - val_loss: 0.2584\n",
      "Epoch 559/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9844 - loss: 0.0334 - val_accuracy: 0.9670 - val_loss: 0.3108\n",
      "Epoch 560/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0372 - val_accuracy: 0.9721 - val_loss: 0.2764\n",
      "Epoch 561/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0322 - val_accuracy: 0.9721 - val_loss: 0.3006\n",
      "Epoch 562/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9862 - loss: 0.0299 - val_accuracy: 0.9721 - val_loss: 0.3247\n",
      "Epoch 563/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0417 - val_accuracy: 0.9670 - val_loss: 0.3245\n",
      "Epoch 564/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9846 - loss: 0.0286 - val_accuracy: 0.9670 - val_loss: 0.3452\n",
      "Epoch 565/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0390 - val_accuracy: 0.9594 - val_loss: 0.4071\n",
      "Epoch 566/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9783 - loss: 0.0448 - val_accuracy: 0.9695 - val_loss: 0.3215\n",
      "Epoch 567/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9804 - loss: 0.0397 - val_accuracy: 0.9670 - val_loss: 0.3346\n",
      "Epoch 568/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9782 - loss: 0.0605 - val_accuracy: 0.9492 - val_loss: 0.3452\n",
      "Epoch 569/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0419 - val_accuracy: 0.9594 - val_loss: 0.3431\n",
      "Epoch 570/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0494 - val_accuracy: 0.9645 - val_loss: 0.3153\n",
      "Epoch 571/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9860 - loss: 0.0336 - val_accuracy: 0.9645 - val_loss: 0.3449\n",
      "Epoch 572/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0359 - val_accuracy: 0.9670 - val_loss: 0.3295\n",
      "Epoch 573/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9852 - loss: 0.0328 - val_accuracy: 0.9670 - val_loss: 0.3395\n",
      "Epoch 574/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9855 - loss: 0.0330 - val_accuracy: 0.9670 - val_loss: 0.3365\n",
      "Epoch 575/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9858 - loss: 0.0308 - val_accuracy: 0.9670 - val_loss: 0.3293\n",
      "Epoch 576/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0386 - val_accuracy: 0.9619 - val_loss: 0.3442\n",
      "Epoch 577/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9800 - loss: 0.0364 - val_accuracy: 0.9695 - val_loss: 0.3147\n",
      "Epoch 578/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9812 - loss: 0.0381 - val_accuracy: 0.9619 - val_loss: 0.3230\n",
      "Epoch 579/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9829 - loss: 0.0316 - val_accuracy: 0.9645 - val_loss: 0.3401\n",
      "Epoch 580/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9766 - loss: 0.0416 - val_accuracy: 0.9569 - val_loss: 0.3552\n",
      "Epoch 581/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9835 - loss: 0.0398 - val_accuracy: 0.9645 - val_loss: 0.2818\n",
      "Epoch 582/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0455 - val_accuracy: 0.9645 - val_loss: 0.2941\n",
      "Epoch 583/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9844 - loss: 0.0348 - val_accuracy: 0.9619 - val_loss: 0.3067\n",
      "Epoch 584/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0345 - val_accuracy: 0.9645 - val_loss: 0.2954\n",
      "Epoch 585/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0298 - val_accuracy: 0.9645 - val_loss: 0.3064\n",
      "Epoch 586/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9837 - loss: 0.0338 - val_accuracy: 0.9569 - val_loss: 0.3133\n",
      "Epoch 587/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9793 - loss: 0.0438 - val_accuracy: 0.9670 - val_loss: 0.3545\n",
      "Epoch 588/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0330 - val_accuracy: 0.9670 - val_loss: 0.3277\n",
      "Epoch 589/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9831 - loss: 0.0450 - val_accuracy: 0.9645 - val_loss: 0.3073\n",
      "Epoch 590/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0358 - val_accuracy: 0.9670 - val_loss: 0.3805\n",
      "Epoch 591/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0337 - val_accuracy: 0.9645 - val_loss: 0.4043\n",
      "Epoch 592/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9843 - loss: 0.0303 - val_accuracy: 0.9670 - val_loss: 0.4042\n",
      "Epoch 593/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9829 - loss: 0.0366 - val_accuracy: 0.9670 - val_loss: 0.3838\n",
      "Epoch 594/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9869 - loss: 0.0337 - val_accuracy: 0.9543 - val_loss: 0.3990\n",
      "Epoch 595/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0505 - val_accuracy: 0.9619 - val_loss: 0.3858\n",
      "Epoch 596/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9829 - loss: 0.0344 - val_accuracy: 0.9619 - val_loss: 0.3985\n",
      "Epoch 597/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0326 - val_accuracy: 0.9645 - val_loss: 0.3978\n",
      "Epoch 598/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9839 - loss: 0.0313 - val_accuracy: 0.9543 - val_loss: 0.4020\n",
      "Epoch 599/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0364 - val_accuracy: 0.9569 - val_loss: 0.4095\n",
      "Epoch 600/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9847 - loss: 0.0294 - val_accuracy: 0.9645 - val_loss: 0.3986\n",
      "Epoch 601/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0314 - val_accuracy: 0.9645 - val_loss: 0.4029\n",
      "Epoch 602/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0306 - val_accuracy: 0.9645 - val_loss: 0.4053\n",
      "Epoch 603/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9879 - loss: 0.0317 - val_accuracy: 0.9645 - val_loss: 0.3900\n",
      "Epoch 604/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0281 - val_accuracy: 0.9645 - val_loss: 0.3993\n",
      "Epoch 605/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9888 - loss: 0.0265 - val_accuracy: 0.9645 - val_loss: 0.4058\n",
      "Epoch 606/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0318 - val_accuracy: 0.9619 - val_loss: 0.4192\n",
      "Epoch 607/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9871 - loss: 0.0290 - val_accuracy: 0.9569 - val_loss: 0.4291\n",
      "Epoch 608/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0350 - val_accuracy: 0.9645 - val_loss: 0.3894\n",
      "Epoch 609/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0375 - val_accuracy: 0.9670 - val_loss: 0.3855\n",
      "Epoch 610/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9848 - loss: 0.0336 - val_accuracy: 0.9670 - val_loss: 0.3669\n",
      "Epoch 611/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0456 - val_accuracy: 0.9670 - val_loss: 0.3781\n",
      "Epoch 612/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0399 - val_accuracy: 0.9645 - val_loss: 0.4056\n",
      "Epoch 613/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9807 - loss: 0.0372 - val_accuracy: 0.9670 - val_loss: 0.4119\n",
      "Epoch 614/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0320 - val_accuracy: 0.9594 - val_loss: 0.4242\n",
      "Epoch 615/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9845 - loss: 0.0297 - val_accuracy: 0.9594 - val_loss: 0.3945\n",
      "Epoch 616/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0383 - val_accuracy: 0.9594 - val_loss: 0.3770\n",
      "Epoch 617/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0325 - val_accuracy: 0.9569 - val_loss: 0.4116\n",
      "Epoch 618/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0456 - val_accuracy: 0.9645 - val_loss: 0.3762\n",
      "Epoch 619/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9763 - loss: 0.0405 - val_accuracy: 0.9619 - val_loss: 0.3294\n",
      "Epoch 620/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0471 - val_accuracy: 0.9695 - val_loss: 0.3049\n",
      "Epoch 621/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9811 - loss: 0.0414 - val_accuracy: 0.9645 - val_loss: 0.2781\n",
      "Epoch 622/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9762 - loss: 0.0642 - val_accuracy: 0.9721 - val_loss: 0.2766\n",
      "Epoch 623/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0309 - val_accuracy: 0.9721 - val_loss: 0.3010\n",
      "Epoch 624/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9804 - loss: 0.0394 - val_accuracy: 0.9670 - val_loss: 0.2908\n",
      "Epoch 625/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0301 - val_accuracy: 0.9645 - val_loss: 0.2765\n",
      "Epoch 626/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0298 - val_accuracy: 0.9670 - val_loss: 0.3189\n",
      "Epoch 627/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9861 - loss: 0.0335 - val_accuracy: 0.9670 - val_loss: 0.3242\n",
      "Epoch 628/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9884 - loss: 0.0256 - val_accuracy: 0.9695 - val_loss: 0.3348\n",
      "Epoch 629/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0287 - val_accuracy: 0.9670 - val_loss: 0.3235\n",
      "Epoch 630/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0314 - val_accuracy: 0.9645 - val_loss: 0.3482\n",
      "Epoch 631/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9816 - loss: 0.0426 - val_accuracy: 0.9645 - val_loss: 0.3572\n",
      "Epoch 632/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9744 - loss: 0.0556 - val_accuracy: 0.9695 - val_loss: 0.3077\n",
      "Epoch 633/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0369 - val_accuracy: 0.9645 - val_loss: 0.3004\n",
      "Epoch 634/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0350 - val_accuracy: 0.9695 - val_loss: 0.3755\n",
      "Epoch 635/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0412 - val_accuracy: 0.9695 - val_loss: 0.3466\n",
      "Epoch 636/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0400 - val_accuracy: 0.9670 - val_loss: 0.3707\n",
      "Epoch 637/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9845 - loss: 0.0385 - val_accuracy: 0.9670 - val_loss: 0.3487\n",
      "Epoch 638/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9884 - loss: 0.0341 - val_accuracy: 0.9645 - val_loss: 0.3573\n",
      "Epoch 639/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0312 - val_accuracy: 0.9695 - val_loss: 0.3548\n",
      "Epoch 640/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9803 - loss: 0.0375 - val_accuracy: 0.9695 - val_loss: 0.3550\n",
      "Epoch 641/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0274 - val_accuracy: 0.9695 - val_loss: 0.3691\n",
      "Epoch 642/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0305 - val_accuracy: 0.9695 - val_loss: 0.3617\n",
      "Epoch 643/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9811 - loss: 0.0337 - val_accuracy: 0.9695 - val_loss: 0.3580\n",
      "Epoch 644/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0280 - val_accuracy: 0.9619 - val_loss: 0.3673\n",
      "Epoch 645/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9840 - loss: 0.0300 - val_accuracy: 0.9721 - val_loss: 0.3670\n",
      "Epoch 646/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9820 - loss: 0.0343 - val_accuracy: 0.9695 - val_loss: 0.3835\n",
      "Epoch 647/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9814 - loss: 0.0366 - val_accuracy: 0.9569 - val_loss: 0.3266\n",
      "Epoch 648/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9796 - loss: 0.0421 - val_accuracy: 0.9670 - val_loss: 0.3571\n",
      "Epoch 649/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0366 - val_accuracy: 0.9645 - val_loss: 0.3451\n",
      "Epoch 650/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0397 - val_accuracy: 0.9695 - val_loss: 0.3551\n",
      "Epoch 651/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0309 - val_accuracy: 0.9721 - val_loss: 0.3446\n",
      "Epoch 652/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9883 - loss: 0.0249 - val_accuracy: 0.9721 - val_loss: 0.3353\n",
      "Epoch 653/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.0458 - val_accuracy: 0.9721 - val_loss: 0.3103\n",
      "Epoch 654/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0334 - val_accuracy: 0.9721 - val_loss: 0.3354\n",
      "Epoch 655/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0354 - val_accuracy: 0.9721 - val_loss: 0.3065\n",
      "Epoch 656/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0374 - val_accuracy: 0.9721 - val_loss: 0.3159\n",
      "Epoch 657/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0308 - val_accuracy: 0.9721 - val_loss: 0.3057\n",
      "Epoch 658/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0328 - val_accuracy: 0.9721 - val_loss: 0.3129\n",
      "Epoch 659/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9861 - loss: 0.0324 - val_accuracy: 0.9721 - val_loss: 0.2922\n",
      "Epoch 660/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0327 - val_accuracy: 0.9645 - val_loss: 0.3052\n",
      "Epoch 661/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.0343 - val_accuracy: 0.9695 - val_loss: 0.3181\n",
      "Epoch 662/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9773 - loss: 0.0464 - val_accuracy: 0.9695 - val_loss: 0.3145\n",
      "Epoch 663/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0321 - val_accuracy: 0.9670 - val_loss: 0.3269\n",
      "Epoch 664/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9778 - loss: 0.0431 - val_accuracy: 0.9670 - val_loss: 0.3082\n",
      "Epoch 665/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0362 - val_accuracy: 0.9695 - val_loss: 0.3111\n",
      "Epoch 666/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0332 - val_accuracy: 0.9645 - val_loss: 0.3195\n",
      "Epoch 667/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9794 - loss: 0.0444 - val_accuracy: 0.9721 - val_loss: 0.3351\n",
      "Epoch 668/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0352 - val_accuracy: 0.9721 - val_loss: 0.3525\n",
      "Epoch 669/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0424 - val_accuracy: 0.9721 - val_loss: 0.3705\n",
      "Epoch 670/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0310 - val_accuracy: 0.9721 - val_loss: 0.3568\n",
      "Epoch 671/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9890 - loss: 0.0278 - val_accuracy: 0.9695 - val_loss: 0.3736\n",
      "Epoch 672/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0315 - val_accuracy: 0.9695 - val_loss: 0.3586\n",
      "Epoch 673/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9861 - loss: 0.0375 - val_accuracy: 0.9670 - val_loss: 0.3802\n",
      "Epoch 674/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0327 - val_accuracy: 0.9695 - val_loss: 0.3988\n",
      "Epoch 675/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0297 - val_accuracy: 0.9695 - val_loss: 0.3962\n",
      "Epoch 676/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0325 - val_accuracy: 0.9670 - val_loss: 0.4030\n",
      "Epoch 677/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0319 - val_accuracy: 0.9695 - val_loss: 0.4060\n",
      "Epoch 678/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0312 - val_accuracy: 0.9645 - val_loss: 0.3998\n",
      "Epoch 679/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0366 - val_accuracy: 0.9721 - val_loss: 0.3902\n",
      "Epoch 680/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9835 - loss: 0.0300 - val_accuracy: 0.9695 - val_loss: 0.3863\n",
      "Epoch 681/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0336 - val_accuracy: 0.9721 - val_loss: 0.3643\n",
      "Epoch 682/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.0337 - val_accuracy: 0.9695 - val_loss: 0.3819\n",
      "Epoch 683/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0351 - val_accuracy: 0.9721 - val_loss: 0.3900\n",
      "Epoch 684/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9814 - loss: 0.0443 - val_accuracy: 0.9645 - val_loss: 0.3963\n",
      "Epoch 685/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9743 - loss: 0.0629 - val_accuracy: 0.9619 - val_loss: 0.3765\n",
      "Epoch 686/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0458 - val_accuracy: 0.9569 - val_loss: 0.3742\n",
      "Epoch 687/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9752 - loss: 0.0607 - val_accuracy: 0.9619 - val_loss: 0.2921\n",
      "Epoch 688/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9804 - loss: 0.0394 - val_accuracy: 0.9594 - val_loss: 0.2965\n",
      "Epoch 689/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0348 - val_accuracy: 0.9645 - val_loss: 0.2991\n",
      "Epoch 690/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9789 - loss: 0.0402 - val_accuracy: 0.9645 - val_loss: 0.3237\n",
      "Epoch 691/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0304 - val_accuracy: 0.9594 - val_loss: 0.3331\n",
      "Epoch 692/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0314 - val_accuracy: 0.9645 - val_loss: 0.3334\n",
      "Epoch 693/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9782 - loss: 0.0377 - val_accuracy: 0.9543 - val_loss: 0.4120\n",
      "Epoch 694/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0485 - val_accuracy: 0.9619 - val_loss: 0.3290\n",
      "Epoch 695/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9788 - loss: 0.0366 - val_accuracy: 0.9721 - val_loss: 0.3246\n",
      "Epoch 696/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9817 - loss: 0.0359 - val_accuracy: 0.9721 - val_loss: 0.3517\n",
      "Epoch 697/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0305 - val_accuracy: 0.9695 - val_loss: 0.3535\n",
      "Epoch 698/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9861 - loss: 0.0285 - val_accuracy: 0.9695 - val_loss: 0.3558\n",
      "Epoch 699/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0288 - val_accuracy: 0.9721 - val_loss: 0.3504\n",
      "Epoch 700/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0275 - val_accuracy: 0.9721 - val_loss: 0.3489\n",
      "Epoch 701/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0287 - val_accuracy: 0.9695 - val_loss: 0.3867\n",
      "Epoch 702/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9803 - loss: 0.0422 - val_accuracy: 0.9721 - val_loss: 0.3010\n",
      "Epoch 703/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9793 - loss: 0.0494 - val_accuracy: 0.9721 - val_loss: 0.3549\n",
      "Epoch 704/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0322 - val_accuracy: 0.9543 - val_loss: 0.3611\n",
      "Epoch 705/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0296 - val_accuracy: 0.9645 - val_loss: 0.3580\n",
      "Epoch 706/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0580 - val_accuracy: 0.9670 - val_loss: 0.3642\n",
      "Epoch 707/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0393 - val_accuracy: 0.9695 - val_loss: 0.3723\n",
      "Epoch 708/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0325 - val_accuracy: 0.9670 - val_loss: 0.3684\n",
      "Epoch 709/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9808 - loss: 0.0536 - val_accuracy: 0.9670 - val_loss: 0.3576\n",
      "Epoch 710/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0395 - val_accuracy: 0.9695 - val_loss: 0.3669\n",
      "Epoch 711/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9851 - loss: 0.0323 - val_accuracy: 0.9670 - val_loss: 0.3732\n",
      "Epoch 712/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9871 - loss: 0.0271 - val_accuracy: 0.9721 - val_loss: 0.3837\n",
      "Epoch 713/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9821 - loss: 0.0336 - val_accuracy: 0.9695 - val_loss: 0.3898\n",
      "Epoch 714/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0343 - val_accuracy: 0.9695 - val_loss: 0.3899\n",
      "Epoch 715/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0326 - val_accuracy: 0.9721 - val_loss: 0.4200\n",
      "Epoch 716/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0305 - val_accuracy: 0.9695 - val_loss: 0.4032\n",
      "Epoch 717/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0317 - val_accuracy: 0.9670 - val_loss: 0.4104\n",
      "Epoch 718/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9835 - loss: 0.0344 - val_accuracy: 0.9670 - val_loss: 0.4236\n",
      "Epoch 719/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0363 - val_accuracy: 0.9695 - val_loss: 0.3913\n",
      "Epoch 720/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0476 - val_accuracy: 0.9695 - val_loss: 0.3690\n",
      "Epoch 721/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9782 - loss: 0.0490 - val_accuracy: 0.9695 - val_loss: 0.3762\n",
      "Epoch 722/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0510 - val_accuracy: 0.9695 - val_loss: 0.3394\n",
      "Epoch 723/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0462 - val_accuracy: 0.9721 - val_loss: 0.3613\n",
      "Epoch 724/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0307 - val_accuracy: 0.9721 - val_loss: 0.3678\n",
      "Epoch 725/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9867 - loss: 0.0345 - val_accuracy: 0.9721 - val_loss: 0.3746\n",
      "Epoch 726/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0291 - val_accuracy: 0.9721 - val_loss: 0.3986\n",
      "Epoch 727/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9828 - loss: 0.0344 - val_accuracy: 0.9670 - val_loss: 0.3878\n",
      "Epoch 728/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9802 - loss: 0.0410 - val_accuracy: 0.9721 - val_loss: 0.3703\n",
      "Epoch 729/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9830 - loss: 0.0330 - val_accuracy: 0.9721 - val_loss: 0.3516\n",
      "Epoch 730/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0289 - val_accuracy: 0.9721 - val_loss: 0.3732\n",
      "Epoch 731/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0304 - val_accuracy: 0.9670 - val_loss: 0.3904\n",
      "Epoch 732/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0383 - val_accuracy: 0.9695 - val_loss: 0.3840\n",
      "Epoch 733/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9843 - loss: 0.0336 - val_accuracy: 0.9670 - val_loss: 0.3639\n",
      "Epoch 734/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0365 - val_accuracy: 0.9619 - val_loss: 0.3892\n",
      "Epoch 735/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9847 - loss: 0.0401 - val_accuracy: 0.9670 - val_loss: 0.4086\n",
      "Epoch 736/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9758 - loss: 0.0569 - val_accuracy: 0.9569 - val_loss: 0.3612\n",
      "Epoch 737/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9676 - loss: 0.0712 - val_accuracy: 0.9645 - val_loss: 0.3601\n",
      "Epoch 738/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9771 - loss: 0.0739 - val_accuracy: 0.9695 - val_loss: 0.3764\n",
      "Epoch 739/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0336 - val_accuracy: 0.9619 - val_loss: 0.4066\n",
      "Epoch 740/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9853 - loss: 0.0316 - val_accuracy: 0.9695 - val_loss: 0.3944\n",
      "Epoch 741/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9807 - loss: 0.0354 - val_accuracy: 0.9695 - val_loss: 0.4136\n",
      "Epoch 742/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9858 - loss: 0.0287 - val_accuracy: 0.9695 - val_loss: 0.4124\n",
      "Epoch 743/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9855 - loss: 0.0286 - val_accuracy: 0.9695 - val_loss: 0.4020\n",
      "Epoch 744/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0300 - val_accuracy: 0.9721 - val_loss: 0.4196\n",
      "Epoch 745/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0308 - val_accuracy: 0.9721 - val_loss: 0.4115\n",
      "Epoch 746/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0354 - val_accuracy: 0.9695 - val_loss: 0.4066\n",
      "Epoch 747/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0366 - val_accuracy: 0.9619 - val_loss: 0.4048\n",
      "Epoch 748/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9851 - loss: 0.0320 - val_accuracy: 0.9695 - val_loss: 0.4131\n",
      "Epoch 749/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0299 - val_accuracy: 0.9721 - val_loss: 0.4146\n",
      "Epoch 750/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0288 - val_accuracy: 0.9721 - val_loss: 0.4013\n",
      "Epoch 751/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0309 - val_accuracy: 0.9695 - val_loss: 0.4141\n",
      "Epoch 752/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9876 - loss: 0.0278 - val_accuracy: 0.9721 - val_loss: 0.4295\n",
      "Epoch 753/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9870 - loss: 0.0248 - val_accuracy: 0.9695 - val_loss: 0.4330\n",
      "Epoch 754/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9866 - loss: 0.0330 - val_accuracy: 0.9645 - val_loss: 0.4294\n",
      "Epoch 755/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0290 - val_accuracy: 0.9670 - val_loss: 0.4621\n",
      "Epoch 756/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0318 - val_accuracy: 0.9695 - val_loss: 0.4738\n",
      "Epoch 757/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0304 - val_accuracy: 0.9695 - val_loss: 0.4781\n",
      "Epoch 758/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9822 - loss: 0.0353 - val_accuracy: 0.9695 - val_loss: 0.4765\n",
      "Epoch 759/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9849 - loss: 0.0338 - val_accuracy: 0.9695 - val_loss: 0.4495\n",
      "Epoch 760/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0361 - val_accuracy: 0.9721 - val_loss: 0.4300\n",
      "Epoch 761/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0308 - val_accuracy: 0.9721 - val_loss: 0.3960\n",
      "Epoch 762/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9879 - loss: 0.0278 - val_accuracy: 0.9721 - val_loss: 0.4267\n",
      "Epoch 763/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9782 - loss: 0.0382 - val_accuracy: 0.9619 - val_loss: 0.4416\n",
      "Epoch 764/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0303 - val_accuracy: 0.9721 - val_loss: 0.4146\n",
      "Epoch 765/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0396 - val_accuracy: 0.9645 - val_loss: 0.4076\n",
      "Epoch 766/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9750 - loss: 0.0761 - val_accuracy: 0.9645 - val_loss: 0.4624\n",
      "Epoch 767/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9769 - loss: 0.0470 - val_accuracy: 0.9569 - val_loss: 0.3997\n",
      "Epoch 768/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9794 - loss: 0.0485 - val_accuracy: 0.9594 - val_loss: 0.4059\n",
      "Epoch 769/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9806 - loss: 0.0346 - val_accuracy: 0.9645 - val_loss: 0.4116\n",
      "Epoch 770/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9840 - loss: 0.0319 - val_accuracy: 0.9645 - val_loss: 0.3940\n",
      "Epoch 771/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9779 - loss: 0.0446 - val_accuracy: 0.9670 - val_loss: 0.3573\n",
      "Epoch 772/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0317 - val_accuracy: 0.9695 - val_loss: 0.3374\n",
      "Epoch 773/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0301 - val_accuracy: 0.9670 - val_loss: 0.3684\n",
      "Epoch 774/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0340 - val_accuracy: 0.9645 - val_loss: 0.3622\n",
      "Epoch 775/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0298 - val_accuracy: 0.9721 - val_loss: 0.3357\n",
      "Epoch 776/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0332 - val_accuracy: 0.9670 - val_loss: 0.3735\n",
      "Epoch 777/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9820 - loss: 0.0337 - val_accuracy: 0.9721 - val_loss: 0.3724\n",
      "Epoch 778/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9862 - loss: 0.0287 - val_accuracy: 0.9721 - val_loss: 0.3670\n",
      "Epoch 779/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9892 - loss: 0.0255 - val_accuracy: 0.9695 - val_loss: 0.3863\n",
      "Epoch 780/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0351 - val_accuracy: 0.9695 - val_loss: 0.3550\n",
      "Epoch 781/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0323 - val_accuracy: 0.9695 - val_loss: 0.3866\n",
      "Epoch 782/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0731 - val_accuracy: 0.9619 - val_loss: 0.3899\n",
      "Epoch 783/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9873 - loss: 0.0327 - val_accuracy: 0.9670 - val_loss: 0.3995\n",
      "Epoch 784/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9728 - loss: 0.0537 - val_accuracy: 0.9619 - val_loss: 0.4738\n",
      "Epoch 785/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0341 - val_accuracy: 0.9695 - val_loss: 0.4767\n",
      "Epoch 786/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9879 - loss: 0.0292 - val_accuracy: 0.9670 - val_loss: 0.4711\n",
      "Epoch 787/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9773 - loss: 0.0373 - val_accuracy: 0.9695 - val_loss: 0.4982\n",
      "Epoch 788/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9845 - loss: 0.0331 - val_accuracy: 0.9670 - val_loss: 0.4744\n",
      "Epoch 789/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0287 - val_accuracy: 0.9619 - val_loss: 0.4719\n",
      "Epoch 790/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0301 - val_accuracy: 0.9695 - val_loss: 0.4949\n",
      "Epoch 791/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.0335 - val_accuracy: 0.9695 - val_loss: 0.4636\n",
      "Epoch 792/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0327 - val_accuracy: 0.9695 - val_loss: 0.4835\n",
      "Epoch 793/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0349 - val_accuracy: 0.9645 - val_loss: 0.4693\n",
      "Epoch 794/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0298 - val_accuracy: 0.9645 - val_loss: 0.4744\n",
      "Epoch 795/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0318 - val_accuracy: 0.9670 - val_loss: 0.4629\n",
      "Epoch 796/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9785 - loss: 0.0447 - val_accuracy: 0.9670 - val_loss: 0.4635\n",
      "Epoch 797/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9807 - loss: 0.0373 - val_accuracy: 0.9695 - val_loss: 0.4471\n",
      "Epoch 798/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0382 - val_accuracy: 0.9695 - val_loss: 0.4523\n",
      "Epoch 799/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0351 - val_accuracy: 0.9670 - val_loss: 0.4360\n",
      "Epoch 800/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9887 - loss: 0.0286 - val_accuracy: 0.9695 - val_loss: 0.4360\n",
      "Epoch 801/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9847 - loss: 0.0307 - val_accuracy: 0.9695 - val_loss: 0.4071\n",
      "Epoch 802/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0302 - val_accuracy: 0.9721 - val_loss: 0.4040\n",
      "Epoch 803/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9803 - loss: 0.0316 - val_accuracy: 0.9670 - val_loss: 0.4211\n",
      "Epoch 804/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0315 - val_accuracy: 0.9670 - val_loss: 0.4222\n",
      "Epoch 805/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0322 - val_accuracy: 0.9670 - val_loss: 0.4532\n",
      "Epoch 806/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0300 - val_accuracy: 0.9670 - val_loss: 0.4621\n",
      "Epoch 807/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9857 - loss: 0.0277 - val_accuracy: 0.9670 - val_loss: 0.4646\n",
      "Epoch 808/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0269 - val_accuracy: 0.9645 - val_loss: 0.4795\n",
      "Epoch 809/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0490 - val_accuracy: 0.9695 - val_loss: 0.4293\n",
      "Epoch 810/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0393 - val_accuracy: 0.9670 - val_loss: 0.4335\n",
      "Epoch 811/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0322 - val_accuracy: 0.9695 - val_loss: 0.4437\n",
      "Epoch 812/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9855 - loss: 0.0289 - val_accuracy: 0.9695 - val_loss: 0.4409\n",
      "Epoch 813/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9801 - loss: 0.0328 - val_accuracy: 0.9670 - val_loss: 0.4605\n",
      "Epoch 814/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9808 - loss: 0.0320 - val_accuracy: 0.9695 - val_loss: 0.4385\n",
      "Epoch 815/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9868 - loss: 0.0277 - val_accuracy: 0.9695 - val_loss: 0.4319\n",
      "Epoch 816/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0331 - val_accuracy: 0.9695 - val_loss: 0.4218\n",
      "Epoch 817/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0334 - val_accuracy: 0.9619 - val_loss: 0.4155\n",
      "Epoch 818/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9686 - loss: 0.0570 - val_accuracy: 0.9569 - val_loss: 0.4206\n",
      "Epoch 819/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9768 - loss: 0.0852 - val_accuracy: 0.9518 - val_loss: 0.4178\n",
      "Epoch 820/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9788 - loss: 0.0433 - val_accuracy: 0.9695 - val_loss: 0.3455\n",
      "Epoch 821/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0305 - val_accuracy: 0.9670 - val_loss: 0.3635\n",
      "Epoch 822/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9821 - loss: 0.0467 - val_accuracy: 0.9619 - val_loss: 0.3614\n",
      "Epoch 823/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9811 - loss: 0.0335 - val_accuracy: 0.9518 - val_loss: 0.4182\n",
      "Epoch 824/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0388 - val_accuracy: 0.9670 - val_loss: 0.3537\n",
      "Epoch 825/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9878 - loss: 0.0317 - val_accuracy: 0.9670 - val_loss: 0.3679\n",
      "Epoch 826/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0301 - val_accuracy: 0.9670 - val_loss: 0.3542\n",
      "Epoch 827/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9858 - loss: 0.0291 - val_accuracy: 0.9670 - val_loss: 0.3775\n",
      "Epoch 828/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0307 - val_accuracy: 0.9670 - val_loss: 0.3824\n",
      "Epoch 829/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0304 - val_accuracy: 0.9670 - val_loss: 0.3481\n",
      "Epoch 830/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.0455 - val_accuracy: 0.9721 - val_loss: 0.3575\n",
      "Epoch 831/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9818 - loss: 0.0334 - val_accuracy: 0.9721 - val_loss: 0.3562\n",
      "Epoch 832/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0300 - val_accuracy: 0.9670 - val_loss: 0.3999\n",
      "Epoch 833/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9802 - loss: 0.0568 - val_accuracy: 0.9569 - val_loss: 0.3841\n",
      "Epoch 834/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0530 - val_accuracy: 0.9645 - val_loss: 0.3531\n",
      "Epoch 835/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0496 - val_accuracy: 0.9594 - val_loss: 0.3619\n",
      "Epoch 836/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9807 - loss: 0.0400 - val_accuracy: 0.9645 - val_loss: 0.3598\n",
      "Epoch 837/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9775 - loss: 0.0388 - val_accuracy: 0.9721 - val_loss: 0.3349\n",
      "Epoch 838/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0327 - val_accuracy: 0.9721 - val_loss: 0.3478\n",
      "Epoch 839/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0302 - val_accuracy: 0.9695 - val_loss: 0.3293\n",
      "Epoch 840/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0302 - val_accuracy: 0.9695 - val_loss: 0.3295\n",
      "Epoch 841/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0363 - val_accuracy: 0.9695 - val_loss: 0.3241\n",
      "Epoch 842/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9796 - loss: 0.0360 - val_accuracy: 0.9645 - val_loss: 0.3344\n",
      "Epoch 843/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0306 - val_accuracy: 0.9670 - val_loss: 0.3583\n",
      "Epoch 844/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0324 - val_accuracy: 0.9695 - val_loss: 0.3203\n",
      "Epoch 845/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0323 - val_accuracy: 0.9645 - val_loss: 0.3052\n",
      "Epoch 846/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0348 - val_accuracy: 0.9670 - val_loss: 0.3076\n",
      "Epoch 847/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9758 - loss: 0.0613 - val_accuracy: 0.9619 - val_loss: 0.3388\n",
      "Epoch 848/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0434 - val_accuracy: 0.9670 - val_loss: 0.3497\n",
      "Epoch 849/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9757 - loss: 0.0418 - val_accuracy: 0.9619 - val_loss: 0.3312\n",
      "Epoch 850/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9801 - loss: 0.0416 - val_accuracy: 0.9695 - val_loss: 0.2854\n",
      "Epoch 851/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0376 - val_accuracy: 0.9721 - val_loss: 0.3089\n",
      "Epoch 852/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9781 - loss: 0.0425 - val_accuracy: 0.9721 - val_loss: 0.2372\n",
      "Epoch 853/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0368 - val_accuracy: 0.9721 - val_loss: 0.2488\n",
      "Epoch 854/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0391 - val_accuracy: 0.9721 - val_loss: 0.2758\n",
      "Epoch 855/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9829 - loss: 0.0317 - val_accuracy: 0.9721 - val_loss: 0.2683\n",
      "Epoch 856/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9862 - loss: 0.0316 - val_accuracy: 0.9721 - val_loss: 0.2724\n",
      "Epoch 857/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0343 - val_accuracy: 0.9721 - val_loss: 0.3192\n",
      "Epoch 858/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0333 - val_accuracy: 0.9645 - val_loss: 0.3270\n",
      "Epoch 859/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9803 - loss: 0.0393 - val_accuracy: 0.9695 - val_loss: 0.3178\n",
      "Epoch 860/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0318 - val_accuracy: 0.9721 - val_loss: 0.3066\n",
      "Epoch 861/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0318 - val_accuracy: 0.9721 - val_loss: 0.3218\n",
      "Epoch 862/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0325 - val_accuracy: 0.9695 - val_loss: 0.3230\n",
      "Epoch 863/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0289 - val_accuracy: 0.9721 - val_loss: 0.3275\n",
      "Epoch 864/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0309 - val_accuracy: 0.9721 - val_loss: 0.3326\n",
      "Epoch 865/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0348 - val_accuracy: 0.9721 - val_loss: 0.3333\n",
      "Epoch 866/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9842 - loss: 0.0333 - val_accuracy: 0.9695 - val_loss: 0.3491\n",
      "Epoch 867/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9875 - loss: 0.0287 - val_accuracy: 0.9695 - val_loss: 0.3686\n",
      "Epoch 868/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0313 - val_accuracy: 0.9721 - val_loss: 0.3757\n",
      "Epoch 869/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0318 - val_accuracy: 0.9695 - val_loss: 0.3877\n",
      "Epoch 870/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9843 - loss: 0.0349 - val_accuracy: 0.9695 - val_loss: 0.3779\n",
      "Epoch 871/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9851 - loss: 0.0299 - val_accuracy: 0.9695 - val_loss: 0.3576\n",
      "Epoch 872/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0362 - val_accuracy: 0.9695 - val_loss: 0.3717\n",
      "Epoch 873/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9806 - loss: 0.0359 - val_accuracy: 0.9721 - val_loss: 0.3923\n",
      "Epoch 874/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0370 - val_accuracy: 0.9695 - val_loss: 0.3424\n",
      "Epoch 875/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0478 - val_accuracy: 0.9569 - val_loss: 0.3686\n",
      "Epoch 876/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9764 - loss: 0.0463 - val_accuracy: 0.9721 - val_loss: 0.4033\n",
      "Epoch 877/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9814 - loss: 0.0391 - val_accuracy: 0.9645 - val_loss: 0.3882\n",
      "Epoch 878/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0321 - val_accuracy: 0.9695 - val_loss: 0.4162\n",
      "Epoch 879/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0396 - val_accuracy: 0.9695 - val_loss: 0.4145\n",
      "Epoch 880/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9896 - loss: 0.0228 - val_accuracy: 0.9721 - val_loss: 0.4154\n",
      "Epoch 881/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0326 - val_accuracy: 0.9695 - val_loss: 0.4155\n",
      "Epoch 882/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0304 - val_accuracy: 0.9721 - val_loss: 0.4201\n",
      "Epoch 883/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0302 - val_accuracy: 0.9721 - val_loss: 0.4306\n",
      "Epoch 884/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.0370 - val_accuracy: 0.9695 - val_loss: 0.3958\n",
      "Epoch 885/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9803 - loss: 0.0346 - val_accuracy: 0.9721 - val_loss: 0.4005\n",
      "Epoch 886/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9840 - loss: 0.0299 - val_accuracy: 0.9721 - val_loss: 0.4107\n",
      "Epoch 887/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0345 - val_accuracy: 0.9670 - val_loss: 0.4695\n",
      "Epoch 888/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9807 - loss: 0.0466 - val_accuracy: 0.9670 - val_loss: 0.3074\n",
      "Epoch 889/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9817 - loss: 0.0354 - val_accuracy: 0.9721 - val_loss: 0.3823\n",
      "Epoch 890/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9791 - loss: 0.0371 - val_accuracy: 0.9721 - val_loss: 0.3992\n",
      "Epoch 891/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0335 - val_accuracy: 0.9721 - val_loss: 0.3994\n",
      "Epoch 892/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9869 - loss: 0.0319 - val_accuracy: 0.9721 - val_loss: 0.3864\n",
      "Epoch 893/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0324 - val_accuracy: 0.9721 - val_loss: 0.3851\n",
      "Epoch 894/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0438 - val_accuracy: 0.9670 - val_loss: 0.3849\n",
      "Epoch 895/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0352 - val_accuracy: 0.9619 - val_loss: 0.3882\n",
      "Epoch 896/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0342 - val_accuracy: 0.9695 - val_loss: 0.3679\n",
      "Epoch 897/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9817 - loss: 0.0326 - val_accuracy: 0.9721 - val_loss: 0.3783\n",
      "Epoch 898/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0280 - val_accuracy: 0.9721 - val_loss: 0.3872\n",
      "Epoch 899/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9811 - loss: 0.0347 - val_accuracy: 0.9721 - val_loss: 0.3906\n",
      "Epoch 900/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9880 - loss: 0.0272 - val_accuracy: 0.9721 - val_loss: 0.3783\n",
      "Epoch 901/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0289 - val_accuracy: 0.9670 - val_loss: 0.3717\n",
      "Epoch 902/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9806 - loss: 0.0375 - val_accuracy: 0.9695 - val_loss: 0.2486\n",
      "Epoch 903/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9754 - loss: 0.0673 - val_accuracy: 0.9569 - val_loss: 0.5043\n",
      "Epoch 904/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9737 - loss: 0.0646 - val_accuracy: 0.9670 - val_loss: 0.2806\n",
      "Epoch 905/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9777 - loss: 0.0538 - val_accuracy: 0.9721 - val_loss: 0.3160\n",
      "Epoch 906/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0327 - val_accuracy: 0.9695 - val_loss: 0.3043\n",
      "Epoch 907/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9775 - loss: 0.0465 - val_accuracy: 0.9695 - val_loss: 0.3095\n",
      "Epoch 908/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9835 - loss: 0.0393 - val_accuracy: 0.9746 - val_loss: 0.2928\n",
      "Epoch 909/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9743 - loss: 0.0513 - val_accuracy: 0.9721 - val_loss: 0.2785\n",
      "Epoch 910/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0399 - val_accuracy: 0.9746 - val_loss: 0.2806\n",
      "Epoch 911/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9852 - loss: 0.0402 - val_accuracy: 0.9721 - val_loss: 0.2652\n",
      "Epoch 912/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0346 - val_accuracy: 0.9670 - val_loss: 0.2877\n",
      "Epoch 913/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0344 - val_accuracy: 0.9695 - val_loss: 0.2799\n",
      "Epoch 914/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0324 - val_accuracy: 0.9695 - val_loss: 0.2875\n",
      "Epoch 915/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0306 - val_accuracy: 0.9721 - val_loss: 0.2916\n",
      "Epoch 916/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0342 - val_accuracy: 0.9721 - val_loss: 0.2905\n",
      "Epoch 917/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9881 - loss: 0.0285 - val_accuracy: 0.9721 - val_loss: 0.2861\n",
      "Epoch 918/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9875 - loss: 0.0300 - val_accuracy: 0.9721 - val_loss: 0.2736\n",
      "Epoch 919/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9850 - loss: 0.0288 - val_accuracy: 0.9695 - val_loss: 0.2791\n",
      "Epoch 920/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9790 - loss: 0.0355 - val_accuracy: 0.9695 - val_loss: 0.3003\n",
      "Epoch 921/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0414 - val_accuracy: 0.9721 - val_loss: 0.2859\n",
      "Epoch 922/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9779 - loss: 0.0428 - val_accuracy: 0.9721 - val_loss: 0.2814\n",
      "Epoch 923/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0292 - val_accuracy: 0.9721 - val_loss: 0.2809\n",
      "Epoch 924/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0290 - val_accuracy: 0.9721 - val_loss: 0.2810\n",
      "Epoch 925/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.0348 - val_accuracy: 0.9721 - val_loss: 0.2958\n",
      "Epoch 926/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9808 - loss: 0.0368 - val_accuracy: 0.9695 - val_loss: 0.2965\n",
      "Epoch 927/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9789 - loss: 0.0437 - val_accuracy: 0.9695 - val_loss: 0.3341\n",
      "Epoch 928/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0442 - val_accuracy: 0.9594 - val_loss: 0.2973\n",
      "Epoch 929/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9771 - loss: 0.0444 - val_accuracy: 0.9645 - val_loss: 0.3146\n",
      "Epoch 930/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0433 - val_accuracy: 0.9695 - val_loss: 0.2802\n",
      "Epoch 931/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0590 - val_accuracy: 0.9695 - val_loss: 0.2980\n",
      "Epoch 932/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9811 - loss: 0.0376 - val_accuracy: 0.9670 - val_loss: 0.3176\n",
      "Epoch 933/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0327 - val_accuracy: 0.9670 - val_loss: 0.3221\n",
      "Epoch 934/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.0373 - val_accuracy: 0.9721 - val_loss: 0.3188\n",
      "Epoch 935/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0354 - val_accuracy: 0.9695 - val_loss: 0.3446\n",
      "Epoch 936/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9829 - loss: 0.0325 - val_accuracy: 0.9721 - val_loss: 0.3369\n",
      "Epoch 937/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9840 - loss: 0.0321 - val_accuracy: 0.9721 - val_loss: 0.3315\n",
      "Epoch 938/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9875 - loss: 0.0255 - val_accuracy: 0.9695 - val_loss: 0.3727\n",
      "Epoch 939/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9777 - loss: 0.0512 - val_accuracy: 0.9670 - val_loss: 0.3135\n",
      "Epoch 940/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0300 - val_accuracy: 0.9695 - val_loss: 0.3112\n",
      "Epoch 941/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9812 - loss: 0.0328 - val_accuracy: 0.9721 - val_loss: 0.3381\n",
      "Epoch 942/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0320 - val_accuracy: 0.9721 - val_loss: 0.3067\n",
      "Epoch 943/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0319 - val_accuracy: 0.9619 - val_loss: 0.3074\n",
      "Epoch 944/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9835 - loss: 0.0326 - val_accuracy: 0.9645 - val_loss: 0.3370\n",
      "Epoch 945/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0293 - val_accuracy: 0.9721 - val_loss: 0.3501\n",
      "Epoch 946/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9874 - loss: 0.0250 - val_accuracy: 0.9695 - val_loss: 0.3222\n",
      "Epoch 947/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9851 - loss: 0.0307 - val_accuracy: 0.9721 - val_loss: 0.3098\n",
      "Epoch 948/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9820 - loss: 0.0417 - val_accuracy: 0.9670 - val_loss: 0.3280\n",
      "Epoch 949/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0339 - val_accuracy: 0.9721 - val_loss: 0.3456\n",
      "Epoch 950/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0329 - val_accuracy: 0.9721 - val_loss: 0.3475\n",
      "Epoch 951/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0328 - val_accuracy: 0.9695 - val_loss: 0.3542\n",
      "Epoch 952/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9859 - loss: 0.0304 - val_accuracy: 0.9695 - val_loss: 0.3415\n",
      "Epoch 953/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0292 - val_accuracy: 0.9721 - val_loss: 0.3325\n",
      "Epoch 954/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9804 - loss: 0.0397 - val_accuracy: 0.9645 - val_loss: 0.3948\n",
      "Epoch 955/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0361 - val_accuracy: 0.9721 - val_loss: 0.3311\n",
      "Epoch 956/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9807 - loss: 0.0518 - val_accuracy: 0.9721 - val_loss: 0.3057\n",
      "Epoch 957/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9753 - loss: 0.0637 - val_accuracy: 0.9619 - val_loss: 0.3029\n",
      "Epoch 958/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9752 - loss: 0.0491 - val_accuracy: 0.9645 - val_loss: 0.3082\n",
      "Epoch 959/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9778 - loss: 0.0459 - val_accuracy: 0.9645 - val_loss: 0.2862\n",
      "Epoch 960/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9799 - loss: 0.0398 - val_accuracy: 0.9670 - val_loss: 0.2966\n",
      "Epoch 961/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9829 - loss: 0.0399 - val_accuracy: 0.9670 - val_loss: 0.3360\n",
      "Epoch 962/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0397 - val_accuracy: 0.9645 - val_loss: 0.3556\n",
      "Epoch 963/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9787 - loss: 0.0431 - val_accuracy: 0.9619 - val_loss: 0.3307\n",
      "Epoch 964/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9817 - loss: 0.0349 - val_accuracy: 0.9619 - val_loss: 0.3617\n",
      "Epoch 965/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9815 - loss: 0.0390 - val_accuracy: 0.9695 - val_loss: 0.3437\n",
      "Epoch 966/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9792 - loss: 0.0428 - val_accuracy: 0.9721 - val_loss: 0.2984\n",
      "Epoch 967/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9866 - loss: 0.0321 - val_accuracy: 0.9695 - val_loss: 0.3503\n",
      "Epoch 968/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9801 - loss: 0.0369 - val_accuracy: 0.9695 - val_loss: 0.3600\n",
      "Epoch 969/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0347 - val_accuracy: 0.9695 - val_loss: 0.3730\n",
      "Epoch 970/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9837 - loss: 0.0350 - val_accuracy: 0.9695 - val_loss: 0.3022\n",
      "Epoch 971/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0501 - val_accuracy: 0.9645 - val_loss: 0.2846\n",
      "Epoch 972/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9841 - loss: 0.0303 - val_accuracy: 0.9619 - val_loss: 0.3251\n",
      "Epoch 973/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9813 - loss: 0.0369 - val_accuracy: 0.9695 - val_loss: 0.3109\n",
      "Epoch 974/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9830 - loss: 0.0340 - val_accuracy: 0.9695 - val_loss: 0.3177\n",
      "Epoch 975/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9855 - loss: 0.0278 - val_accuracy: 0.9695 - val_loss: 0.3257\n",
      "Epoch 976/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9846 - loss: 0.0314 - val_accuracy: 0.9695 - val_loss: 0.3205\n",
      "Epoch 977/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9807 - loss: 0.0417 - val_accuracy: 0.9645 - val_loss: 0.3301\n",
      "Epoch 978/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0291 - val_accuracy: 0.9695 - val_loss: 0.3459\n",
      "Epoch 979/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0287 - val_accuracy: 0.9695 - val_loss: 0.3467\n",
      "Epoch 980/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9827 - loss: 0.0379 - val_accuracy: 0.9695 - val_loss: 0.3463\n",
      "Epoch 981/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0364 - val_accuracy: 0.9695 - val_loss: 0.3292\n",
      "Epoch 982/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9854 - loss: 0.0311 - val_accuracy: 0.9670 - val_loss: 0.3187\n",
      "Epoch 983/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9822 - loss: 0.0424 - val_accuracy: 0.9670 - val_loss: 0.3058\n",
      "Epoch 984/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9832 - loss: 0.0329 - val_accuracy: 0.9619 - val_loss: 0.3480\n",
      "Epoch 985/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0337 - val_accuracy: 0.9695 - val_loss: 0.3486\n",
      "Epoch 986/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9833 - loss: 0.0338 - val_accuracy: 0.9721 - val_loss: 0.3509\n",
      "Epoch 987/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9850 - loss: 0.0331 - val_accuracy: 0.9721 - val_loss: 0.3344\n",
      "Epoch 988/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.0312 - val_accuracy: 0.9746 - val_loss: 0.3403\n",
      "Epoch 989/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9794 - loss: 0.0400 - val_accuracy: 0.9746 - val_loss: 0.3630\n",
      "Epoch 990/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9827 - loss: 0.0440 - val_accuracy: 0.9518 - val_loss: 0.4490\n",
      "Epoch 991/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9819 - loss: 0.0368 - val_accuracy: 0.9594 - val_loss: 0.4257\n",
      "Epoch 992/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9783 - loss: 0.0413 - val_accuracy: 0.9645 - val_loss: 0.4068\n",
      "Epoch 993/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9845 - loss: 0.0384 - val_accuracy: 0.9569 - val_loss: 0.4012\n",
      "Epoch 994/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9837 - loss: 0.0360 - val_accuracy: 0.9594 - val_loss: 0.3647\n",
      "Epoch 995/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9805 - loss: 0.0333 - val_accuracy: 0.9594 - val_loss: 0.3936\n",
      "Epoch 996/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9831 - loss: 0.0427 - val_accuracy: 0.9619 - val_loss: 0.3757\n",
      "Epoch 997/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9838 - loss: 0.0328 - val_accuracy: 0.9645 - val_loss: 0.3451\n",
      "Epoch 998/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9825 - loss: 0.0358 - val_accuracy: 0.9645 - val_loss: 0.3496\n",
      "Epoch 999/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9839 - loss: 0.0325 - val_accuracy: 0.9594 - val_loss: 0.3356\n",
      "Epoch 1000/1000\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9847 - loss: 0.0361 - val_accuracy: 0.9645 - val_loss: 0.3984\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 3. Train the Model\n",
    "# -------------------------\n",
    "batch_size = 32\n",
    "epochs = 1000 # Increase epochs if necessary\n",
    "\n",
    "history = model.fit(\n",
    "    [X_symptoms_train, X_weights_train], y_train,\n",
    "    validation_split=0.1,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per Epoch: [1.1047232151031494, 0.22070646286010742, 0.18642540276050568, 0.15308868885040283, 0.1424235999584198, 0.13100984692573547, 0.1330299824476242, 0.11933767050504684, 0.11498575657606125, 0.12257509678602219, 0.10440509021282196, 0.09923392534255981, 0.11198285222053528, 0.09594957530498505, 0.098381906747818, 0.12957443296909332, 0.1089491993188858, 0.0908946767449379, 0.0938400849699974, 0.08676838129758835, 0.08716311305761337, 0.07995855063199997, 0.08514025807380676, 0.07945442944765091, 0.09119709581136703, 0.07863491773605347, 0.07967852056026459, 0.08267700672149658, 0.08282294124364853, 0.07628393918275833, 0.07518012076616287, 0.10581099987030029, 0.08686599135398865, 0.0779581218957901, 0.07639187574386597, 0.07807039469480515, 0.08099361509084702, 0.07758382707834244, 0.07105791568756104, 0.07084304839372635, 0.08068551868200302, 0.08487243205308914, 0.07096999883651733, 0.07348208129405975, 0.07295408844947815, 0.06756976246833801, 0.06841877102851868, 0.06734048575162888, 0.0677441731095314, 0.07703888416290283, 0.06844460964202881, 0.06425981223583221, 0.07341857254505157, 0.07205543667078018, 0.07297693192958832, 0.07683690637350082, 0.06625759601593018, 0.05993592366576195, 0.06102047860622406, 0.061788320541381836, 0.06404721736907959, 0.06554660201072693, 0.06033181771636009, 0.05813257023692131, 0.0771729126572609, 0.10749128460884094, 0.06766891479492188, 0.07101276516914368, 0.06419911235570908, 0.05427791550755501, 0.056074805557727814, 0.05697036534547806, 0.05577026307582855, 0.05596313253045082, 0.05111175402998924, 0.049443766474723816, 0.04892414063215256, 0.054276857525110245, 0.0668257400393486, 0.06701727211475372, 0.06107921525835991, 0.06207268312573433, 0.06098301708698273, 0.05573969706892967, 0.05816307291388512, 0.05460057035088539, 0.05643503740429878, 0.07580941915512085, 0.05100437253713608, 0.058163974434137344, 0.049225788563489914, 0.05181775614619255, 0.07018859684467316, 0.07139797508716583, 0.05978482589125633, 0.046666469424963, 0.05487542971968651, 0.06127261370420456, 0.053290609270334244, 0.04662644490599632, 0.048151999711990356, 0.04721113666892052, 0.0472697913646698, 0.04400239139795303, 0.06727565079927444, 0.08099287003278732, 0.0607132688164711, 0.04919256642460823, 0.056233007460832596, 0.053532592952251434, 0.051145538687705994, 0.04881306365132332, 0.0495024211704731, 0.04276585206389427, 0.041599519550800323, 0.04446906968951225, 0.052935779094696045, 0.05070364102721214, 0.049879226833581924, 0.04478840157389641, 0.04155075550079346, 0.042991992086172104, 0.05644208565354347, 0.05236204341053963, 0.058143578469753265, 0.055591095238924026, 0.05148071423172951, 0.05760526657104492, 0.05630498751997948, 0.04683277755975723, 0.04107727110385895, 0.0379866361618042, 0.0405290462076664, 0.05124519392848015, 0.08384329080581665, 0.0659356340765953, 0.051432639360427856, 0.047139622271060944, 0.04501056671142578, 0.0458945631980896, 0.0408792681992054, 0.04220288619399071, 0.038103122264146805, 0.04161543399095535, 0.05472460761666298, 0.04848778620362282, 0.05676927790045738, 0.05586903914809227, 0.06358370184898376, 0.052529942244291306, 0.06593690067529678, 0.06389165669679642, 0.04374052584171295, 0.0512809157371521, 0.042991284281015396, 0.056151341646909714, 0.048998136073350906, 0.05553537607192993, 0.05271667614579201, 0.0437709279358387, 0.04721811041235924, 0.05738178640604019, 0.04617331549525261, 0.044122692197561264, 0.03907774016261101, 0.0359199158847332, 0.0385899655520916, 0.04163427650928497, 0.0360528789460659, 0.03627119958400726, 0.04349963366985321, 0.04680211469531059, 0.04354444518685341, 0.0554889440536499, 0.06136125326156616, 0.06265537440776825, 0.04408056661486626, 0.05221627280116081, 0.04271586984395981, 0.0387287363409996, 0.04953112453222275, 0.04832754284143448, 0.03926091268658638, 0.03567608445882797, 0.03476119413971901, 0.03495568037033081, 0.03920404985547066, 0.051787909120321274, 0.05074349790811539, 0.07789497077465057, 0.06309030205011368, 0.053991712629795074, 0.03851168602705002, 0.036068178713321686, 0.03634219244122505, 0.037107862532138824, 0.05170007422566414, 0.05103667825460434, 0.047528985887765884, 0.03887554258108139, 0.051625218242406845, 0.039982471615076065, 0.04198684170842171, 0.05551597476005554, 0.048755429685115814, 0.042300522327423096, 0.03750726953148842, 0.035948704928159714, 0.0527103953063488, 0.07112926244735718, 0.047856688499450684, 0.04339008405804634, 0.03991956263780594, 0.03922850638628006, 0.03788265213370323, 0.03692483901977539, 0.036205995827913284, 0.04080703482031822, 0.03560427203774452, 0.03791647031903267, 0.03429541364312172, 0.03915584832429886, 0.04761119559407234, 0.052451539784669876, 0.04019930586218834, 0.034184779971838, 0.044252555817365646, 0.0422234982252121, 0.05573294684290886, 0.07828123867511749, 0.04721226170659065, 0.05564062297344208, 0.06026838719844818, 0.04338734596967697, 0.04316097870469093, 0.04610828310251236, 0.04819566011428833, 0.04823886230587959, 0.04156801477074623, 0.04408665746450424, 0.03722240775823593, 0.04374748095870018, 0.043517712503671646, 0.04550357535481453, 0.04788827523589134, 0.051288772374391556, 0.06424012035131454, 0.04296055808663368, 0.0397733636200428, 0.037119653075933456, 0.04600938782095909, 0.04434314742684364, 0.04323175549507141, 0.03643084317445755, 0.037314947694540024, 0.03422385826706886, 0.0354311428964138, 0.04973527416586876, 0.08232950419187546, 0.06063142046332359, 0.06226557120680809, 0.05667195841670036, 0.041815973818302155, 0.03815332427620888, 0.04391800984740257, 0.04204080253839493, 0.043721046298742294, 0.04082654416561127, 0.04064888134598732, 0.04321063309907913, 0.03668501600623131, 0.03586907684803009, 0.03551539406180382, 0.03694970905780792, 0.04410194605588913, 0.0424974262714386, 0.03662750869989395, 0.036659423261880875, 0.036505766212940216, 0.03842634707689285, 0.038358528167009354, 0.05117064341902733, 0.051925044506788254, 0.06750540435314178, 0.04784214124083519, 0.05323255434632301, 0.04648503661155701, 0.04136837273836136, 0.03681822121143341, 0.0368478000164032, 0.035581380128860474, 0.03574921935796738, 0.036354608833789825, 0.044375695288181305, 0.04020625725388527, 0.03494255244731903, 0.03580392897129059, 0.03411569818854332, 0.03935469686985016, 0.04189080372452736, 0.04130946099758148, 0.0419272854924202, 0.08585267513990402, 0.08806871622800827, 0.06721209734678268, 0.04196888953447342, 0.043350521475076675, 0.04460801184177399, 0.04169611260294914, 0.03868044912815094, 0.03725152090191841, 0.03527028113603592, 0.034486692398786545, 0.03668760508298874, 0.038178700953722, 0.03563658893108368, 0.0340934582054615, 0.033361244946718216, 0.032994892448186874, 0.03335098549723625, 0.03356756642460823, 0.03666896000504494, 0.04087189957499504, 0.051825061440467834, 0.038774870336055756, 0.041900694370269775, 0.0380338579416275, 0.03452054783701897, 0.034041184931993484, 0.0338636189699173, 0.033332936465740204, 0.04470293968915939, 0.055691711604595184, 0.05707268789410591, 0.04587294161319733, 0.042195674031972885, 0.04020588472485542, 0.038992904126644135, 0.035860031843185425, 0.04056748375296593, 0.03518071398139, 0.03909803554415703, 0.041285883635282516, 0.04172360524535179, 0.03541918471455574, 0.03489334508776665, 0.0352000892162323, 0.03366002067923546, 0.03263036161661148, 0.037371207028627396, 0.06455204635858536, 0.0621032752096653, 0.05051921680569649, 0.04461844265460968, 0.04260904714465141, 0.0352754220366478, 0.034241851419210434, 0.03419976308941841, 0.03339853510260582, 0.033320315182209015, 0.03524100407958031, 0.03597625344991684, 0.04053521901369095, 0.04667157307267189, 0.05532372370362282, 0.05260821059346199, 0.0557086244225502, 0.039884570986032486, 0.03710145875811577, 0.0394747331738472, 0.03816072270274162, 0.0332401841878891, 0.033489327877759933, 0.033472806215286255, 0.031842827796936035, 0.03865346312522888, 0.03214086964726448, 0.03476136922836304, 0.032537996768951416, 0.03661239892244339, 0.03304152563214302, 0.04703420400619507, 0.03739158436655998, 0.03766524791717529, 0.041148848831653595, 0.0377424880862236, 0.03642759844660759, 0.03716550022363663, 0.03537673130631447, 0.03383754566311836, 0.04383927211165428, 0.04920537769794464, 0.04459935054183006, 0.04191916063427925, 0.037598345428705215, 0.03536463528871536, 0.03700297698378563, 0.03675958886742592, 0.03787759691476822, 0.03479684889316559, 0.032591648399829865, 0.03184063732624054, 0.04364606365561485, 0.04826367646455765, 0.05572676658630371, 0.05982302874326706, 0.040936969220638275, 0.03692787140607834, 0.0410151481628418, 0.05075379088521004, 0.048312392085790634, 0.047858282923698425, 0.04200725257396698, 0.05285884439945221, 0.044429849833250046, 0.03700394555926323, 0.0347340889275074, 0.04898528382182121, 0.03903608024120331, 0.052210886031389236, 0.07614659518003464, 0.04672468826174736, 0.04055215045809746, 0.03942359238862991, 0.03582562133669853, 0.034686654806137085, 0.03296906501054764, 0.03168134763836861, 0.0328400544822216, 0.03434361517429352, 0.03473421558737755, 0.03246522694826126, 0.033042971044778824, 0.037781063467264175, 0.035143714398145676, 0.037009552121162415, 0.04561205580830574, 0.03476985543966293, 0.03399083763360977, 0.03703032433986664, 0.04612112417817116, 0.05099298059940338, 0.036484066396951675, 0.034864410758018494, 0.03329882025718689, 0.03555938974022865, 0.031686924397945404, 0.03271551430225372, 0.03144602105021477, 0.03271351009607315, 0.03644983842968941, 0.037899963557720184, 0.0350969135761261, 0.035841621458530426, 0.033901065587997437, 0.03365979716181755, 0.03269487991929054, 0.031751375645399094, 0.032188575714826584, 0.04129650816321373, 0.06461653858423233, 0.058351654559373856, 0.04846363887190819, 0.04081662744283676, 0.042169224470853806, 0.044801872223615646, 0.06334026157855988, 0.05390280485153198, 0.04483262822031975, 0.04711443558335304, 0.04044215753674507, 0.04543328285217285, 0.0586676262319088, 0.06604426354169846, 0.042260266840457916, 0.04231904819607735, 0.03785470500588417, 0.043092917650938034, 0.03945881873369217, 0.039106082171201706, 0.03399563580751419, 0.03314650431275368, 0.0380575954914093, 0.03460194543004036, 0.033633243292570114, 0.032139550894498825, 0.03263700753450394, 0.0337769016623497, 0.03235732764005661, 0.03181951493024826, 0.03131028264760971, 0.05612431466579437, 0.04227001219987869, 0.03807501867413521, 0.05129512771964073, 0.04654286429286003, 0.05373375117778778, 0.04210860654711723, 0.037323322147130966, 0.03571409359574318, 0.03887057304382324, 0.03597410395741463, 0.0373445525765419, 0.0371507965028286, 0.035666823387145996, 0.03379476070404053, 0.03841240331530571, 0.04334596171975136, 0.04106913134455681, 0.06067139655351639, 0.046899329870939255, 0.05391991138458252, 0.05505035072565079, 0.03573446720838547, 0.037403978407382965, 0.034156788140535355, 0.044151052832603455, 0.03725488483905792, 0.03622102737426758, 0.0365125946700573, 0.031676799058914185, 0.035092469304800034, 0.0357045978307724, 0.03532564640045166, 0.03185570612549782, 0.03191542625427246, 0.03143356740474701, 0.034341953694820404, 0.03262934461236, 0.03423129767179489, 0.03677636384963989, 0.03927477449178696, 0.05354652181267738, 0.043134503066539764, 0.052709680050611496, 0.043808404356241226, 0.03869953379034996, 0.03405125066637993, 0.03254137188196182, 0.03209904581308365, 0.033319927752017975, 0.042251866310834885, 0.03709816187620163, 0.034621402621269226, 0.03264043852686882, 0.034566730260849, 0.0356062576174736, 0.032735325396060944, 0.03305971249938011, 0.03180590271949768, 0.03237508609890938, 0.03557782247662544, 0.043332211673259735, 0.03302857652306557, 0.0387173555791378, 0.03913445398211479, 0.03466548025608063, 0.047394927591085434, 0.04009483754634857, 0.045020587742328644, 0.03368346765637398, 0.03175930306315422, 0.036553677171468735, 0.03162036091089249, 0.0371820293366909, 0.04958190396428108, 0.04700110852718353, 0.06154678389430046, 0.04308152198791504, 0.04608149081468582, 0.03743990883231163, 0.03407756984233856, 0.03255196660757065, 0.03367815166711807, 0.03154249116778374, 0.033379193395376205, 0.03643035888671875, 0.03898952156305313, 0.03338678553700447, 0.03558992221951485, 0.04361681267619133, 0.04778565093874931, 0.03585391491651535, 0.033067408949136734, 0.031785473227500916, 0.03859801962971687, 0.040948960930109024, 0.03383742645382881, 0.044793546199798584, 0.03688709810376167, 0.03230341523885727, 0.03460058197379112, 0.04600632190704346, 0.04033024609088898, 0.04665438085794449, 0.03548634797334671, 0.03553972765803337, 0.034766070544719696, 0.03430793806910515, 0.032732460647821426, 0.03301367908716202, 0.03323651850223541, 0.03438466042280197, 0.03145308047533035, 0.03189188614487648, 0.03124251961708069, 0.033090461045503616, 0.037194136530160904, 0.04368525370955467, 0.04085235670208931, 0.050547171384096146, 0.04181845486164093, 0.0339282788336277, 0.03393496572971344, 0.03641967847943306, 0.03647349029779434, 0.03746118023991585, 0.04239225760102272, 0.04179307818412781, 0.058763131499290466, 0.04466106742620468, 0.05265742167830467, 0.03356153517961502, 0.04084381088614464, 0.034678760915994644, 0.03193415328860283, 0.034172143787145615, 0.0327192023396492, 0.03225985914468765, 0.030851194635033607, 0.043069396167993546, 0.041531752794981, 0.03482864424586296, 0.03420524299144745, 0.040375445038080215, 0.03811602294445038, 0.03961583226919174, 0.04044926539063454, 0.03392713516950607, 0.0334390364587307, 0.03343261033296585, 0.032298289239406586, 0.03332759067416191, 0.031791772693395615, 0.03131534159183502, 0.03322980925440788, 0.04222654178738594, 0.04708714410662651, 0.04186287149786949, 0.03720901533961296, 0.03263908624649048, 0.031696077436208725, 0.04724212735891342, 0.0412600040435791, 0.034921739250421524, 0.03462217375636101, 0.032982710748910904, 0.03205620497465134, 0.03745241090655327, 0.03566814586520195, 0.0347256101667881, 0.04440147057175636, 0.038769133388996124, 0.04319920018315315, 0.03733368590474129, 0.035979971289634705, 0.04267498478293419, 0.034524571150541306, 0.03481663763523102, 0.03117041476070881, 0.03315236046910286, 0.036747902631759644, 0.036817748099565506, 0.032186780124902725, 0.03330286592245102, 0.033721789717674255, 0.0325695164501667, 0.032120417803525925, 0.036183204501867294, 0.03621450811624527, 0.035259876400232315, 0.033016886562108994, 0.049562886357307434, 0.0454324446618557, 0.05439873784780502, 0.05043211579322815, 0.06350602209568024, 0.04470119997859001, 0.039235375821590424, 0.03330658748745918, 0.03146018832921982, 0.033851709216833115, 0.03837258741259575, 0.03794976696372032, 0.03312984108924866, 0.03251579776406288, 0.03153694048523903, 0.030551692470908165, 0.030511431396007538, 0.03201644495129585, 0.03500133007764816, 0.044685665518045425, 0.04672351852059364, 0.04184064641594887, 0.03590124100446701, 0.0649835616350174, 0.03707835078239441, 0.03233684226870537, 0.05274808406829834, 0.03699340298771858, 0.033995021134614944, 0.03257814049720764, 0.033303357660770416, 0.032590147107839584, 0.03127696365118027, 0.03189300373196602, 0.03377561271190643, 0.03485923632979393, 0.038149867206811905, 0.03672223165631294, 0.0582839697599411, 0.054464247077703476, 0.04191210865974426, 0.03520948067307472, 0.03588027134537697, 0.03368426114320755, 0.0367807000875473, 0.03995102643966675, 0.0360913947224617, 0.03357474505901337, 0.03420290723443031, 0.035041045397520065, 0.03458937257528305, 0.039665691554546356, 0.051983363926410675, 0.05797818675637245, 0.09184717386960983, 0.06179576367139816, 0.034804247319698334, 0.035060130059719086, 0.03358255699276924, 0.03067450225353241, 0.03228645771741867, 0.03295795992016792, 0.033199943602085114, 0.03362710401415825, 0.040411025285720825, 0.03515768051147461, 0.03201889991760254, 0.031177978962659836, 0.03178415820002556, 0.030808111652731895, 0.02972903847694397, 0.03775942325592041, 0.03391415253281593, 0.03162488713860512, 0.03133120387792587, 0.03643627464771271, 0.03326856344938278, 0.03780495375394821, 0.030763547867536545, 0.03169994428753853, 0.034274499863386154, 0.034925393760204315, 0.05847945809364319, 0.08153136819601059, 0.047297559678554535, 0.04882459342479706, 0.0342678427696228, 0.03397088125348091, 0.049514420330524445, 0.03424444422125816, 0.0315159447491169, 0.03020349331200123, 0.03560127690434456, 0.03567202389240265, 0.034150123596191406, 0.03542665019631386, 0.032944973558187485, 0.03727158531546593, 0.03915446251630783, 0.06655152142047882, 0.04208195209503174, 0.049111057072877884, 0.03654169663786888, 0.03118079900741577, 0.03334105387330055, 0.03219112381339073, 0.03236569091677666, 0.030407056212425232, 0.03161189705133438, 0.030129054561257362, 0.03084028698503971, 0.033712487667798996, 0.037768080830574036, 0.039737679064273834, 0.039886362850666046, 0.03426047042012215, 0.0377156026661396, 0.037303753197193146, 0.03386075794696808, 0.030767470598220825, 0.032167017459869385, 0.03161239996552467, 0.03376065194606781, 0.030882714316248894, 0.030001536011695862, 0.03168599680066109, 0.04736506566405296, 0.03803504630923271, 0.03370410203933716, 0.03339807689189911, 0.03058231621980667, 0.03240345045924187, 0.03213658556342125, 0.031703028827905655, 0.0433010496199131, 0.05107364431023598, 0.08640416711568832, 0.04343109577894211, 0.03267015516757965, 0.051431432366371155, 0.040147148072719574, 0.04042816907167435, 0.033504609018564224, 0.034362562000751495, 0.032455578446388245, 0.03158770129084587, 0.032659608870744705, 0.039482444524765015, 0.03357451781630516, 0.03250082582235336, 0.06401170790195465, 0.053742777556180954, 0.04716868698596954, 0.038174863904714584, 0.03422272577881813, 0.032875604927539825, 0.03369554132223129, 0.034025657922029495, 0.03630964830517769, 0.03322526812553406, 0.03319542109966278, 0.0331694670021534, 0.04154372960329056, 0.047876082360744476, 0.058650314807891846, 0.04505903646349907, 0.039535731077194214, 0.03601036220788956, 0.036253832280635834, 0.04889676719903946, 0.0352432057261467, 0.03139292821288109, 0.03141449764370918, 0.03164016455411911, 0.03143591806292534, 0.03213660418987274, 0.037969786673784256, 0.03157396987080574, 0.03339151665568352, 0.0339585542678833, 0.03346586972475052, 0.03200189769268036, 0.03141405060887337, 0.03104381635785103, 0.032367948442697525, 0.03465719148516655, 0.03494782745838165, 0.03370228409767151, 0.035613738000392914, 0.033196672797203064, 0.03211154788732529, 0.041108325123786926, 0.059101346880197525, 0.03973821923136711, 0.03533702343702316, 0.03316354379057884, 0.03372456878423691, 0.03213544934988022, 0.03601755574345589, 0.035009659826755524, 0.03106691688299179, 0.03485534340143204, 0.03227701410651207, 0.03196985647082329, 0.040344174951314926, 0.05135423317551613, 0.03721664845943451, 0.034127023071050644, 0.03378458321094513, 0.032520491629838943, 0.038323912769556046, 0.05117569491267204, 0.03508031368255615, 0.034564364701509476, 0.030455879867076874, 0.030931847169995308, 0.03039034642279148, 0.030041692778468132, 0.03300538286566734, 0.049863994121551514, 0.10836564749479294, 0.06387189775705338, 0.04516411945223808, 0.03742167353630066, 0.037424664944410324, 0.04141160473227501, 0.04646321013569832, 0.03969582915306091, 0.03914221003651619, 0.03557677939534187, 0.03300121799111366, 0.03215177357196808, 0.03214177489280701, 0.035968415439128876, 0.03263867273926735, 0.03285802900791168, 0.03220486268401146, 0.03191366046667099, 0.0354597382247448, 0.03371388465166092, 0.03184950351715088, 0.03109930269420147, 0.031928349286317825, 0.0360572375357151, 0.04560897871851921, 0.04629923775792122, 0.038109950721263885, 0.05494164675474167, 0.053321968764066696, 0.03543512523174286, 0.03288939967751503, 0.03654585778713226, 0.038455814123153687, 0.033961787819862366, 0.03499169275164604, 0.031523577868938446, 0.03897655010223389, 0.032434649765491486, 0.031442150473594666, 0.03189050033688545, 0.03318491578102112, 0.03277627006173134, 0.031497642397880554, 0.031195737421512604, 0.034726839512586594, 0.03772682696580887, 0.03849158436059952, 0.0340222604572773, 0.033628545701503754, 0.03702147677540779, 0.03293703868985176, 0.033001504838466644, 0.04106037691235542, 0.04068741202354431, 0.06322165578603745, 0.04914363846182823, 0.04643973335623741, 0.04586390405893326, 0.03658463805913925, 0.03971363231539726, 0.039434585720300674, 0.03719233348965645, 0.037770826369524, 0.042304251343011856, 0.03566762059926987, 0.03290046751499176, 0.03431686386466026, 0.04397635534405708, 0.050937362015247345, 0.034858398139476776, 0.03522142022848129, 0.03248325362801552, 0.0315425768494606, 0.03128081560134888, 0.04248076304793358, 0.03412281721830368, 0.032558221369981766, 0.035615988075733185, 0.03576921299099922, 0.034027546644210815, 0.04229459911584854, 0.03551945462822914, 0.033262401819229126, 0.03462952375411987, 0.03209277614951134, 0.030700189992785454, 0.04142292961478233, 0.04463627561926842, 0.038363732397556305, 0.03789346665143967, 0.041833072900772095, 0.03948211669921875, 0.03335462510585785, 0.0408870168030262, 0.03405898064374924, 0.035280320793390274, 0.03625207766890526, 0.039760246872901917]\n",
      "Validation Loss per Epoch: [0.31271448731422424, 0.19885259866714478, 0.1913992017507553, 0.19015470147132874, 0.228063702583313, 0.23858992755413055, 0.21593475341796875, 0.1683453470468521, 0.18584080040454865, 0.16235259175300598, 0.1513797491788864, 0.16561074554920197, 0.1762227714061737, 0.15803936123847961, 0.17729181051254272, 0.21375149488449097, 0.16477395594120026, 0.16474877297878265, 0.141976997256279, 0.19975683093070984, 0.15810196101665497, 0.15696483850479126, 0.1494186967611313, 0.16454286873340607, 0.17485441267490387, 0.16216088831424713, 0.1683938056230545, 0.16971613466739655, 0.15989018976688385, 0.19518907368183136, 0.1718790978193283, 0.16221369802951813, 0.16016742587089539, 0.15973053872585297, 0.20603324472904205, 0.19958263635635376, 0.1823398768901825, 0.18352138996124268, 0.1773015856742859, 0.1856922209262848, 0.22866807878017426, 0.19541390240192413, 0.18215623497962952, 0.20705492794513702, 0.20886173844337463, 0.20050619542598724, 0.2114403247833252, 0.21072369813919067, 0.2600409686565399, 0.18160778284072876, 0.18867726624011993, 0.18938079476356506, 0.1895807981491089, 0.182520791888237, 0.19137869775295258, 0.18710735440254211, 0.2076890766620636, 0.20001298189163208, 0.20619840919971466, 0.17750594019889832, 0.19469116628170013, 0.20098885893821716, 0.20675304532051086, 0.22582201659679413, 0.20574180781841278, 0.17061972618103027, 0.20778495073318481, 0.1638757586479187, 0.20561806857585907, 0.20294293761253357, 0.19095230102539062, 0.18986602127552032, 0.20042851567268372, 0.18813852965831757, 0.19708657264709473, 0.1830012947320938, 0.20513752102851868, 0.19447831809520721, 0.1915132999420166, 0.19604983925819397, 0.217111736536026, 0.21398814022541046, 0.20174278318881989, 0.19147586822509766, 0.19988910853862762, 0.20993590354919434, 0.20933803915977478, 0.1663801074028015, 0.20701445639133453, 0.1967313587665558, 0.18927983939647675, 0.1856948286294937, 0.20178887248039246, 0.20896996557712555, 0.18763388693332672, 0.2047894299030304, 0.2053077667951584, 0.20472368597984314, 0.19110903143882751, 0.20060956478118896, 0.19726920127868652, 0.20950570702552795, 0.21506786346435547, 0.21264983713626862, 0.19713474810123444, 0.22223639488220215, 0.2170650213956833, 0.22457434237003326, 0.2252005934715271, 0.22744525969028473, 0.22046785056591034, 0.20525316894054413, 0.21411281824111938, 0.2058192938566208, 0.20630884170532227, 0.24202027916908264, 0.21330830454826355, 0.21295276284217834, 0.2150726467370987, 0.21243856847286224, 0.22524313628673553, 0.2167098969221115, 0.21381495893001556, 0.23946531116962433, 0.214502215385437, 0.23190607130527496, 0.2338637411594391, 0.21901482343673706, 0.19525636732578278, 0.20980840921401978, 0.2190401554107666, 0.22163520753383636, 0.21358850598335266, 0.31660568714141846, 0.2551895081996918, 0.21038952469825745, 0.19969719648361206, 0.23205618560314178, 0.21573631465435028, 0.21600224077701569, 0.20263443887233734, 0.21471600234508514, 0.21507865190505981, 0.21401920914649963, 0.22474074363708496, 0.20905464887619019, 0.28288325667381287, 0.21430912613868713, 0.19922955334186554, 0.2173803150653839, 0.2304721623659134, 0.20736831426620483, 0.2189980000257492, 0.20121824741363525, 0.22259235382080078, 0.22376574575901031, 0.23424576222896576, 0.20331230759620667, 0.21122139692306519, 0.2033793330192566, 0.18906038999557495, 0.2102169692516327, 0.20767775177955627, 0.21417127549648285, 0.20581364631652832, 0.2147253155708313, 0.20849397778511047, 0.21731889247894287, 0.21728947758674622, 0.22453950345516205, 0.20828692615032196, 0.23133105039596558, 0.22447535395622253, 0.2551329433917999, 0.24668799340724945, 0.19689321517944336, 0.22695863246917725, 0.20779606699943542, 0.20756709575653076, 0.20716504752635956, 0.23942965269088745, 0.20029442012310028, 0.206282839179039, 0.2017863690853119, 0.21445155143737793, 0.21550898253917694, 0.21419356763362885, 0.20933151245117188, 0.23044289648532867, 0.24669714272022247, 0.2527332901954651, 0.2512719929218292, 0.24719928205013275, 0.2599550783634186, 0.2643830478191376, 0.2638661563396454, 0.25180694460868835, 0.2569011449813843, 0.23725679516792297, 0.25032147765159607, 0.25072145462036133, 0.2648840844631195, 0.2857397496700287, 0.2590811252593994, 0.25652047991752625, 0.2549763023853302, 0.2515260577201843, 0.26691123843193054, 0.2602577209472656, 0.20670494437217712, 0.2122751772403717, 0.22294320166110992, 0.21156683564186096, 0.2397669553756714, 0.23865152895450592, 0.2323576807975769, 0.22244305908679962, 0.2434704750776291, 0.24805676937103271, 0.24460609257221222, 0.26000651717185974, 0.2882941663265228, 0.26594144105911255, 0.2628719210624695, 0.2505660355091095, 0.2591783106327057, 0.26326853036880493, 0.247472882270813, 0.25077036023139954, 0.2351834774017334, 0.21876303851604462, 0.29452478885650635, 0.21188759803771973, 0.2311246395111084, 0.25529924035072327, 0.2253209799528122, 0.23546132445335388, 0.23034492135047913, 0.2446087896823883, 0.23469123244285583, 0.23586982488632202, 0.25833895802497864, 0.25999677181243896, 0.2538585066795349, 0.25331199169158936, 0.22689060866832733, 0.22287875413894653, 0.23102685809135437, 0.21748539805412292, 0.2212131917476654, 0.2028677761554718, 0.20338086783885956, 0.215692937374115, 0.22575005888938904, 0.23055320978164673, 0.22545160353183746, 0.2440940886735916, 0.19957897067070007, 0.22679314017295837, 0.2451077401638031, 0.27426761388778687, 0.2357090264558792, 0.23514743149280548, 0.22393926978111267, 0.2346537858247757, 0.2487632781267166, 0.2521991431713104, 0.22442351281642914, 0.21986398100852966, 0.22863130271434784, 0.24863380193710327, 0.22909125685691833, 0.2621091306209564, 0.24365630745887756, 0.25231224298477173, 0.23927830159664154, 0.24303993582725525, 0.2580184042453766, 0.2388027161359787, 0.2573675215244293, 0.2675538659095764, 0.2184215635061264, 0.2650448977947235, 0.269061803817749, 0.27728256583213806, 0.2142847776412964, 0.24702255427837372, 0.24423839151859283, 0.22971312701702118, 0.2685187757015228, 0.26468023657798767, 0.2570750117301941, 0.2677721083164215, 0.2531334459781647, 0.2565096318721771, 0.26182088255882263, 0.26530721783638, 0.25759488344192505, 0.25604045391082764, 0.25613072514533997, 0.277256578207016, 0.3085109293460846, 0.22011706233024597, 0.20779724419116974, 0.16177326440811157, 0.1946800947189331, 0.20463024079799652, 0.19580982625484467, 0.21203263103961945, 0.22904720902442932, 0.21607571840286255, 0.21073555946350098, 0.20651301741600037, 0.20607562363147736, 0.20441988110542297, 0.21427541971206665, 0.22176751494407654, 0.22015470266342163, 0.22190997004508972, 0.2360525131225586, 0.23076939582824707, 0.21442586183547974, 0.22787503898143768, 0.2223075032234192, 0.22968009114265442, 0.20640945434570312, 0.22307872772216797, 0.2253076732158661, 0.21605822443962097, 0.22076138854026794, 0.2229703664779663, 0.23779083788394928, 0.23996451497077942, 0.18998214602470398, 0.21780361235141754, 0.2118961364030838, 0.2024950385093689, 0.21736016869544983, 0.19945676624774933, 0.19856268167495728, 0.19916494190692902, 0.24333810806274414, 0.2538646459579468, 0.22069206833839417, 0.21868959069252014, 0.21051761507987976, 0.20973610877990723, 0.21312761306762695, 0.21989953517913818, 0.22016116976737976, 0.223995640873909, 0.18953968584537506, 0.18772287666797638, 0.22615103423595428, 0.23077437281608582, 0.23276452720165253, 0.24177971482276917, 0.23010557889938354, 0.23985205590724945, 0.2542187571525574, 0.25040605664253235, 0.24329032003879547, 0.22284764051437378, 0.2435697615146637, 0.24421846866607666, 0.26136860251426697, 0.22622346878051758, 0.22909106314182281, 0.23831243813037872, 0.24869808554649353, 0.24593019485473633, 0.25445833802223206, 0.24082531034946442, 0.25171980261802673, 0.2881210148334503, 0.24705471098423004, 0.2611721456050873, 0.2621901333332062, 0.25747084617614746, 0.30391114950180054, 0.36714065074920654, 0.2783741056919098, 0.2640073001384735, 0.24869345128536224, 0.21629559993743896, 0.23225246369838715, 0.24193927645683289, 0.2392454594373703, 0.24253495037555695, 0.27573347091674805, 0.24183307588100433, 0.21138060092926025, 0.21206678450107574, 0.2440544217824936, 0.2695799171924591, 0.26713740825653076, 0.27458831667900085, 0.27488765120506287, 0.31831663846969604, 0.30684223771095276, 0.2958452105522156, 0.2951370179653168, 0.26584964990615845, 0.23773014545440674, 0.2384108603000641, 0.19791433215141296, 0.257706880569458, 0.2927132546901703, 0.33600133657455444, 0.26712286472320557, 0.2606925964355469, 0.2675733268260956, 0.2569620609283447, 0.2524309754371643, 0.2762117087841034, 0.24271734058856964, 0.2962541878223419, 0.2601999342441559, 0.2757287323474884, 0.25634852051734924, 0.2616540491580963, 0.2479361593723297, 0.23332642018795013, 0.23549722135066986, 0.23831726610660553, 0.2342035174369812, 0.24861906468868256, 0.2441752403974533, 0.2378067523241043, 0.25428465008735657, 0.24254350364208221, 0.243484765291214, 0.24515287578105927, 0.24476352334022522, 0.23760442435741425, 0.2747718393802643, 0.22696399688720703, 0.24467511475086212, 0.26262006163597107, 0.33124682307243347, 0.18703778088092804, 0.22461053729057312, 0.22517383098602295, 0.24793773889541626, 0.2464440017938614, 0.24479804933071136, 0.252546101808548, 0.2390802502632141, 0.24352268874645233, 0.24535241723060608, 0.2612049877643585, 0.23471160233020782, 0.23572449386119843, 0.23377332091331482, 0.23426444828510284, 0.2347223311662674, 0.24356834590435028, 0.24188607931137085, 0.2695188820362091, 0.291337251663208, 0.22698119282722473, 0.20243099331855774, 0.21291592717170715, 0.2596498429775238, 0.20986756682395935, 0.23333494365215302, 0.252716600894928, 0.2717090845108032, 0.2444845736026764, 0.23499777913093567, 0.24482648074626923, 0.23449848592281342, 0.2631743550300598, 0.2912813127040863, 0.30701470375061035, 0.3089618682861328, 0.29283785820007324, 0.2824459969997406, 0.31730300188064575, 0.27995651960372925, 0.273267537355423, 0.2828117311000824, 0.2776212990283966, 0.29275643825531006, 0.27829790115356445, 0.2930930256843567, 0.2713390588760376, 0.27812981605529785, 0.27056562900543213, 0.2876856029033661, 0.28598400950431824, 0.23727722465991974, 0.2684251368045807, 0.29533448815345764, 0.2439294159412384, 0.27680346369743347, 0.2742438018321991, 0.2737923562526703, 0.27557307481765747, 0.271807998418808, 0.27685797214508057, 0.26973778009414673, 0.2955342233181, 0.28133416175842285, 0.28434327244758606, 0.2986804246902466, 0.3206492066383362, 0.36094844341278076, 0.2782498896121979, 0.24195539951324463, 0.28289473056793213, 0.3237444758415222, 0.2647862136363983, 0.30209559202194214, 0.2900184094905853, 0.30028215050697327, 0.2860875129699707, 0.2805980443954468, 0.28895848989486694, 0.29041314125061035, 0.30667367577552795, 0.293062299489975, 0.3045194745063782, 0.3007534146308899, 0.3171860873699188, 0.31263989210128784, 0.31894007325172424, 0.3139503598213196, 0.32168614864349365, 0.28601181507110596, 0.2854601740837097, 0.2731696367263794, 0.2910989820957184, 0.291180282831192, 0.28815627098083496, 0.3567507863044739, 0.28512704372406006, 0.30887800455093384, 0.3062645494937897, 0.31463372707366943, 0.3435804843902588, 0.33108144998550415, 0.298216849565506, 0.3019903302192688, 0.30254507064819336, 0.303457647562027, 0.30082967877388, 0.29568415880203247, 0.313066303730011, 0.3041398823261261, 0.290195494890213, 0.30075931549072266, 0.2850119173526764, 0.271777868270874, 0.29253292083740234, 0.2774452269077301, 0.31627410650253296, 0.2584053575992584, 0.3107646703720093, 0.27635449171066284, 0.3005768358707428, 0.3247012794017792, 0.32454726099967957, 0.34518715739250183, 0.40707969665527344, 0.3214796185493469, 0.33464518189430237, 0.3452405631542206, 0.3430532217025757, 0.31531062722206116, 0.34486955404281616, 0.32947343587875366, 0.33948764204978943, 0.3364635705947876, 0.32927635312080383, 0.3442111015319824, 0.3147036135196686, 0.32299935817718506, 0.34005364775657654, 0.35518878698349, 0.2818082571029663, 0.2941388487815857, 0.3066714107990265, 0.2954142093658447, 0.3064294457435608, 0.31333425641059875, 0.3545408248901367, 0.3276880979537964, 0.3072708547115326, 0.3804952800273895, 0.40425777435302734, 0.4042133390903473, 0.38383617997169495, 0.3990267515182495, 0.3858264982700348, 0.39848366379737854, 0.397848516702652, 0.40200263261795044, 0.4095478355884552, 0.39861178398132324, 0.4029128849506378, 0.40526267886161804, 0.3900367319583893, 0.3993314802646637, 0.4057542681694031, 0.41915905475616455, 0.4290672242641449, 0.38935813307762146, 0.38552042841911316, 0.3669310510158539, 0.3781294822692871, 0.4056307375431061, 0.4118983745574951, 0.4242427945137024, 0.39454641938209534, 0.3770133852958679, 0.41163456439971924, 0.3761643171310425, 0.3294445276260376, 0.30488327145576477, 0.27813565731048584, 0.2765786051750183, 0.30096104741096497, 0.2908253073692322, 0.2765316963195801, 0.3189035952091217, 0.32417234778404236, 0.33479270339012146, 0.3234964609146118, 0.34815603494644165, 0.3572165071964264, 0.30769988894462585, 0.300391286611557, 0.37553882598876953, 0.3466257154941559, 0.3706933557987213, 0.34867095947265625, 0.3573436439037323, 0.35484614968299866, 0.3550058603286743, 0.36905205249786377, 0.3617278039455414, 0.3579894006252289, 0.3672572374343872, 0.36697840690612793, 0.38347506523132324, 0.32655569911003113, 0.35709190368652344, 0.34514203667640686, 0.3551352322101593, 0.34458550810813904, 0.3352992534637451, 0.31027019023895264, 0.33542805910110474, 0.30651184916496277, 0.31590983271598816, 0.30569446086883545, 0.3128659129142761, 0.29218789935112, 0.30523189902305603, 0.31811845302581787, 0.31454139947891235, 0.3268537223339081, 0.30823105573654175, 0.3111056685447693, 0.31951621174812317, 0.3351142108440399, 0.3524657189846039, 0.3704899847507477, 0.3567732572555542, 0.37364327907562256, 0.3585781455039978, 0.3801642060279846, 0.3987891972064972, 0.3961564898490906, 0.40298858284950256, 0.4060054421424866, 0.39978229999542236, 0.3901979327201843, 0.38630470633506775, 0.3642636239528656, 0.3819117546081543, 0.38999080657958984, 0.3963252007961273, 0.37645435333251953, 0.3741772770881653, 0.2920904755592346, 0.2964956760406494, 0.29910850524902344, 0.32373693585395813, 0.3331414759159088, 0.3334116041660309, 0.4119848310947418, 0.32902204990386963, 0.3246195912361145, 0.3517148494720459, 0.35346806049346924, 0.3558056950569153, 0.35039013624191284, 0.34889811277389526, 0.38666537404060364, 0.3009745478630066, 0.35494786500930786, 0.3610748052597046, 0.35802507400512695, 0.36422210931777954, 0.37225237488746643, 0.36840319633483887, 0.3575949966907501, 0.3669029772281647, 0.37324097752571106, 0.3836931586265564, 0.3898482024669647, 0.38994407653808594, 0.4199536442756653, 0.40318843722343445, 0.4103609025478363, 0.4235983192920685, 0.39133062958717346, 0.36899182200431824, 0.3762162923812866, 0.3393923342227936, 0.36132344603538513, 0.36775243282318115, 0.37459617853164673, 0.3986169397830963, 0.38781091570854187, 0.37031081318855286, 0.35160309076309204, 0.3731946647167206, 0.39040982723236084, 0.3840162754058838, 0.36387309432029724, 0.38918739557266235, 0.4086448550224304, 0.361184298992157, 0.3601374328136444, 0.37639719247817993, 0.4066203832626343, 0.3944184482097626, 0.4136205315589905, 0.41240209341049194, 0.4019983112812042, 0.41955822706222534, 0.41150790452957153, 0.40659862756729126, 0.4047820270061493, 0.41305771470069885, 0.4146244525909424, 0.4012938439846039, 0.41408464312553406, 0.42946141958236694, 0.43301573395729065, 0.42943400144577026, 0.4621002674102783, 0.47375592589378357, 0.47814786434173584, 0.4764717221260071, 0.44945305585861206, 0.42999914288520813, 0.39597195386886597, 0.42668071389198303, 0.4416484534740448, 0.4145873486995697, 0.40763336420059204, 0.4624112844467163, 0.39971816539764404, 0.4059484004974365, 0.41163089871406555, 0.3940158486366272, 0.3573017418384552, 0.33739420771598816, 0.3684052526950836, 0.36219245195388794, 0.3356921970844269, 0.3735419809818268, 0.37241801619529724, 0.3669535517692566, 0.3862817585468292, 0.35498708486557007, 0.3865593373775482, 0.38988104462623596, 0.39948946237564087, 0.47380104660987854, 0.4766620397567749, 0.47105059027671814, 0.498198539018631, 0.4743921756744385, 0.47192513942718506, 0.4949360191822052, 0.46361616253852844, 0.48347729444503784, 0.46933284401893616, 0.47438064217567444, 0.4629170298576355, 0.4635346233844757, 0.4470857083797455, 0.45225805044174194, 0.43604525923728943, 0.43604913353919983, 0.40714946389198303, 0.4039972126483917, 0.42106831073760986, 0.42215925455093384, 0.453186959028244, 0.46214285492897034, 0.4645856022834778, 0.479549378156662, 0.4293467700481415, 0.43345192074775696, 0.44366464018821716, 0.44093701243400574, 0.46053263545036316, 0.4385499954223633, 0.43187323212623596, 0.42179882526397705, 0.41546955704689026, 0.4206485152244568, 0.4177703857421875, 0.34553706645965576, 0.36345088481903076, 0.3614324629306793, 0.4181826710700989, 0.3537321388721466, 0.36787959933280945, 0.35420939326286316, 0.37747570872306824, 0.3824203312397003, 0.3480636775493622, 0.3575233519077301, 0.3562091588973999, 0.3998505771160126, 0.384098619222641, 0.3530913293361664, 0.3618772029876709, 0.3597954213619232, 0.3349466025829315, 0.3477507531642914, 0.32930508255958557, 0.3295339345932007, 0.3240869343280792, 0.33439287543296814, 0.3582541346549988, 0.3203270137310028, 0.3052281141281128, 0.3076346814632416, 0.3387908935546875, 0.3497360646724701, 0.33122536540031433, 0.2853528559207916, 0.30893653631210327, 0.2372477501630783, 0.24884474277496338, 0.27582332491874695, 0.2683086693286896, 0.2724347710609436, 0.31920281052589417, 0.32700207829475403, 0.31777089834213257, 0.30664119124412537, 0.32178619503974915, 0.32299938797950745, 0.3275265097618103, 0.33262333273887634, 0.33329668641090393, 0.3491239547729492, 0.3686194121837616, 0.3757251501083374, 0.3876905143260956, 0.377907931804657, 0.3575654923915863, 0.37166595458984375, 0.39230984449386597, 0.3424018919467926, 0.3685675263404846, 0.4033024311065674, 0.38819533586502075, 0.41623789072036743, 0.4144981801509857, 0.4153960049152374, 0.41552338004112244, 0.42005497217178345, 0.4305988848209381, 0.3958362936973572, 0.400547057390213, 0.410704642534256, 0.4695171117782593, 0.30743512511253357, 0.3822875916957855, 0.3991835415363312, 0.39936572313308716, 0.3863656222820282, 0.3850834369659424, 0.3848879337310791, 0.38816899061203003, 0.367896169424057, 0.3782576620578766, 0.3871628940105438, 0.3905594050884247, 0.37826383113861084, 0.3716900050640106, 0.24864062666893005, 0.5042540431022644, 0.28060442209243774, 0.3159632682800293, 0.30431175231933594, 0.30952444672584534, 0.29283469915390015, 0.2785259485244751, 0.28057995438575745, 0.26524674892425537, 0.2877446711063385, 0.2799220681190491, 0.2875010073184967, 0.2916071116924286, 0.2905460596084595, 0.28606411814689636, 0.27358773350715637, 0.2790696918964386, 0.3003234267234802, 0.28589436411857605, 0.28135013580322266, 0.28090375661849976, 0.2810177206993103, 0.2958323359489441, 0.2965090870857239, 0.3340936005115509, 0.2972903251647949, 0.3145706355571747, 0.28017565608024597, 0.29801350831985474, 0.31759220361709595, 0.3220762014389038, 0.3187755346298218, 0.3446333706378937, 0.33685094118118286, 0.33147603273391724, 0.3726567327976227, 0.313503623008728, 0.31124746799468994, 0.3380703926086426, 0.30666983127593994, 0.3073560893535614, 0.3369689881801605, 0.35007187724113464, 0.3222009837627411, 0.30983835458755493, 0.3280062973499298, 0.345617413520813, 0.347528874874115, 0.3541669249534607, 0.34151020646095276, 0.3324546217918396, 0.39482271671295166, 0.3311053514480591, 0.3057471811771393, 0.30292370915412903, 0.308180034160614, 0.28615137934684753, 0.2966245412826538, 0.33596745133399963, 0.3556317985057831, 0.33074477314949036, 0.3617078959941864, 0.34366971254348755, 0.29835212230682373, 0.3502979576587677, 0.3599843382835388, 0.37302708625793457, 0.3022312819957733, 0.2846498191356659, 0.3251431882381439, 0.31088414788246155, 0.31767982244491577, 0.3256562650203705, 0.32051730155944824, 0.3301423490047455, 0.3459123969078064, 0.346670925617218, 0.34626519680023193, 0.32922840118408203, 0.31868112087249756, 0.30576014518737793, 0.3480338156223297, 0.34864699840545654, 0.3508880138397217, 0.33439815044403076, 0.3402612507343292, 0.3629930317401886, 0.44895362854003906, 0.4257046580314636, 0.40677696466445923, 0.40118011832237244, 0.3646751046180725, 0.3936297297477722, 0.37566208839416504, 0.34510523080825806, 0.3495507836341858, 0.33562323451042175, 0.3983543813228607]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# Print and Plot Train vs. Validation Loss\n",
    "# ----------------------------------------------------------------\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "print(\"Training Loss per Epoch:\", train_loss)\n",
    "print(\"Validation Loss per Epoch:\", val_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy per Epoch: [0.7382834553718567, 0.918690025806427, 0.9271597862243652, 0.9373235702514648, 0.9415584206581116, 0.948334276676178, 0.9418407678604126, 0.948334276676178, 0.9508752226829529, 0.9508752226829529, 0.9553924202919006, 0.9559571146965027, 0.9463579654693604, 0.95652174949646, 0.9587803483009338, 0.9545454382896423, 0.9553924202919006, 0.9601919651031494, 0.9593449831008911, 0.9570863842964172, 0.9556747674942017, 0.9647092223167419, 0.9584980010986328, 0.961885929107666, 0.9596273303031921, 0.9604743123054504, 0.9627329111099243, 0.9604743123054504, 0.9613212943077087, 0.9644268751144409, 0.9680970907211304, 0.9556747674942017, 0.9593449831008911, 0.962168276309967, 0.9624505639076233, 0.9635798931121826, 0.9635798931121826, 0.9669678211212158, 0.9686617851257324, 0.9666854739189148, 0.9624505639076233, 0.9627329111099243, 0.9683794379234314, 0.9666854739189148, 0.9632975459098816, 0.9686617851257324, 0.9680970907211304, 0.970073401927948, 0.9675324559211731, 0.9672501683235168, 0.9689440727233887, 0.9717673659324646, 0.9641445279121399, 0.9664031863212585, 0.9689440727233887, 0.9658384919166565, 0.9695087671279907, 0.9726143479347229, 0.9734613299369812, 0.9731789827346802, 0.9709203839302063, 0.969791054725647, 0.9706380367279053, 0.9726143479347229, 0.9672501683235168, 0.9647092223167419, 0.9712027311325073, 0.9695087671279907, 0.9720497131347656, 0.9743083119392395, 0.9751552939414978, 0.9728966951370239, 0.9731789827346802, 0.9723320007324219, 0.9762845635414124, 0.9788255095481873, 0.9768492579460144, 0.9743083119392395, 0.9712027311325073, 0.9743083119392395, 0.9740259647369385, 0.9745905995368958, 0.9731789827346802, 0.9734613299369812, 0.9731789827346802, 0.975437581539154, 0.9737436771392822, 0.970073401927948, 0.977978527545929, 0.9728966951370239, 0.9774138927459717, 0.9748729467391968, 0.9689440727233887, 0.9680970907211304, 0.9760022759437561, 0.978543221950531, 0.9751552939414978, 0.9745905995368958, 0.9740259647369385, 0.9776962399482727, 0.9776962399482727, 0.97826087474823, 0.977978527545929, 0.9776962399482727, 0.9717673659324646, 0.9664031863212585, 0.9728966951370239, 0.9776962399482727, 0.9768492579460144, 0.975437581539154, 0.9774138927459717, 0.9768492579460144, 0.9774138927459717, 0.9796724915504456, 0.9808018207550049, 0.978543221950531, 0.9768492579460144, 0.9762845635414124, 0.9757199287414551, 0.9802371263504028, 0.9776962399482727, 0.9799548387527466, 0.9757199287414551, 0.9737436771392822, 0.9731789827346802, 0.975437581539154, 0.9757199287414551, 0.9745905995368958, 0.9751552939414978, 0.9796724915504456, 0.9805194735527039, 0.9813664555549622, 0.9808018207550049, 0.9762845635414124, 0.9689440727233887, 0.9712027311325073, 0.9768492579460144, 0.9776962399482727, 0.978543221950531, 0.978543221950531, 0.9802371263504028, 0.9799548387527466, 0.9819310903549194, 0.9808018207550049, 0.9765669107437134, 0.9771315455436707, 0.9723320007324219, 0.975437581539154, 0.975437581539154, 0.9771315455436707, 0.9717673659324646, 0.9757199287414551, 0.9805194735527039, 0.9771315455436707, 0.9788255095481873, 0.9774138927459717, 0.975437581539154, 0.9762845635414124, 0.9771315455436707, 0.9788255095481873, 0.9788255095481873, 0.9720497131347656, 0.9765669107437134, 0.9793902039527893, 0.9808018207550049, 0.9824957847595215, 0.9805194735527039, 0.9805194735527039, 0.9816488027572632, 0.9808018207550049, 0.9796724915504456, 0.9791078567504883, 0.9799548387527466, 0.9748729467391968, 0.9745905995368958, 0.9745905995368958, 0.9808018207550049, 0.9765669107437134, 0.978543221950531, 0.9813664555549622, 0.9793902039527893, 0.977978527545929, 0.9802371263504028, 0.9830604195594788, 0.9824957847595215, 0.9841897487640381, 0.9810841083526611, 0.9771315455436707, 0.9796724915504456, 0.9743083119392395, 0.9737436771392822, 0.9765669107437134, 0.9824957847595215, 0.9822134375572205, 0.9833427667617798, 0.9813664555549622, 0.9748729467391968, 0.9768492579460144, 0.9765669107437134, 0.9810841083526611, 0.9802371263504028, 0.9810841083526611, 0.9813664555549622, 0.975437581539154, 0.9768492579460144, 0.9802371263504028, 0.9824957847595215, 0.9819310903549194, 0.9760022759437561, 0.975437581539154, 0.9776962399482727, 0.9793902039527893, 0.9810841083526611, 0.9808018207550049, 0.9805194735527039, 0.9827780723571777, 0.9816488027572632, 0.9816488027572632, 0.9822134375572205, 0.9810841083526611, 0.9830604195594788, 0.9816488027572632, 0.9802371263504028, 0.9776962399482727, 0.9819310903549194, 0.9822134375572205, 0.9805194735527039, 0.9791078567504883, 0.9774138927459717, 0.9726143479347229, 0.978543221950531, 0.9748729467391968, 0.9748729467391968, 0.9791078567504883, 0.9796724915504456, 0.9788255095481873, 0.9793902039527893, 0.977978527545929, 0.9799548387527466, 0.9802371263504028, 0.9827780723571777, 0.9805194735527039, 0.9799548387527466, 0.9774138927459717, 0.9774138927459717, 0.9768492579460144, 0.9748729467391968, 0.97826087474823, 0.9813664555549622, 0.9824957847595215, 0.9793902039527893, 0.9805194735527039, 0.9791078567504883, 0.9819310903549194, 0.9805194735527039, 0.9830604195594788, 0.9827780723571777, 0.9774138927459717, 0.9672501683235168, 0.9706380367279053, 0.9717673659324646, 0.9762845635414124, 0.9808018207550049, 0.9816488027572632, 0.9796724915504456, 0.9799548387527466, 0.9776962399482727, 0.9824957847595215, 0.9813664555549622, 0.9819310903549194, 0.9822134375572205, 0.983625054359436, 0.9819310903549194, 0.9819310903549194, 0.9810841083526611, 0.9805194735527039, 0.9816488027572632, 0.9813664555549622, 0.9827780723571777, 0.9822134375572205, 0.9827780723571777, 0.9768492579460144, 0.9765669107437134, 0.9734613299369812, 0.9771315455436707, 0.9776962399482727, 0.9799548387527466, 0.9805194735527039, 0.983625054359436, 0.9816488027572632, 0.9824957847595215, 0.9824957847595215, 0.9819310903549194, 0.9808018207550049, 0.9813664555549622, 0.9830604195594788, 0.9841897487640381, 0.9824957847595215, 0.9822134375572205, 0.9799548387527466, 0.97826087474823, 0.9813664555549622, 0.9731789827346802, 0.9680970907211304, 0.9706380367279053, 0.97826087474823, 0.978543221950531, 0.9768492579460144, 0.9799548387527466, 0.9816488027572632, 0.9830604195594788, 0.9816488027572632, 0.983625054359436, 0.9819310903549194, 0.9799548387527466, 0.9827780723571777, 0.9839074015617371, 0.9833427667617798, 0.983625054359436, 0.9830604195594788, 0.9830604195594788, 0.9819310903549194, 0.9816488027572632, 0.97826087474823, 0.9819310903549194, 0.9822134375572205, 0.9824957847595215, 0.9827780723571777, 0.9833427667617798, 0.9841897487640381, 0.9833427667617798, 0.9810841083526611, 0.97826087474823, 0.9774138927459717, 0.9774138927459717, 0.9793902039527893, 0.9808018207550049, 0.9822134375572205, 0.983625054359436, 0.9813664555549622, 0.9830604195594788, 0.9819310903549194, 0.9776962399482727, 0.9813664555549622, 0.9824957847595215, 0.9824957847595215, 0.9824957847595215, 0.983625054359436, 0.9841897487640381, 0.9822134375572205, 0.9734613299369812, 0.9751552939414978, 0.9776962399482727, 0.9805194735527039, 0.9799548387527466, 0.9827780723571777, 0.9833427667617798, 0.9824957847595215, 0.9830604195594788, 0.9833427667617798, 0.9824957847595215, 0.9819310903549194, 0.9830604195594788, 0.9808018207550049, 0.9776962399482727, 0.975437581539154, 0.977978527545929, 0.9808018207550049, 0.9824957847595215, 0.9813664555549622, 0.9819310903549194, 0.9830604195594788, 0.983625054359436, 0.9827780723571777, 0.9841897487640381, 0.9824957847595215, 0.9833427667617798, 0.9827780723571777, 0.9830604195594788, 0.9827780723571777, 0.9839074015617371, 0.9791078567504883, 0.9819310903549194, 0.9822134375572205, 0.9813664555549622, 0.9822134375572205, 0.9822134375572205, 0.9819310903549194, 0.9819310903549194, 0.9830604195594788, 0.9813664555549622, 0.9788255095481873, 0.9791078567504883, 0.9805194735527039, 0.9819310903549194, 0.9824957847595215, 0.9813664555549622, 0.9813664555549622, 0.9822134375572205, 0.9827780723571777, 0.983625054359436, 0.9841897487640381, 0.9808018207550049, 0.978543221950531, 0.9788255095481873, 0.975437581539154, 0.9813664555549622, 0.9819310903549194, 0.9816488027572632, 0.9793902039527893, 0.9808018207550049, 0.9796724915504456, 0.9796724915504456, 0.9802371263504028, 0.9819310903549194, 0.9827780723571777, 0.9839074015617371, 0.9796724915504456, 0.9816488027572632, 0.9791078567504883, 0.9793902039527893, 0.9791078567504883, 0.9805194735527039, 0.9813664555549622, 0.9827780723571777, 0.983625054359436, 0.9841897487640381, 0.9847543835639954, 0.9844720363616943, 0.9819310903549194, 0.9822134375572205, 0.9844720363616943, 0.9841897487640381, 0.9810841083526611, 0.9824957847595215, 0.9827780723571777, 0.9808018207550049, 0.9833427667617798, 0.9824957847595215, 0.983625054359436, 0.9805194735527039, 0.97826087474823, 0.9824957847595215, 0.9819310903549194, 0.9850367307662964, 0.9822134375572205, 0.9841897487640381, 0.9830604195594788, 0.9844720363616943, 0.983625054359436, 0.9833427667617798, 0.9813664555549622, 0.9830604195594788, 0.9830604195594788, 0.9839074015617371, 0.983625054359436, 0.9839074015617371, 0.9841897487640381, 0.9847543835639954, 0.9822134375572205, 0.9762845635414124, 0.9760022759437561, 0.9760022759437561, 0.9805194735527039, 0.9796724915504456, 0.9793902039527893, 0.9774138927459717, 0.9796724915504456, 0.9796724915504456, 0.9796724915504456, 0.9816488027572632, 0.9799548387527466, 0.977978527545929, 0.9737436771392822, 0.9799548387527466, 0.9813664555549622, 0.9816488027572632, 0.9819310903549194, 0.9808018207550049, 0.9802371263504028, 0.983625054359436, 0.9839074015617371, 0.9813664555549622, 0.9822134375572205, 0.9839074015617371, 0.9841897487640381, 0.983625054359436, 0.9827780723571777, 0.9833427667617798, 0.9839074015617371, 0.9841897487640381, 0.9796724915504456, 0.9808018207550049, 0.9813664555549622, 0.97826087474823, 0.9793902039527893, 0.9793902039527893, 0.9816488027572632, 0.9827780723571777, 0.9841897487640381, 0.9822134375572205, 0.9819310903549194, 0.9822134375572205, 0.9802371263504028, 0.9824957847595215, 0.9824957847595215, 0.9816488027572632, 0.9808018207550049, 0.9796724915504456, 0.9768492579460144, 0.978543221950531, 0.9793902039527893, 0.9788255095481873, 0.9830604195594788, 0.9827780723571777, 0.9822134375572205, 0.9822134375572205, 0.9827780723571777, 0.9819310903549194, 0.9827780723571777, 0.9844720363616943, 0.9827780723571777, 0.9822134375572205, 0.983625054359436, 0.9844720363616943, 0.9839074015617371, 0.9839074015617371, 0.9827780723571777, 0.9833427667617798, 0.9833427667617798, 0.9824957847595215, 0.9813664555549622, 0.975437581539154, 0.9793902039527893, 0.9774138927459717, 0.97826087474823, 0.9799548387527466, 0.9824957847595215, 0.9833427667617798, 0.9839074015617371, 0.9830604195594788, 0.9805194735527039, 0.9808018207550049, 0.9839074015617371, 0.9841897487640381, 0.9847543835639954, 0.983625054359436, 0.9830604195594788, 0.9839074015617371, 0.983625054359436, 0.9839074015617371, 0.983625054359436, 0.9822134375572205, 0.9819310903549194, 0.9833427667617798, 0.9810841083526611, 0.9822134375572205, 0.9802371263504028, 0.9810841083526611, 0.9816488027572632, 0.9839074015617371, 0.9841897487640381, 0.9830604195594788, 0.9839074015617371, 0.9827780723571777, 0.978543221950531, 0.9799548387527466, 0.97826087474823, 0.9788255095481873, 0.9788255095481873, 0.9833427667617798, 0.9830604195594788, 0.983625054359436, 0.983625054359436, 0.9841897487640381, 0.9839074015617371, 0.9833427667617798, 0.9810841083526611, 0.9824957847595215, 0.9819310903549194, 0.9805194735527039, 0.9788255095481873, 0.9819310903549194, 0.9833427667617798, 0.9844720363616943, 0.9824957847595215, 0.9808018207550049, 0.983625054359436, 0.9824957847595215, 0.9822134375572205, 0.9830604195594788, 0.9827780723571777, 0.9813664555549622, 0.9824957847595215, 0.9793902039527893, 0.9822134375572205, 0.9819310903549194, 0.9822134375572205, 0.9822134375572205, 0.9830604195594788, 0.9824957847595215, 0.983625054359436, 0.983625054359436, 0.9844720363616943, 0.9844720363616943, 0.9839074015617371, 0.9844720363616943, 0.9819310903549194, 0.9796724915504456, 0.9819310903549194, 0.9791078567504883, 0.9813664555549622, 0.9827780723571777, 0.9824957847595215, 0.9827780723571777, 0.9827780723571777, 0.9819310903549194, 0.9810841083526611, 0.978543221950531, 0.978543221950531, 0.9808018207550049, 0.9805194735527039, 0.9822134375572205, 0.9810841083526611, 0.9827780723571777, 0.9841897487640381, 0.9839074015617371, 0.9833427667617798, 0.9830604195594788, 0.9841897487640381, 0.9816488027572632, 0.9796724915504456, 0.9827780723571777, 0.9827780723571777, 0.9827780723571777, 0.9824957847595215, 0.9816488027572632, 0.9819310903549194, 0.983625054359436, 0.9824957847595215, 0.9830604195594788, 0.9841897487640381, 0.9830604195594788, 0.9841897487640381, 0.9839074015617371, 0.9833427667617798, 0.9808018207550049, 0.9788255095481873, 0.9799548387527466, 0.9824957847595215, 0.9839074015617371, 0.9839074015617371, 0.9827780723571777, 0.9802371263504028, 0.9830604195594788, 0.983625054359436, 0.9833427667617798, 0.9844720363616943, 0.9813664555549622, 0.9816488027572632, 0.9830604195594788, 0.9793902039527893, 0.9810841083526611, 0.9791078567504883, 0.9813664555549622, 0.9816488027572632, 0.9808018207550049, 0.9847543835639954, 0.9839074015617371, 0.9844720363616943, 0.9841897487640381, 0.9813664555549622, 0.9830604195594788, 0.9839074015617371, 0.9841897487640381, 0.9824957847595215, 0.9833427667617798, 0.9839074015617371, 0.9827780723571777, 0.9839074015617371, 0.9822134375572205, 0.983625054359436, 0.9791078567504883, 0.9808018207550049, 0.9788255095481873, 0.9774138927459717, 0.9743083119392395, 0.9793902039527893, 0.9816488027572632, 0.9827780723571777, 0.9827780723571777, 0.9813664555549622, 0.9791078567504883, 0.9816488027572632, 0.9816488027572632, 0.983625054359436, 0.9841897487640381, 0.983625054359436, 0.9841897487640381, 0.9839074015617371, 0.9819310903549194, 0.9796724915504456, 0.9802371263504028, 0.9808018207550049, 0.9819310903549194, 0.9788255095481873, 0.9827780723571777, 0.983625054359436, 0.9791078567504883, 0.9813664555549622, 0.9833427667617798, 0.9841897487640381, 0.9824957847595215, 0.9844720363616943, 0.9839074015617371, 0.9856013655662537, 0.9833427667617798, 0.9839074015617371, 0.9808018207550049, 0.9833427667617798, 0.9805194735527039, 0.9762845635414124, 0.9802371263504028, 0.9813664555549622, 0.9839074015617371, 0.9822134375572205, 0.9813664555549622, 0.9813664555549622, 0.9839074015617371, 0.9844720363616943, 0.9833427667617798, 0.9833427667617798, 0.9833427667617798, 0.9822134375572205, 0.9791078567504883, 0.9743083119392395, 0.9695087671279907, 0.9788255095481873, 0.983625054359436, 0.9841897487640381, 0.9833427667617798, 0.9850367307662964, 0.9847543835639954, 0.9833427667617798, 0.9847543835639954, 0.983625054359436, 0.9822134375572205, 0.9827780723571777, 0.9833427667617798, 0.9830604195594788, 0.983625054359436, 0.9847543835639954, 0.9839074015617371, 0.9833427667617798, 0.9824957847595215, 0.9844720363616943, 0.9830604195594788, 0.9827780723571777, 0.983625054359436, 0.9827780723571777, 0.9844720363616943, 0.9850367307662964, 0.9822134375572205, 0.9830604195594788, 0.9805194735527039, 0.9743083119392395, 0.97826087474823, 0.9791078567504883, 0.9824957847595215, 0.9830604195594788, 0.9799548387527466, 0.9827780723571777, 0.9839074015617371, 0.9847543835639954, 0.9827780723571777, 0.983625054359436, 0.9822134375572205, 0.9830604195594788, 0.9841897487640381, 0.9816488027572632, 0.9824957847595215, 0.9802371263504028, 0.9805194735527039, 0.9793902039527893, 0.9830604195594788, 0.9856013655662537, 0.9833427667617798, 0.983625054359436, 0.9839074015617371, 0.9847543835639954, 0.9847543835639954, 0.9841897487640381, 0.9844720363616943, 0.9824957847595215, 0.9822134375572205, 0.9813664555549622, 0.9824957847595215, 0.9844720363616943, 0.9844720363616943, 0.983625054359436, 0.9839074015617371, 0.9833427667617798, 0.983625054359436, 0.9839074015617371, 0.9827780723571777, 0.983625054359436, 0.9847543835639954, 0.9827780723571777, 0.9813664555549622, 0.9822134375572205, 0.9819310903549194, 0.9833427667617798, 0.9839074015617371, 0.9827780723571777, 0.9839074015617371, 0.9839074015617371, 0.9816488027572632, 0.9734613299369812, 0.9743083119392395, 0.9793902039527893, 0.9844720363616943, 0.97826087474823, 0.9805194735527039, 0.9833427667617798, 0.9844720363616943, 0.9819310903549194, 0.9844720363616943, 0.9850367307662964, 0.9853190183639526, 0.9827780723571777, 0.9833427667617798, 0.9841897487640381, 0.9819310903549194, 0.977978527545929, 0.9802371263504028, 0.9813664555549622, 0.9816488027572632, 0.9822134375572205, 0.983625054359436, 0.9833427667617798, 0.9827780723571777, 0.9830604195594788, 0.9830604195594788, 0.9827780723571777, 0.9819310903549194, 0.9805194735527039, 0.9774138927459717, 0.9793902039527893, 0.9810841083526611, 0.9824957847595215, 0.983625054359436, 0.9796724915504456, 0.983625054359436, 0.9833427667617798, 0.983625054359436, 0.9847543835639954, 0.9844720363616943, 0.9839074015617371, 0.9819310903549194, 0.9839074015617371, 0.9841897487640381, 0.983625054359436, 0.9844720363616943, 0.9833427667617798, 0.9844720363616943, 0.9839074015617371, 0.9839074015617371, 0.9839074015617371, 0.9827780723571777, 0.983625054359436, 0.9824957847595215, 0.9833427667617798, 0.9833427667617798, 0.9822134375572205, 0.9796724915504456, 0.9819310903549194, 0.9824957847595215, 0.9827780723571777, 0.9833427667617798, 0.9833427667617798, 0.983625054359436, 0.9827780723571777, 0.9824957847595215, 0.9822134375572205, 0.9827780723571777, 0.9822134375572205, 0.9819310903549194, 0.9788255095481873, 0.9819310903549194, 0.9830604195594788, 0.9830604195594788, 0.9833427667617798, 0.9819310903549194, 0.9802371263504028, 0.9830604195594788, 0.9827780723571777, 0.9839074015617371, 0.9841897487640381, 0.9841897487640381, 0.9850367307662964, 0.983625054359436, 0.9796724915504456, 0.9726143479347229, 0.9751552939414978, 0.9796724915504456, 0.9824957847595215, 0.9816488027572632, 0.9813664555549622, 0.9802371263504028, 0.9819310903549194, 0.9824957847595215, 0.9827780723571777, 0.983625054359436, 0.9841897487640381, 0.983625054359436, 0.9827780723571777, 0.9844720363616943, 0.9841897487640381, 0.9839074015617371, 0.9827780723571777, 0.9824957847595215, 0.9830604195594788, 0.9839074015617371, 0.9841897487640381, 0.9833427667617798, 0.9824957847595215, 0.9791078567504883, 0.9805194735527039, 0.9816488027572632, 0.9799548387527466, 0.97826087474823, 0.9833427667617798, 0.9833427667617798, 0.9824957847595215, 0.9816488027572632, 0.9816488027572632, 0.9827780723571777, 0.983625054359436, 0.9830604195594788, 0.9833427667617798, 0.9827780723571777, 0.983625054359436, 0.9833427667617798, 0.9830604195594788, 0.9827780723571777, 0.9833427667617798, 0.983625054359436, 0.9827780723571777, 0.9819310903549194, 0.9830604195594788, 0.9833427667617798, 0.9822134375572205, 0.9833427667617798, 0.9833427667617798, 0.9827780723571777, 0.9830604195594788, 0.9774138927459717, 0.9774138927459717, 0.9799548387527466, 0.9791078567504883, 0.9822134375572205, 0.9822134375572205, 0.9819310903549194, 0.9810841083526611, 0.9819310903549194, 0.9802371263504028, 0.9839074015617371, 0.9827780723571777, 0.9830604195594788, 0.9810841083526611, 0.9793902039527893, 0.9822134375572205, 0.9830604195594788, 0.983625054359436, 0.9847543835639954, 0.9850367307662964, 0.9808018207550049, 0.9833427667617798, 0.9839074015617371, 0.9827780723571777, 0.9833427667617798, 0.9839074015617371, 0.9822134375572205, 0.9819310903549194, 0.9833427667617798, 0.9833427667617798, 0.9847543835639954, 0.9833427667617798, 0.9827780723571777, 0.9805194735527039, 0.9796724915504456, 0.9810841083526611, 0.9816488027572632, 0.9810841083526611, 0.9822134375572205, 0.9813664555549622, 0.9819310903549194, 0.9827780723571777, 0.9830604195594788, 0.9819310903549194]\n",
      "Validation Accuracy per Epoch: [0.8959391117095947, 0.9492385983467102, 0.9263959527015686, 0.9492385983467102, 0.9213197827339172, 0.9238578677177429, 0.9263959527015686, 0.9365482330322266, 0.9390863180160522, 0.9467005133628845, 0.9543147087097168, 0.9467005133628845, 0.9390863180160522, 0.9593908786773682, 0.9390863180160522, 0.9340101480484009, 0.9365482330322266, 0.9467005133628845, 0.9492385983467102, 0.9492385983467102, 0.9517766237258911, 0.9517766237258911, 0.9467005133628845, 0.9543147087097168, 0.9365482330322266, 0.9517766237258911, 0.9467005133628845, 0.9467005133628845, 0.9644669890403748, 0.9467005133628845, 0.9568527936935425, 0.9517766237258911, 0.9441624283790588, 0.9517766237258911, 0.9517766237258911, 0.9492385983467102, 0.9568527936935425, 0.9543147087097168, 0.9619289636611938, 0.9517766237258911, 0.9441624283790588, 0.9492385983467102, 0.9517766237258911, 0.9441624283790588, 0.9441624283790588, 0.9593908786773682, 0.9568527936935425, 0.9416243433952332, 0.9314720630645752, 0.9593908786773682, 0.9695431590080261, 0.9619289636611938, 0.9568527936935425, 0.9644669890403748, 0.9492385983467102, 0.9467005133628845, 0.9467005133628845, 0.9568527936935425, 0.9441624283790588, 0.9619289636611938, 0.9517766237258911, 0.9695431590080261, 0.9593908786773682, 0.9467005133628845, 0.9619289636611938, 0.9543147087097168, 0.9441624283790588, 0.9619289636611938, 0.9543147087097168, 0.9543147087097168, 0.9619289636611938, 0.9670050740242004, 0.9543147087097168, 0.9695431590080261, 0.9644669890403748, 0.9619289636611938, 0.9568527936935425, 0.9619289636611938, 0.9619289636611938, 0.9543147087097168, 0.9543147087097168, 0.9543147087097168, 0.9593908786773682, 0.9644669890403748, 0.9644669890403748, 0.9543147087097168, 0.9619289636611938, 0.9670050740242004, 0.9517766237258911, 0.9517766237258911, 0.9568527936935425, 0.9619289636611938, 0.9619289636611938, 0.9568527936935425, 0.9695431590080261, 0.9543147087097168, 0.9619289636611938, 0.9543147087097168, 0.9644669890403748, 0.9644669890403748, 0.9619289636611938, 0.9670050740242004, 0.9644669890403748, 0.9543147087097168, 0.9619289636611938, 0.9644669890403748, 0.9619289636611938, 0.9670050740242004, 0.9568527936935425, 0.9619289636611938, 0.9517766237258911, 0.9670050740242004, 0.9695431590080261, 0.9644669890403748, 0.9695431590080261, 0.9644669890403748, 0.9593908786773682, 0.9695431590080261, 0.9543147087097168, 0.9644669890403748, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9593908786773682, 0.9695431590080261, 0.9517766237258911, 0.9670050740242004, 0.9543147087097168, 0.9644669890403748, 0.9644669890403748, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9492385983467102, 0.9517766237258911, 0.9644669890403748, 0.9644669890403748, 0.9568527936935425, 0.9619289636611938, 0.9619289636611938, 0.9670050740242004, 0.9593908786773682, 0.9644669890403748, 0.9543147087097168, 0.9644669890403748, 0.9619289636611938, 0.9543147087097168, 0.9644669890403748, 0.9670050740242004, 0.9619289636611938, 0.9568527936935425, 0.9619289636611938, 0.9644669890403748, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9619289636611938, 0.9644669890403748, 0.9543147087097168, 0.9695431590080261, 0.9644669890403748, 0.9543147087097168, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9644669890403748, 0.9619289636611938, 0.9619289636611938, 0.9517766237258911, 0.9670050740242004, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9416243433952332, 0.9644669890403748, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9568527936935425, 0.9593908786773682, 0.9670050740242004, 0.9619289636611938, 0.9670050740242004, 0.9644669890403748, 0.9644669890403748, 0.9593908786773682, 0.9517766237258911, 0.9670050740242004, 0.9644669890403748, 0.9644669890403748, 0.9644669890403748, 0.9619289636611938, 0.9670050740242004, 0.9644669890403748, 0.9568527936935425, 0.9644669890403748, 0.9644669890403748, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9593908786773682, 0.9619289636611938, 0.9593908786773682, 0.9619289636611938, 0.9695431590080261, 0.9670050740242004, 0.9644669890403748, 0.9644669890403748, 0.9670050740242004, 0.9619289636611938, 0.9670050740242004, 0.9441624283790588, 0.9670050740242004, 0.9670050740242004, 0.9593908786773682, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9619289636611938, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9619289636611938, 0.9593908786773682, 0.9644669890403748, 0.9517766237258911, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9593908786773682, 0.9543147087097168, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9619289636611938, 0.9670050740242004, 0.9644669890403748, 0.9619289636611938, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9568527936935425, 0.9390863180160522, 0.9746192693710327, 0.9720812439918518, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9619289636611938, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9619289636611938, 0.9720812439918518, 0.9695431590080261, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9644669890403748, 0.9644669890403748, 0.9695431590080261, 0.9670050740242004, 0.9644669890403748, 0.9619289636611938, 0.9720812439918518, 0.9695431590080261, 0.9593908786773682, 0.9492385983467102, 0.9593908786773682, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9720812439918518, 0.9593908786773682, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9695431590080261, 0.9619289636611938, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9568527936935425, 0.9619289636611938, 0.9619289636611938, 0.9644669890403748, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9543147087097168, 0.9593908786773682, 0.9644669890403748, 0.9695431590080261, 0.9670050740242004, 0.9619289636611938, 0.9670050740242004, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9593908786773682, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9593908786773682, 0.9644669890403748, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9619289636611938, 0.9644669890403748, 0.9695431590080261, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9695431590080261, 0.9644669890403748, 0.9720812439918518, 0.9695431590080261, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9593908786773682, 0.9720812439918518, 0.9670050740242004, 0.9720812439918518, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9619289636611938, 0.9593908786773682, 0.9670050740242004, 0.9593908786773682, 0.9695431590080261, 0.9568527936935425, 0.9619289636611938, 0.9593908786773682, 0.9644669890403748, 0.9619289636611938, 0.9720812439918518, 0.9644669890403748, 0.9695431590080261, 0.9644669890403748, 0.9543147087097168, 0.9593908786773682, 0.9670050740242004, 0.9593908786773682, 0.9644669890403748, 0.9619289636611938, 0.9593908786773682, 0.9619289636611938, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9593908786773682, 0.9720812439918518, 0.9568527936935425, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9644669890403748, 0.9593908786773682, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9593908786773682, 0.9670050740242004, 0.9644669890403748, 0.9619289636611938, 0.9568527936935425, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9619289636611938, 0.9670050740242004, 0.9720812439918518, 0.9670050740242004, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9644669890403748, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9543147087097168, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9670050740242004, 0.9593908786773682, 0.9695431590080261, 0.9670050740242004, 0.9492385983467102, 0.9593908786773682, 0.9644669890403748, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9619289636611938, 0.9644669890403748, 0.9568527936935425, 0.9644669890403748, 0.9644669890403748, 0.9619289636611938, 0.9644669890403748, 0.9644669890403748, 0.9568527936935425, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9670050740242004, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9543147087097168, 0.9619289636611938, 0.9619289636611938, 0.9644669890403748, 0.9543147087097168, 0.9568527936935425, 0.9644669890403748, 0.9644669890403748, 0.9644669890403748, 0.9644669890403748, 0.9644669890403748, 0.9644669890403748, 0.9619289636611938, 0.9568527936935425, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9670050740242004, 0.9593908786773682, 0.9593908786773682, 0.9593908786773682, 0.9568527936935425, 0.9644669890403748, 0.9619289636611938, 0.9695431590080261, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9644669890403748, 0.9644669890403748, 0.9695431590080261, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9619289636611938, 0.9720812439918518, 0.9695431590080261, 0.9568527936935425, 0.9670050740242004, 0.9644669890403748, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9644669890403748, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9644669890403748, 0.9619289636611938, 0.9568527936935425, 0.9619289636611938, 0.9593908786773682, 0.9644669890403748, 0.9644669890403748, 0.9593908786773682, 0.9644669890403748, 0.9543147087097168, 0.9619289636611938, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9543147087097168, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9619289636611938, 0.9670050740242004, 0.9568527936935425, 0.9644669890403748, 0.9695431590080261, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9619289636611938, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9619289636611938, 0.9720812439918518, 0.9644669890403748, 0.9644669890403748, 0.9568527936935425, 0.9593908786773682, 0.9644669890403748, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9644669890403748, 0.9720812439918518, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9619289636611938, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9619289636611938, 0.9568527936935425, 0.9517766237258911, 0.9695431590080261, 0.9670050740242004, 0.9619289636611938, 0.9517766237258911, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9568527936935425, 0.9644669890403748, 0.9593908786773682, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9695431590080261, 0.9644669890403748, 0.9670050740242004, 0.9619289636611938, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9644669890403748, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9568527936935425, 0.9720812439918518, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9670050740242004, 0.9695431590080261, 0.9568527936935425, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9746192693710327, 0.9720812439918518, 0.9746192693710327, 0.9720812439918518, 0.9670050740242004, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9593908786773682, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9670050740242004, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9619289636611938, 0.9644669890403748, 0.9720812439918518, 0.9695431590080261, 0.9720812439918518, 0.9670050740242004, 0.9720812439918518, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9720812439918518, 0.9644669890403748, 0.9720812439918518, 0.9720812439918518, 0.9619289636611938, 0.9644669890403748, 0.9644669890403748, 0.9670050740242004, 0.9670050740242004, 0.9644669890403748, 0.9619289636611938, 0.9619289636611938, 0.9695431590080261, 0.9720812439918518, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9619289636611938, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9644669890403748, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9695431590080261, 0.9670050740242004, 0.9670050740242004, 0.9619289636611938, 0.9695431590080261, 0.9720812439918518, 0.9720812439918518, 0.9746192693710327, 0.9746192693710327, 0.9517766237258911, 0.9593908786773682, 0.9644669890403748, 0.9568527936935425, 0.9593908786773682, 0.9593908786773682, 0.9619289636611938, 0.9644669890403748, 0.9644669890403748, 0.9593908786773682, 0.9644669890403748]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# Print and Plot Train vs. Validation Accuracy\n",
    "# ----------------------------------------------------------------\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "print(\"Training Accuracy per Epoch:\", train_acc)\n",
    "print(\"Validation Accuracy per Epoch:\", val_acc)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3663 | Test Accuracy: 0.9593\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 4. Evaluate the Model\n",
    "# -------------------------\n",
    "loss, accuracy = model.evaluate([X_symptoms_test, X_weights_test], y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f} | Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m new_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m     11\u001b[0m new_tokens \u001b[38;5;241m=\u001b[39m [sym\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m new_symptoms\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 12\u001b[0m new_seq \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mtexts_to_sequences(new_tokens)\n\u001b[0;32m     13\u001b[0m new_seq \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m new_seq \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sub]\n\u001b[0;32m     14\u001b[0m new_seq \u001b[38;5;241m=\u001b[39m pad_sequences([new_seq], maxlen\u001b[38;5;241m=\u001b[39mmax_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 5. Making Predictions\n",
    "# -------------------------\n",
    "\n",
    "# For making predictions on new data, make sure to preprocess the symptom tokens and weights similarly.\n",
    "\n",
    "# Example:\n",
    "\n",
    "new_symptoms = \"cold , cough , fever\"\n",
    "new_weights = [5, 6, 7]\n",
    "new_tokens = [sym.strip() for sym in new_symptoms.split(',')]\n",
    "new_seq = tokenizer.texts_to_sequences(new_tokens)\n",
    "new_seq = [item for sub in new_seq for item in sub]\n",
    "new_seq = pad_sequences([new_seq], maxlen=max_len, padding='post')\n",
    "new_weights = np.array([np.pad(new_weights, (0, max_len - len(new_weights)), 'constant')])\n",
    "prediction = model.predict([new_seq, new_weights])\n",
    "predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "print(\"Predicted Disease:\", predicted_label[0])\n",
    "predicted_disease = predicted_label[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hypothyroidism'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms = pd.read_csv(\"symtoms_df.csv\")\n",
    "precautions = pd.read_csv(\"precautions_df.csv\")\n",
    "workout = pd.read_csv(\"workout_df.csv\")\n",
    "description = pd.read_csv(\"description.csv\")\n",
    "medications = pd.read_csv('medications.csv')\n",
    "diets = pd.read_csv(\"diets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(sample_dis):\n",
    "    desc = description[description['Disease'] == sample_dis]['Description']\n",
    "    desc = \" \".join([w for w in desc])\n",
    "\n",
    "    pre = precautions[precautions['Disease'] == sample_dis][['Precaution_1', 'Precaution_2', 'Precaution_3', 'Precaution_4']]\n",
    "    pre = [col for col in pre.values]\n",
    "\n",
    "    med = medications[medications['Disease'] == sample_dis]['Medication']\n",
    "    med = [med for med in med.values]\n",
    "\n",
    "    die = diets[diets['Disease'] == sample_dis]['Diet']\n",
    "    die = [die for die in die.values]\n",
    "\n",
    "    wrkout = workout[workout['disease'] == sample_dis] ['workout']\n",
    "\n",
    "\n",
    "    return desc,pre,med,die,wrkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted disease:\n",
      "Hypothyroidism\n",
      "description:\n",
      "Hypothyroidism is a condition where the thyroid gland doesn't produce enough thyroid hormone.\n",
      "precautions:\n",
      "['reduce stress' 'exercise' 'eat healthy' 'get proper sleep']\n",
      "medications:\n",
      "['Antithyroid medications', 'Radioactive iodine', 'Thyroid surgery', 'Beta-blockers', 'Corticosteroids']\n",
      "workout:\n",
      "Include iodine-rich foods\n",
      "Consume selenium-rich foods\n",
      "Stay hydrated\n",
      "Include nutrient-rich foods\n",
      "Limit processed foods\n",
      "Consume foods rich in vitamins B and D\n",
      "Consult a healthcare professional\n",
      "Follow medical recommendations\n",
      "Maintain a stable weight\n",
      "Engage in regular exercise\n",
      "diets:\n",
      "['Hypothyroidism Diet', 'Iodine-rich foods', 'Selenium-rich foods', 'Fruits and vegetables', 'Whole grains']\n"
     ]
    }
   ],
   "source": [
    "desc, pre, med, die, wrkout = mapping(predicted_disease)\n",
    "\n",
    "print(\"predicted disease:\")\n",
    "print(predicted_disease)\n",
    "print(\"description:\")\n",
    "print(desc)\n",
    "\n",
    "print(\"precautions:\")\n",
    "for i in pre:\n",
    "    print(i)   \n",
    "\n",
    "print(\"medications:\")\n",
    "for i in med:\n",
    "    print( i)\n",
    "    \n",
    "\n",
    "print(\"workout:\")\n",
    "for i in wrkout:\n",
    "    print(i)\n",
    "    \n",
    "\n",
    "print(\"diets:\")\n",
    "for i in die:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Save the tokenizer\\nimport pickle\\nwith open(\\'tokenizer.pickle\\', \\'wb\\') as handle:\\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n# Save the label encoder\\nwith open(\\'label_encoder.pickle\\', \\'wb\\') as handle:\\n    pickle.dump(le, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\\nprint(\"Model and resources saved successfully!\")'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('best_model.h5')\n",
    "'''\n",
    "# Save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save the label encoder\n",
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(le, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Model and resources saved successfully!\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and resources saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save the label encoder\n",
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# You might also want to save the max_len value as it's needed for preprocessing\n",
    "with open('max_len.pickle', 'wb') as handle:\n",
    "    pickle.dump(max_len, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Model and resources saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
